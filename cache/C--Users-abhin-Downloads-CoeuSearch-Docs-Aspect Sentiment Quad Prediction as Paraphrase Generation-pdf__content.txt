Aspect Sentiment Quad Prediction as Paraphrase Generation ∗ Wenxuan Zhang1, Yang Deng1, Xin Li2, Yifei Yuan1, Lidong Bing2 and Wai Lam1 1The Chinese University of Hong Kong 2DAMO Academy, Alibaba Group {wxzhang,ydeng,yfyuan,wlam}@se.cuhk.edu.hk {xinting.lx,l.bing}@alibaba-inc.com Abstract Aspect-based sentiment analysis (ABSA) has been extensively studied in recent years, which typically involves four fundamental sentiment elements, including the aspect category, aspect term, opinion term, and sentiment polarity. Ex- isting studies usually consider the detection of partial sentiment elements, instead of predict- ing the four elements in one shot. In this work, we introduce the Aspect Sentiment Quad Pre- diction (ASQP) task, aiming to jointly detect all sentiment elements in quads for a given opinionated sentence, which can reveal a more comprehensive and complete aspect-level sen- timent structure. We further propose a novel PARAPHRASE modeling paradigm to cast the ASQP task to a paraphrase generation process. On one hand, the generation formulation al- lows solving ASQP in an end-to-end manner, alleviating the potential error propagation in the pipeline solution. On the other hand, the se- mantics of the sentiment elements can be fully exploited by learning to generate them in the natural language form. Extensive experiments on benchmark datasets show the superiority of our proposed method and the capacity of cross- task transfer with the proposed uniﬁed PARA- PHRASE modeling framework. 1 Introduction As a ﬁne-grained opinion mining problem, aspect- based sentiment analysis (ABSA) aims to anal- yse sentiment information at the aspect level (Liu, 2012; Pontiki et al., 2014). Typically, four funda- mental sentiment elements are involved in ABSA, including 1) aspect category denoting the type of the concerned aspect; 2) aspect term which can be either explicitly or implicitly mentioned in the given text; 3) opinion term which describes the ∗ Work done when Wenxuan Zhang was an intern at Al- ibaba. This work was supported by Alibaba Group through Alibaba Research Intern Program, and a grant from the Re- search Grant Council of the Hong Kong Special Administra- tive Region, China (Project Codes: 14204418). opinion towards the aspect; and 4) sentiment polar- ity denoting the sentiment class. Given an example sentence “The pasta is over-cooked!”, the senti- ment elements are “food quality”, “pasta”, “over- cooked”, and “negative”, respectively. Due to its broad application scenarios, many re- search efforts have been made on ABSA to predict or extract those sentiment elements (Pontiki et al., 2014, 2015, 2016). Early studies focus on the pre- diction of a single element such as aspect term extraction (Liu et al., 2015; Xu et al., 2018), as- pect category detection (Zhou et al., 2015), aspect sentiment classiﬁcation based on either an aspect category (Ruder et al., 2016; Hu et al., 2019a) or an aspect term (Huang and Carley, 2018). More recent works propose to extract multiple associated sentiment elements at the same time (Zhang et al., 2021). For example, Chen et al. (2020) consider the aspect and opinion term pairwise extraction; Peng et al. (2020) propose the aspect sentiment triplet extraction (ASTE) task to detect the (aspect term, opinion term, sentiment polarity) triplets; Wan et al. (2020) handle the target aspect sentiment detection (TASD) task that jointly detects the aspect category, aspect term, and sentiment polarity. Despite their popularity, these ABSA tasks only attempt to perform partial prediction instead of providing a complete aspect-level sentiment pic- ture, i.e., identifying the four sentiment elements in one shot. To this end, we introduce the aspect sentiment quad prediction (ASQP) task, aiming to predict all (aspect category, aspect term, opinion term, sentiment polarity) quads for a given opinion- ated sentence. This new task compensates for the drawbacks of previous tasks and helps us compre- hensively understand user’s aspect-level opinions. To tackle ASQP, one straightforward idea is to decouple the quad prediction problem into sev- eral sub-tasks and solve them in a pipeline manner. However, such multi-stage approaches would suffer severely from error propagation because the overall 1 2 0 2 t c O 2 ] L C . s c [ 1 v 6 9 7 0 0 . 0 1 1 2 : v i X r a             prediction performance hinges on the accuracy of every step (Peng et al., 2020; Chen et al., 2020). Besides, the involved sub-tasks, which are usually formulated as either token-level or sequence-level classiﬁcation problems, underutilize the rich se- mantic information of the label (i.e., the meaning of sentiment elements to be predicted) since they treat the labels as number indices during training. Intuitively, the aspect term “pasta” is unlikely to be coupled with the aspect category “service gen- eral” due to the large semantic gap between them. But such information cannot be suitably utilized in those classiﬁcation-type methods. Inspired by recent success in formulating vari- ous NLP tasks as text generation problems (Athi- waratkun et al., 2020; Paolini et al., 2021; Liu et al., 2021), we propose to tackle ASQP in a sequence- to-sequence (S2S) manner in this paper. On one hand, the sentiment quads can be predicted in an end-to-end manner, alleviating the potential error propagation in the pipeline solutions. On the other hand, the rich label semantic information could be fully exploited by learning to generate the senti- ment elements in the natural language form. Exploiting generation modeling for the ASQP task mainly faces two challenges: (i) how to lin- earize the desired sentiment information so as to facilitate the S2S learning? (ii) how can we utilize the pretrained models for tackling the task, which is a common practice now for solving various ABSA tasks (Xu et al., 2020; Cai et al., 2020)? To handle these two challenges, we propose a novel PARA- PHRASE modeling paradigm, which transforms the ASQP task as a paraphrase generation problem (Bhagat and Hovy, 2013). Speciﬁcally, our ap- proach linearizes the sentiment quad into a natu- ral language sentence as if we were paraphrasing the input sentence and highlighting its major sen- timent elements. For example, we can transform the aforementioned sentiment quad (food quality, pasta, over-cooked, negative) to a sentence “Food quality is bad because pasta is over-cooked”. Such a linearized target sequence, paired with the input sentence “The pasta is over-cooked!” can then be used to learn the mapping function of a genera- tion model. We can seamlessly utilize the large pretrained generative models such as T5 (Raffel et al., 2020) by ﬁne-tuning with such input-target pairs. Therefore, the rich label semantics of the sentiment elements is naturally fused with the rich knowledge of the pretrained models in the form of natural sentences, rather than directly treating the desired sentiment quad text sequence as the generation target (Zhang et al., 2021). We summarize our contributions as follows: 1) We study a new task, namely aspect sentiment quad prediction (ASQP) in this work and introduce two datasets with sentiment quad annotations for each sample, aiming to analyze more comprehensive aspect-level sentiment information. 2) We propose to tackle ASQP as a paraphrase generation problem, which can predict the sentiment quads in one shot and fully utilize the semantics information of natu- ral language labels. 3) Extensive experiments show that the proposed PARAPHRASE modeling is effec- tive to tackle ASQP as well as other ABSA tasks, outperforming the previous state-of-the-art models in all cases. 4) The experiment also suggests that our PARAPHRASE method naturally facilitates the knowledge transfer across related tasks with the uniﬁed framework, which can be especially beneﬁ- cial in the low-resource setting.1 2 Related Work ABSA has been extensively studied in recent years where the main research line is the extraction of the sentiment elements. Early studies focus on the prediction of a single element such as extracting the aspect term (Liu et al., 2015; Yin et al., 2016; Xu et al., 2018; Ma et al., 2019), detecting the men- tioned aspect category (Zhou et al., 2015; Bu et al., 2021), and predicting the sentiment polarity, given either an aspect term (Wang et al., 2016; Huang and Carley, 2018; Zhang and Qian, 2020) or an as- pect category (Ruder et al., 2016; Hu et al., 2019a). Some works further consider the joint detection of two sentiment elements, including the pairwise extraction of aspect and opinion term (Wang et al., 2017; Chen et al., 2020; Zhao et al., 2020); the prediction of aspect term and its corresponding sen- timent polarity (Li et al., 2019a; He et al., 2019; Hu et al., 2019b; Luo et al., 2019; Chen and Qian, 2020); and the co-extraction of aspect category and sentiment polarity (Cai et al., 2020). More recently, triplet prediction tasks are pro- posed in ABSA, aiming to predict the sentiment elements in triplet format. Peng et al. (2020) pro- pose the aspect sentiment triplet extraction (ASTE) task, which has received lots of attention (Xu et al., 2020; Huang et al., 2021; Mao et al., 2021; Chen 1Code and annotated ASQP datasets are publicly available at https://github.com/IsakZhang/ABSA-QUAD. et al., 2021). Wan et al. (2020) introduce the target aspect sentiment detection (TASD) task, aiming to predict the aspect category, aspect term, and senti- ment polarity simultaneously, which can handle the case where the aspect term is implicit expressed in the given text (treated as “null”) (Wu et al., 2021). Built on top of those tasks, we introduce the aspect sentiment quad prediction problem, aiming to pre- dict the four sentiment elements in one shot, which can provide a more detailed and comprehensive sentiment structure for a given text. Adopting pretrained transformer-based models such as BERT (Devlin et al., 2019) has become a common practice for tackling the ABSA problem. Especially, many ABSA tasks beneﬁt from appro- priately utilizing the pretrained models. Sun et al. (2019) transform the aspect sentiment classiﬁcation task as a language inference problem by construct- ing an auxiliary sentence. Chen et al. (2021) and Mao et al. (2021) formulate multiple ABSA tasks as a reading comprehension task to fully utilize the knowledge of the pre-trained model. Very re- cently, there are some attempts on tackling ABSA problem in a S2S manner, either treating the class index (Yan et al., 2021) or the desired sentiment element sequence (Zhang et al., 2021) as the target of the generation model. In this work, we propose a PARAPHRASE modeling that can better utilize the knowledge of the pre-trained model via casting the original task to a paraphrase generation process. 3 Methodology 3.1 Problem Statement Given a sentence x, aspect sentiment quad predic- tion (ASQP) aims to predict all aspect-level senti- ment quadruplets {(c, a, o, p)} which corresponds to the aspect category, aspect term, opinion term, and sentiment polarity, respectively. The aspect category c falls into a category set Vc; the aspect term a and the opinion term o are typically text spans in the sentence x while the aspect term can also be null if the target is not explicitly mentioned: a ∈ Vx ∪ {∅} and o ∈ Vx where Vx denotes the set containing all possible continuous spans of x. The sentiment polarity p belongs to one of the senti- ment class {POS, NEU, NEG} denoting the positive, neutral, and negative sentiment respectively. Figure 1: Overview of the paraphrase generation frame- work. The underlined task identiﬁer in the input is only used under the cross-task transfer setting. tion problem and solve it in a sequence-to-sequence manner. As depicted in Figure 1, given a sentence x, we aim to generate a target sequence y with an encoder-decoder model M : x → y where y contains all the desired sentiment elements. Then the sentiment quads Q = {(c, a, o, p)} can be re- covered from y for making the prediction. On one hand, the semantics of the sentiment ele- ments in Q could be fully exploited by generating them in the natural language form in y. On the other hand, the input and target are both natural language sentences, which can naturally utilize the rich knowledge in the pretrained generative model. PARAPHRASE Modeling To facilitate the S2S learning, given the sentence label pair (x, Q), an important component of the PARAPHRASE model- ing framework is to linearize the sentiment quads Q to a natural language sequence y for constructing the input target pair (x, y). Ideally, we aim to neglect unnecessary details in the input sentence while highlight the major sentiment elements in the target sentence during the paraphrasing process. Based on this motivation, we linearize a sentiment quad q = (c, a, o, p) to a natural sentence as follows: Pc(c) is Pp(p) because Pa(a) is Po(o). 3.2 ASQP as Paraphrase Generation We propose a PARAPHRASE modeling paradigm to transform the ASQP task as a paraphrase genera- where Pz(·) is the projection function for z ∈ {c, a, o, p}, which maps the sentiment element z from the original format to a natural language form. c: ambience generala: placeo: too tinyp: NEGQuad #2c: drinks stylea: wine listo: excellentp: POSQuad #1Drinks style is great because wine list is excellent [SSEP] ambience general is bad because place is too tinyThewinelistyesterday…!ASQPDrinksstyleisgreat…tootinyThe wine list yesterday was excellent, but the place is too tiny for me! ASQPEncoderDecoderTarget y Input x Quads Q Quad RecoveryBy adopting suitable projection functions, a struc- tured sentiment quad q can then be transformed to an equivalent natural language sentence. For the input sentence x with multiple sentiment quads, we ﬁrst linearize each quad q to a natural sentence as described above. Then these sentences are concatenated with a special symbol [SSEP] to form the ﬁnal target sequence y, containing all the sentiment quads for the given sentence. Target Construction for ASQP Since the as- pect category c and opinion term o in each sen- timent quad are already in the natural language form, their projection functions just keep the orig- inal formats: Pc(c) = c and Po(o) = o. For the sentiment polarity, the projection is as follows: Pp(p) =    great ok bad if p = POS if p = NEU if p = NEG (1) where the main idea is to transform the sentiment label from the original class format to a natural lan- guage expression and also ensure the coherence of the whole linearized target sequence so that the semantics of the sentiment polarity can be ex- ploited by the generation model. Note that the spe- ciﬁc mapping can either be pre-deﬁned with com- monsense knowledge as in Equation 1 or dataset- dependent which utilizes the most common concur- ring opinion term for each sentiment polarity as the sentiment expression. As for the aspect term, we map it to an implicit pronoun if it is not explicitly mentioned, otherwise we can just use the original natural language form: Pa(a) = (cid:40) it a = ∅ a otherwise (2) This is to mimic the writing process where users often use a pronoun such as “it” or “this” to refer to a target that is not explicitly expressed. After deﬁning the speciﬁc projection functions for each sentiment element, we can then transform a sentiment quad to a sentence containing all the elements in the natural language form to facilitate the S2S learning. Two target construction examples for the ASQP task are shown in Figure 2. 3.3 Sequence-to-Sequence Learning The input-to-target generation can be modeled with a classical encoder-decoder model such as the Figure 2: Two examples of the target sentence construc- tion for the ASQP task. Better viewed in colors. Transformer architecture (Vaswani et al., 2017). Given the sentence x, the encoder ﬁrst transforms it into a contextualized encoded sequence e. The decoder then aims to model the conditional prob- ability distribution of the target sentence y given the encoded input representation: pθ(y|e) which is parameterized by θ. At the i-th time step, the decoder output yi is computed based on both the encoded input e and the previous outputs y<i: yi = fdec(e, y<i) where fdec(·) denotes the decoder computations. To ob- tain the probability distribution for the next token, a softmax function is then applied: pθ(yi+1|e, y<i+1) = softmax(W T yi) (3) where W maps the prediction yi to a logit vector, which can then be used to compute the probability distribution over the whole vocabulary set. Training With a pretrained encoder-decoder model such as T5 (Raffel et al., 2020), we can ini- tialize θ with the pretrained parameter weights and further ﬁne-tune the parameters on the input-target pair to maximize the log-likelihood pθ(y|e): max θ log pθ(y|e) = (cid:88)n i=1 log pθ(yi|e, y<i) (4) where n is the length of the target sequence y. Inference and Quad Recovery After the train- ing, we generate the target sequence y(cid:48) in an au- toregressive manner and select the token with the highest probability over the vocabulary set as the next token at each time step. Then we can recover the predicted sentiment quads Q(cid:48) from the genera- tions. Speciﬁcally, we ﬁrst split the possible multi- ple quads via detecting the pre-deﬁned separation token [SSEP]. Then for each linearized sentiment quad sequence, we extract the sentiment elements according to the modeling strategy introduced in Input-1The pasta yesterday was delicious!Label-1Target-1(c, a, o, p): (food quality, pasta, delicious, POS)Food quality is greatbecause pastais deliciousInput-2Everything they serve here … was just very disappointed, I wish they would change next timeLabel-2Target-2(c, a, o, p): (food quality, NULL, disappointed, NEG)Food quality is badbecause itis disappointed➯➯➯➯Sec 3.2 and compare them with the gold sentiment quad in Q for the evaluation. If such decoding fails, for example, the generated sequence violates the deﬁned format, we treat the prediction as null. Rest15 #0 #+ #S Train 834 Dev 209 Test 537 1005 252 453 34 14 37 #- 315 81 305 #S 1264 316 544 Rest16 #+ #0 1369 341 583 62 23 40 #- 558 143 176 3.4 ABSA as Paraphrase Generation The proposed PARAPHRASE modeling in fact pro- vides a general paradigm to tackle the ABSA prob- lem, which transforms the sentiment element pre- diction to a paraphrase generation process. There- fore, it can be easily extended to handle other ABSA tasks as well: we only need to change the projection functions for each sentiment element to suit the need for each task. We take the target aspect sentiment detection (TASD) (Wan et al., 2020) and aspect sentiment triplet extraction (ASTE) (Peng et al., 2020) tasks as two examples here2. The TASD task predicts the (c, a, p) triplets where all sentiment elements have the same con- dition as in the ASQP problem. Since it does not involve the opinion term prediction, we just let Po(o) = Pp(p) which uses a manually constructed opinion word as the opinion expression to describe the sentiment in the paraphrase. Other projection functions can remain the same as in the ASQP task. For instance, it transforms the (service general, waiter, NEG) triplet to the target sentence “Service general is bad because waiter is bad”. For the ASTE task aiming to predict (a, o, p) triplets, we map the aspect category to an implicit pronoun such as “it” (Po(o) = it) in all cases. Be- sides, it ignores the implicit aspect term, which means a ∈ Vx. We then always use the aspect term in its original natural language form: Pa(a) = a. Given an example triplet (Chinese food, nice, POS), a target sentence “It is great because Chinese food is nice” can be constructed accordingly. 3.5 Cross-task Knowledge Transfer In practice, it is usually rather difﬁcult and expen- sive to collect large-scale annotated data for com- plex ABSA problems like ASQP. Fortunately, as introduced in the last section, the proposed PARA- PHRASE method tackles various ABSA tasks in a uniﬁed framework. This characteristic naturally en- ables the knowledge to be easily transferred across related ABSA tasks, which is especially beneﬁcial 2In fact, any ABSA task involving the prediction of one or multiple sentiment elements can be considered as a sub-task of ASQP. We mainly discuss ASTE and TASD tasks in this paper since they are more closely related. Table 1: Data statistics for the ASQP task. #S, #+, #0, and #- denote the number of sentences, number of pos- itive, neutral, negative quads respectively. under the low-resource setting (i.e., the labeled data for the concerned task is insufﬁcient). We investigate cross-task transfer for the con- cerned ASQP task, with the help of its two sub- tasks, including ASTE and TASD. Similar to re- cent works on using “prompt” as the task identiﬁer (Raffel et al., 2020; Liu et al., 2021), we add a task- speciﬁc text sufﬁx (e.g., ASQP for the ASQP task in Figure 1) to the input sentence before feeding it to the model for specifying which task the model should perform. Since the PARAPHRASE paradigm provides a consistent training objective, the rich task-speciﬁc knowledge can ﬁrst be learned from training on the TASD and ASTE tasks, and then nat- urally transferred to the ASQP task via ﬁne-tuning on the (limited) ASQP data. 4 Experimental Setup Dataset We build the ASQP datasets based on SemEval Shared Challenges (Pontiki et al., 2015, 2016). The annotations of the opinion term and aspect category are derived from Peng et al. (2020) and Wan et al. (2020) respectively. We align the samples from these two sources and merge the an- notations with the same aspect term in each sen- tence as the anchor. We further conduct some addi- tional annotations: • Sentences without explicit aspect terms are ig- nored in Peng et al. (2020), we add these sen- tences back to our ASQP datasets and manually annotate the opinion terms for them, based on the given aspect category. For example, given a sentence “Everything we had was good...” with implicit aspect term, we then annotate “good” as the opinion term according to the aspect category “food quality”. The quads with implicit opinion expressions are discarded. • For the same aspect term associated with multi- ple aspect categories and/or opinion terms, the merging result will have more than four senti- ment elements for each quad, we then manually check those cases to correct the labels to ensure Type Methods Pipeline Uniﬁed HGCN-BERT + BERT-Linear HGCN-BERT + BERT-TFM TASO-BERT-Linear TASO-BERT-CRF GAS Ours PARAPHRASE w/o sentiment polarity semantics w/o aspect category semantics w/o polarity & category semantics Rest15 Rest16 Pre Rec F1 Pre Rec F1 24.43 25.55 41.86 44.24 45.31 46.16 45.30 44.65 43.46 20.25 22.01 26.50 28.66 46.70 47.72 46.87 46.59 45.19 22.15 23.65 32.46 34.78 45.98 46.93 46.07 45.60 44.30 25.36 27.40 49.73 48.65 54.54 56.63 56.56 56.27 56.04 24.03 26.41 40.70 39.68 57.62 59.30 58.82 58.38 57.53 24.68 26.90 44.77 43.71 56.04 57.93 57.67 57.31 56.77 Table 2: Main results of the ASQP task and ablations on label semantics for the proposed method. The best and second best results are in bold and underlined respectively. Scores are averaged over 5 runs with different seeds. the aspect category and opinion term are matched in the same quad. Every sample is annotated by two human an- notators and the conﬂict cases would be checked. Finally, we obtain two datasets, namely Rest15 and Rest16, where each data instance contains a review sentence with one or multiple sentiment quads. We further split 20% of the data from the training set as the validation set. The statistics is summarized in Table 1. Evaluation Metrics We employ F1 scores as the main evaluation metrics. A sentiment quad pre- diction is counted as correct if and only if all the predicted elements are exactly the same as the gold labels. We also report the precision (Pre) and recall (Rec) scores for the ASQP task. Experiment Details The averaged scores over ﬁve runs with different random seed initialization are reported. We adopt the T5-BASE (Raffel et al., 2020) as the pretrained generative model described in Sec 3.3, which adopts a classical Transformer encoder-decoder network architecture. Regarding the training, we use a batch size of 16 and learning rate being 3e-4. The number of training epochs is 20 for all experiments. During the inference, we utilize greedy decoding for generating the output sequence. We also experiment with beam search decoding with the number of beams being 3, 5, and 8 respectively, all leading to similar performance with the greedy decoding. Therefore, greedy de- coding is used for simplicity. Baselines Since the ASQP task has not been ex- plored previously, we construct two types of base- lines to compare with our PARAPHRASE method: • Pipeline model: we cascade models in a pipeline manner for the quad prediction: HGCN (Cai et al., 2020) for jointly detecting the aspect cate- gory and sentiment polarity, followed by a BERT- based model extracting the aspect and opinion term (Li et al., 2019b), given the predicted aspect category and sentiment. The latter one can be ei- ther equipped with a linear layer (BERT-Linear) or a transformer block (BERT-TFM) on top. • Uniﬁed model: we ﬁrst modify TAS (Wan et al., 2020), a state-of-the-art uniﬁed model to extract (c, a, p) triplet, for tackling the ASQP task. TAS expands each original data sample into multiple samples, each with a speciﬁc aspect category and sentiment polarity pair, to solve the task in an end-to-end manner. We change its tagging schema to predict aspect and opinion term simul- taneously for constructing a uniﬁed model to pre- dict the quad, denoted as TASO (TAS with Opin- ion). There are two variants in terms of the pre- diction layer: either using a linear classiﬁcation layer (TASO-Linear) or the CRF layer (TASO- CRF). We also consider a generation-type base- line GAS, originally proposed in (Zhang et al., 2021), we modify it to directly treat the senti- ment quads sequence as the target for learning the generation model. It uses the same pretrained model as ours. 5 Results and Discussions 5.1 Main Results The result for the ASQP task is reported in Table 2. There are some notable observations: Firstly, the performance of the pipeline methods is far from satisfactory. Although both adopting BERT as the backbone, the uniﬁed methods (e.g., TASO-BERT- Linear) perform much better than the pipeline ones (e.g., HGCN-BERT + BERT-Linear). This veriﬁes our assumption that the pipeline solutions tend to accumulate errors from the sub-task models and ﬁnally affect the performance of the ﬁnal quad prediction. Secondly, among the uniﬁed methods, GAS outperforms two variants of TASO by a large margin, showing the effectiveness of the sequence- to-sequence modeling for the ASQP task. Besides, to solve the task in a uniﬁed manner, TASO ex- pands the dataset to |Vc| × |Vp| times the original size, leading to large computation costs and train- ing time. Thirdly, we can see that our proposed method, PARAPHRASE modeling achieves the best performance on all metrics across two datasets. Our method tackles the ASQP problem in an end-to-end manner, alleviating the possible error propagation in the pipeline solutions. Moreover, compared with the GAS method using the same pre-trained model, our PARAPHRASE also achieves superior results, suggesting that constructing target sequence in the natural language form is a better way for utiliz- ing the knowledge from the pre-trained generative model, thus leading to better performance. 5.2 Effect of Label Semantics Different from previous classiﬁcation-type meth- ods for tackling ABSA problem, our PARAPHRASE modeling can take advantage of the semantics of the sentiment elements by generating the natural language labels. We conduct ablation studies to further investigate the impact of the label seman- tics. Speciﬁcally, instead of mapping the label to the natural language form with the projection func- tions introduced in Sec 3.2, we map each label to a special symbol, similar as the number index in the classiﬁcation-type models, for representing each label class. We consider three cases: (1) w/o sen- timent polarity semantics: Pp(pi) = SPi where pi is a sentiment polarity, i denotes the index. For example, we map the positive class as SP1; (2) w/o aspect category semantics: Pc(cj) = ACj where we project the aspect category cj to a symbol with its index j3. For instance, the aspect category “food quality” will be mapped to AC3; (3) w/o polarity & category semantics: it considers the above two cases where both the meaning of aspect category and the sentiment polarity are removed. The results are presented in the lower part in Ta- 3The mapping relation between the category and their in- dexes is pre-deﬁned based on the entire dataset. CMLA+ (Wang et al., 2017) Li-uniﬁed-R (Li et al., 2019a) P-pipeline (Peng et al., 2020) Jet+BERT (Xu et al., 2020) GTS+BERT (Wu et al., 2020) Two-Stage (Huang et al., 2021) GAS (Zhang et al., 2021) PARAPHRASE L14 R14 R15 R16 33.16 42.34 42.87 51.04 55.21 58.58 58.19 61.13 42.79 51.00 51.46 62.40 64.81 68.16 70.52 72.03 37.01 47.82 52.32 57.53 54.88 58.59 60.23 62.56 41.72 44.31 54.21 63.83 66.08 67.52 69.05 71.70 Table 3: Results of the ASTE task compared with pre- vious state-of-the-art models. F1 scores are reported. ble 2. We can see that discarding the semantics of either element leads to a performance drop, and the drop becomes larger after discarding both of them. Comparing the ablations on the sentiment polarity and aspect category, the model suffers more when the aspect category is projected to an indexed sym- bol. The possible reason is that there are only three types of sentiment polarities, which is much less than the number of types for the aspect category. Therefore, it can be easier for the model to learn the mapping between the special symbols and the polarity type during the training. 5.3 Results on ASTE and TASD Tasks the proposed PARA- As described in Sec 3.4, PHRASE modeling provides a uniﬁed framework to tackle the ABSA problem, we thus test it on the ASTE and TASD tasks, and compare with the previous state-of-the-art methods for each task. For the ASTE task, we utilize the dataset pro- vided by Xu et al. (2020). We adopt two types of baselines: 1) pipeline-based methods includ- ing CMLA+ (Wang et al., 2017), Li-uniﬁed-R (Li et al., 2019a), Peng-pipeline (Peng et al., 2020) which ﬁrstly extract aspect and opinion terms sepa- rately, then conduct the pairing; Two-stage (Huang et al., 2021) which proposes a two-stage method to enhance the correlation between aspects and opin- ions; and 2) end-to-end models including GTS (Wu et al., 2020) and Jet (Xu et al., 2020), both design- ing uniﬁed tagging schemes in order to solve the task in an end-to-end fashion. For the TASD task, we adopt the dataset pre- pared by Wan et al. (2020). We compare with a pipeline-type baseline method Baseline-1-f_lex (Brun and Nikoulina, 2018), two BERT based mod- els including TAS-CRF and TAS-TO (Wan et al., 2020), and a recent model MEJD (Wu et al., 2021) which utilizes a graph structure to model the depen- dency among the sentiment elements. (a) Number of quads w.r.t. the mistake type. (b) Examples containing the input sentence, gold label and predicted quads. Figure 3: Error analysis and case study. Brun and Nikoulina (2018) TAS-CRF (Wan et al., 2020) TAS-TO (Wan et al., 2020) MEJD (Wu et al., 2021) GAS PARAPHRASE Rest15 Rest16 - 57.51 58.09 57.76 60.63 63.06 38.10 65.89 65.44 67.66 68.31 71.97 Table 4: Results of the TASD task compared with pre- vious state-of-the-art models. F1 scores are reported. The results for the ASTE and TASD tasks are shown in the Table 3 and 4 respectively. We also report the performance of the GAS method for comparison. We observe that the proposed PARA- PHRASE method consistently outperforms the pre- vious state-of-the-art models across all datasets in two tasks, showing the effectiveness of converting various ABSA tasks into a paraphrase generation problem. More importantly, by transforming the problem into a uniﬁed S2S task, we alleviate exten- sive task-speciﬁc model designs. Unlike previous studies with different network architectures for dif- ferent tasks, we use the same framework for solving the ASQP, ASTE, and TASD tasks, indicating the great generality of the PARAPHRASE method. 5.4 Error Analysis and Case Study To better understand the behaviour of the proposed method, especially in which cases it would fail, we conduct error analysis and case study in this section. We sample 100 sentences in the development set of each dataset and employ the trained model to make the predictions. Then we check the incorrect quad predictions and categorize their error types. when predicting the opinion term. Different from the aspect term, opinion term is typically not a single word, but a text span. We ﬁnd that the model often struggles to detect the exact same span as the ground-truths, as shown in the Example-1 in Figure 3b. For the aspect category, the model is often confused by semantically similar aspect categories such as “food quality” and “food style options”. For the sentiment polarity, the most common mistake is made by the confusion between “positive” and “neutral” classes, possibly due to the imbalanced label distribution in the dataset. Moreover, we compute the amount of predicted quads whose sentiment elements do not belong to the corresponding vocabulary set, due to the na- ture of the generation modeling since it does not perform “extraction” in the given sentence. For in- stance, a predicted aspect category does not belong to the deﬁned aspect category set Vc. As shown in the generation column in Figure 3a, this er- ror type in fact accounts for only a small portion in total. Example-2 presents a case for such error where the model changes the word “expected” in the original sentence to “thought” when predicting the opinion term. Although this might be similar to human readers, this prediction is judged as incor- rect since we use the exact match for the evaluation. Nevertheless, contrary to the possible perception that the generation type method might generate un- bounded contents which can be difﬁcult to recover sentiment quads or provide meaningless outputs, the predictions from the proposed method actually suffer little from the generation error. 5.5 ABSA Cross-task Transfer We ﬁrst analyze which type of sentiment element in the sentiment quad is the most difﬁcult for the model to predict and present the results in Figure 3a. In both datasets, the most common mistake is With the PARAPHRASE modeling, different ABSA tasks can be tackled in a similar manner, enabling the knowledge learned from related tasks to be eas- ily transferred to the target task. In our case, ASTE  Example-1 Sentence: Average to good Thai food, but terrible delivery. Gold Label: (food quality, Thai food, POS, Average to good), (service general, delivery, NEG, terrible) Prediction: (food quality, Thai food, NEG, Average) ✗, (service general, delivery, NEG, terrible) ✔ Example-2 Sentence: I went there for lunch and it was not as good as I expected from the reviews I read. Gold Label: (food quality, lunch, NEG, not as good as I expected) Prediction: (food quality, lunch, NEG, not as good as I thought) ✗characteristics of the proposed method. We can notice that ASQP remains a challeng- ing problem and worth further exploring. We look forward future work could propose better meth- ods to tackle such a difﬁcult ABSA task for fully revealing the aspect-level opinion information. References Ben Athiwaratkun, Cicero Nogueira dos Santos, Jason Krone, and Bing Xiang. 2020. Augmented natu- In ral language for generative sequence labeling. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 375–385, Online. Association for Computa- tional Linguistics. Rahul Bhagat and Eduard H. Hovy. 2013. What is a paraphrase? Comput. Linguistics, 39(3):463–472. Caroline Brun and Vassilina Nikoulina. 2018. As- pect based sentiment analysis into the wild. In Pro- ceedings of the 9th Workshop on Computational Ap- proaches to Subjectivity, Sentiment and Social Me- dia Analysis, WASSA@EMNLP 2018, pages 116– 122. Jiahao Bu, Lei Ren, Shuang Zheng, Yang Yang, Jin- gang Wang, Fuzheng Zhang, and Wei Wu. 2021. ASAP: A chinese review dataset towards aspect category sentiment analysis and rating prediction. CoRR, abs/2103.06605. Hongjie Cai, Yaofeng Tu, Xiangsheng Zhou, Jianfei Yu, and Rui Xia. 2020. Aspect-category based senti- ment analysis with hierarchical graph convolutional In Proceedings of the 28th International network. Conference on Computational Linguistics, COLING 2020, pages 833–843. Shaowei Chen, Jie Liu, Yu Wang, Wenzheng Zhang, and Ziming Chi. 2020. Synchronous double- channel recurrent network for aspect-opinion pair extraction. In Proceedings of the 58th Annual Meet- ing of the Association for Computational Linguistics, ACL 2020, pages 6515–6524. Shaowei Chen, Yu Wang, Jie Liu, and Yuelin Wang. 2021. Bidirectional machine reading comprehen- sion for aspect sentiment triplet extraction. In AAAI. Zhuang Chen and Tieyun Qian. 2020. Relation-aware collaborative learning for uniﬁed aspect-based sen- timent analysis. In Proceedings of the 58th Annual Meeting of the Association for Computational Lin- guistics, ACL 2020, pages 3685–3694. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language under- standing. In NAACL, pages 4171–4186. Figure 4: Cross-task transfer results. F1 scores on two datasets are shown with respect to the ratio of the ASQP data under three settings. and TASD are regarded as two sub-tasks to trans- fer the knowledge for handling ASQP. Here we consider two common situations where we might have adequate ASTE/TASD data for transfer (“Ad- equate transfer”) or we only have a small amount of ASTE/TASD data (“Scanty transfer”). In the experiment, we utilize 500/100 ASTE and TASD data samples for these two settings respectively. We vary the ratio of the ASQP data to simulate different scales of low-resource settings and report the results under two transfer situations in Figure 4. We also show the performance if we only train the model with the ASQP task, without any help from the knowledge transfer (“Train from scratch”). As can be observed in the ﬁgure, utilizing the knowledge learned from two triplet detection tasks can greatly beneﬁt the concerned sentiment quad prediction. For instance, with adequate annotated data of ASTE and TASD, using 5% of the ASQP data can lead to competitive performance compared with purely training with 50% ASQP data. Even with a scanty amount of data from related tasks to transfer, the model can still perform much better than purely trained on the sentiment quad data, especially under the low-resource setting. 6 Conclusions We introduce a new ABSA task, namely aspect sentiment quad prediction (ASQP) in this paper, aiming to provide a more comprehensive aspect- level sentiment picture. We propose a novel PARA- PHRASE modeling paradigm that tackles the orig- inal quad prediction as a paraphrase generation problem. Experiments on two datasets show its superiority compared with previous state-of-the-art models. We also demonstrate that the proposed method provides a uniﬁed framework that can be easily adapted to handle other ABSA tasks as well. Extensive analysis are conducted to understand the Ruidan He, Wee Sun Lee, Hwee Tou Ng, and Daniel Dahlmeier. 2019. An interactive multi-task learning network for end-to-end aspect-based sentiment anal- ysis. In ACL19, pages 504–515. Mengting Hu, Shiwan Zhao, Li Zhang, Keke Cai, Zhong Su, Renhong Cheng, and Xiaowei Shen. 2019a. CAN: constrained attention networks for multi-aspect sentiment analysis. In Proceedings of the 2019 Conference on Empirical Methods in Nat- ural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, pages 4600–4609. Minghao Hu, Yuxing Peng, Zhen Huang, Dongsheng Li, and Yiwei Lv. 2019b. Open-domain targeted sen- timent analysis via span-based extraction and classi- ﬁcation. In Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, pages 537–546. Binxuan Huang and Kathleen M. Carley. 2018. Param- eterized convolutional neural networks for aspect level sentiment classiﬁcation. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1091–1096. Lianzhe Huang, Peiyi Wang, Sujian Li, Tianyu Liu, Xiaodong Zhang, Zhicong Cheng, Dawei Yin, and Houfeng Wang. 2021. First target and opinion then polarity: Enhancing target-opinion correla- tion for aspect sentiment triplet extraction. CoRR, abs/2102.08549. Xin Li, Lidong Bing, Piji Li, and Wai Lam. 2019a. A uniﬁed model for opinion target extraction and target sentiment prediction. In AAAI, pages 6714–6721. Xin Li, Lidong Bing, Wenxuan Zhang, and Wai Lam. 2019b. Exploiting BERT for end-to-end aspect- In Proceedings of the based sentiment analysis. 5th Workshop on Noisy User-generated Text, W- NUT@EMNLP 2019, pages 34–41. Bing Liu. 2012. Sentiment Analysis and Opinion Min- ing. Synthesis Lectures on Human Language Tech- nologies. Pengfei Liu, Shaﬁq R. Joty, and Helen M. Meng. 2015. Fine-grained opinion mining with recurrent neural In Proceedings networks and word embeddings. of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015, pages 1433–1443. Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. 2021. GPT understands, too. CoRR, abs/2103.10385. Huaishao Luo, Tianrui Li, Bing Liu, and Junbo Zhang. 2019. DOER: dual cross-shared RNN for aspect In ACL, pages 591– term-polarity co-extraction. 601. Dehong Ma, Sujian Li, Fangzhao Wu, Xing Xie, and Houfeng Wang. 2019. Exploring sequence-to- sequence learning in aspect term extraction. In Pro- ceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, pages 3538–3547. Yue Mao, Yi Shen, Chao Yu, and Longjun Cai. 2021. A joint training dual-mrc framework for aspect based sentiment analysis. CoRR, abs/2101.00816. Giovanni Paolini, Ben Athiwaratkun, Jason Krone, Jie Ma, Alessandro Achille, RISHITA ANUBHAI, Ci- cero Nogueira dos Santos, Bing Xiang, and Stefano Soatto. 2021. Structured prediction as translation In Interna- between augmented natural languages. tional Conference on Learning Representations. Haiyun Peng, Lu Xu, Lidong Bing, Fei Huang, Wei Lu, and Luo Si. 2020. Knowing what, how and why: A near complete solution for aspect-based sentiment In The Thirty-Fourth AAAI Conference analysis. on Artiﬁcial Intelligence, AAAI 2020, pages 8600– 8607. Maria Pontiki, Dimitris Galanis, Haris Papageor- giou, Ion Androutsopoulos, Suresh Manandhar, Mo- hammad Al-Smadi, Mahmoud Al-Ayyoub, Yanyan Zhao, Bing Qin, Orphée De Clercq, Véronique Hoste, Marianna Apidianaki, Xavier Tannier, Na- talia V. Loukachevitch, Evgeniy V. Kotelnikov, Núria Bel, Salud María Jiménez Zafra, and Gülsen Eryigit. 2016. Semeval-2016 task 5: Aspect based In Proceedings of the 10th sentiment analysis. International Workshop on Semantic Evaluation, SemEval@NAACL-HLT 2016, pages 19–30. Maria Pontiki, Dimitris Galanis, Haris Papageorgiou, Suresh Manandhar, and Ion Androutsopoulos. 2015. Semeval-2015 task 12: Aspect based sentiment anal- ysis. In SemEval@NAACL-HLT, pages 486–495. Maria Pontiki, Dimitris Galanis, John Pavlopoulos, Ion Androutsopoulos, and Semeval-2014 task In Se- Harris Papageorgiou, Suresh Manandhar. 2014. 4: Aspect based sentiment analysis. mEval@COLING 2014, pages 27–35. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a uniﬁed text-to-text trans- former. J. Mach. Learn. Res., 21:140:1–140:67. Sebastian Ruder, Parsa Ghaffari, and John G. Breslin. 2016. A hierarchical model of reviews for aspect- In Proceedings of the based sentiment analysis. 2016 Conference on Empirical Methods in Natu- ral Language Processing, EMNLP 2016, pages 999– 1005. Chi Sun, Luyao Huang, and Xipeng Qiu. 2019. Uti- lizing BERT for aspect-based sentiment analysis via In Proceedings of constructing auxiliary sentence. the 2019 Conference of the North American Chap- ter of the Association for Computational Linguistics: Mi Zhang and Tieyun Qian. 2020. Convolution over hierarchical syntactic and lexical graphs for aspect level sentiment analysis. In Proceedings of the 2020 Conference on Empirical Methods in Natural Lan- guage Processing, EMNLP 2020, pages 3540–3549. Wenxuan Zhang, Xin Li, Yang Deng, Lidong Bing, and Wai Lam. 2021. Towards generative aspect- In Proceedings of the based sentiment analysis. 59th Annual Meeting of the Association for Com- putational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021, pages 504–510. He Zhao, Longtao Huang, Rong Zhang, Quan Lu, and Hui Xue. 2020. Spanmlt: A span-based multi-task learning framework for pair-wise aspect and opinion terms extraction. In Proceedings of the 58th Annual Meeting of the Association for Computational Lin- guistics, ACL 2020, pages 3239–3248. Xinjie Zhou, Xiaojun Wan, and Jianguo Xiao. 2015. Representation learning for aspect category detec- tion in online reviews. In Proceedings of the Twenty- Ninth AAAI Conference on Artiﬁcial Intelligence, pages 417–424. Human Language Technologies, NAACL-HLT 2019, pages 380–385. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Pro- cessing Systems 30: Annual Conference on Neural Information Processing Systems 2017, pages 5998– 6008. Hai Wan, Yufei Yang, Jianfeng Du, Yanan Liu, Kunxun Qi, and Jeff Z. Pan. 2020. Target-aspect-sentiment joint detection for aspect-based sentiment analysis. In The Thirty-Fourth AAAI Conference on Artiﬁcial Intelligence, AAAI 2020, pages 9122–9129. Wenya Wang, Sinno Jialin Pan, Daniel Dahlmeier, and Xiaokui Xiao. 2017. Coupled multi-layer attentions In for co-extraction of aspect and opinion terms. Proceedings of the Thirty-First AAAI Conference on Artiﬁcial Intelligence, pages 3316–3322. Yequan Wang, Minlie Huang, Xiaoyan Zhu, and Li Zhao. 2016. Attention-based LSTM for aspect- In Proceedings of level sentiment classiﬁcation. the 2016 Conference on Empirical Methods in Natu- ral Language Processing, EMNLP 2016, pages 606– 615. Chao Wu, Qingyu Xiong, Hualing Yi, Yang Yu, Qiwu Zhu, Min Gao, and Jie Chen. 2021. Multiple- element joint detection for aspect-based sentiment analysis. Knowledge-Based Systems, page 107073. Zhen Wu, Chengcan Ying, Fei Zhao, Zhifang Fan, Xinyu Dai, and Rui Xia. 2020. Grid tagging scheme for aspect-oriented ﬁne-grained opinion extraction. In Findings of the Association for Computational Linguistics: EMNLP 2020. Hu Xu, Bing Liu, Lei Shu, and Philip S. Yu. 2018. Dou- ble embeddings and cnn-based sequence labeling for aspect extraction. In Proceedings of the 56th Annual Meeting of the Association for Computational Lin- guistics, ACL 2018, pages 592–598. Lu Xu, Hao Li, Wei Lu, and Lidong Bing. 2020. Position-aware tagging for aspect sentiment triplet extraction. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Process- ing, EMNLP 2020, pages 2339–2349. Hang Yan, Junqi Dai, Tuo Ji, Xipeng Qiu, and Zheng Zhang. 2021. A uniﬁed generative framework for aspect-based sentiment analysis. In Proceedings of the 59th Annual Meeting of the Association for Com- putational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021, pages 2416–2429. Yichun Yin, Furu Wei, Li Dong, Kaimeng Xu, Ming Zhang, and Ming Zhou. 2016. Unsupervised word and dependency path embeddings for aspect term ex- In Proceedings of the Twenty-Fifth Inter- traction. national Joint Conference on Artiﬁcial Intelligence, IJCAI 2016, pages 2979–2985. 