PASTE : Tagging-Free Decoding Framework Using Pointer Networks Aspect Sentiment Triplet Extraction Rajdeep Mukherjee∗ , Tapas Nayak∗ , Yash Butala , Sourangshu Bhattacharya Pawan Goyal Department Computer Science Engineering , IIT Kharagpur , India { rajdeep     , yashbutala } @ iitkgp.ac.in , tnk  .   @ gmail.com , { sourangshu , pawang } @ cse.iitkgp.ac.in Abstract Aspect Sentiment Triplet Extraction ( ASTE ) deals extracting opinion triplets , consist- ing opinion target aspect , associ- ated sentiment , corresponding opinion term/span explaining rationale behind sentiment . Existing research efforts ma- jorly tagging-based . Among methods tak- ing sequence tagging approach , fail capture strong interdependence three opinion factors , whereas others fall short identifying triplets overlapping aspect/opinion spans . recent grid tagging approach hand fails capture span-level semantics predicting sen- timent aspect-opinion pair . Differ- ent , present tagging-free so- lution task , addressing lim- itations existing works . adapt encoder-decoder architecture Pointer Network-based decoding framework gen- erates entire opinion triplet time step thereby making solution end-to-end . Interactions aspects opinions effectively captured decoder con- sidering entire detected spans pre- dicting connecting sentiment . Extensive experiments several benchmark datasets es- tablish better efﬁcacy proposed ap- proach , especially recall , predict- ing multiple aspect/opinion-overlapped triplets review sentence . re- port results without BERT also demonstrate utility domain- speciﬁc BERT post-training task .   Introduction Aspect-based Sentiment Analysis ( ABSA ) broad umbrella several ﬁne-grained sentiment analysis tasks , extensively studied since humble beginning SemEval      ( Pon- tiki et al. ,     a ) . Overall , task revolves around ∗Equal contribution Sent   : Triplets Sent   : Triplets ﬁlm good , could better . [ Aspect ; Opinion ; Sentiment ] (   ) ﬁlm ; good ; positive (   ) ﬁlm ; could better ; negative weather gloomy , food tasty . (   ) weather ; gloomy ; negative (   ) food ; tasty ; positive Table   : triplets ( opinion triplets ) present review sentences . Examples Aspect-Opinion-Sentiment automatically extracting opinion targets as- pects discussed review sentences , along sentiments expressed towards . Early efforts Aspect-level Sentiment Classiﬁcation ( Tay et al. ,      ; Li et al. ,     a ; Xue Li ,      ) focus predicting sentiment polarities given aspects . However , real-world sce- nario , aspects may known a-priori . Works End-to-End ABSA ( Li et al. ,      ; et al. ,      ; Chen Qian ,      ) thus focus extracting aspects well corresponding sentiments si- multaneously . methods however cap- ture reasons behind expressed sentiments , could otherwise provide valuable clues effective extraction aspect-sentiment pairs . Consider two examples shown Table   . ﬁrst sentence , sentiment associated aspect ﬁlm , changes depending connect- ing opinion phrases ; good suggesting positive sentiment , could better indicating negative sentiment . Hence , simply extracting pairs ﬁlm-positive , ﬁlm-negative without additionally capturing reasoning phrases may confuse reader . second sentence , opinion term gloomy higher probability associated weather , food . therefore observe three elements opin- ion factors opinion triplet strongly inter- dependent . order offer complete picture discussed , sentiment , , ( Peng et al. ,      ) deﬁned task Aspect Sentiment Triplet Extraction ( ASTE ) . Given opinionated sentence , deals ex- tracting three elements : aspect term/span , opinion term/span , connecting senti- ment form opinion triplets shown Table   . noted given sentence might contain multiple triplets , may share aspect opinion spans ( e.g. , two triplets Sent .   Table   share aspect ﬁlm ) . efﬁcient solution task must therefore able handle challenging data points . Peng et al . (      ) propose two-stage pipeline framework . ﬁrst stage , extract aspect- sentiment pairs opinion spans using two sepa- rate sequence-tagging tasks , former leveraging uniﬁed tagging scheme proposed ( Li et al. ,      ) , later based BIEOS  tagging scheme . second stage , pair extracted aspect opinion spans , use MLP-based classiﬁer determine validity generated triplet . Zhang et al . (      ) propose multi-task framework jointly detect aspects , opinions , sentiment dependencies . Although decouple sentiment prediction task aspect extraction , use two separate sequence taggers ( BIEOS-based ) detect aspect opinion spans isolation predicting con- necting sentiment . methods however break interaction aspects opinions extraction process . former ad- ditionally suffers error propagation problem , latter , relying word-level sentiment depen- dencies , guarantee sentiment consistency multi-word aspect/opinion spans . Xu et al . (     b ) propose novel position-aware tagging scheme ( extending BIEOS tags ) bet- ter capture interactions among three opin- ion factors . One model variants however detect aspect-overlapped triplets , identify opinion-overlapped triplets . Hence , need ensemble two variants trained handling cases . Wu et al . (      ) try address limitation proposing novel grid tagging scheme-based approach . However , end predicting relationship every possible word pair , irrespective syntactically connected , thereby impacting span-level sentiment consistency guarantees . Different tagging-based methods ,  BIOES commonly used tagging scheme sequence labeling tasks , denotes “ begin , inside , outside , end single ” respectively . propose investigate utility tagging- free scheme task . innovation lies formulating ASTE structured prediction prob- lem . Taking motivation similar sequence- to-sequence approaches proposed joint entity- relation extraction ( Nayak Ng ,      ; Chen et al. ,      ) , semantic role labeling ( Fei et al. ,      ) etc. , propose PASTE , Pointer Network- based encoder-decoder architecture task ASTE . pointer network effectively captures aspect-opinion interdependence detect- ing respective spans . decoder learns model span-level interactions predict- ing connecting sentiment . entire opinion triplet thus decoded every time step , thereby making solution end-to-end . note how- ever , aspect opinion spans varying lengths , makes triplet decod- ing process challenging . ensuring uniformity , also propose position-based representation scheme suitably exploited proposed architecture . , opinion triplet repre- sented  -point tuple , consisting start end positions aspect opinion spans , sentiment ( POS/NEG/NEU ) expressed towards aspect . summarize contributions : • present end-to-end tagging-free solution task ASTE addresses limita- tions previous tagging-based methods . proposed architecture , PASTE , exploits aspect-opinion interdependence span detection process , also models span-level interactions sentiment prediction , thereby truly capturing inter-relatedness be- tween three elements opinion triplet . • propose position-based scheme uni- formly represent opinion triplet , irrespective varying lengths aspect opinion spans . • Extensive experiments ASTE-Data-V  dataset ( Xu et al. ,     b ) establish overall superiority PASTE strong state-of-the- art baselines , especially predicting multiple and/or overlapping triplets . also achieve sig- niﬁcant (   .  % ) recall gains process .   Approach Given task ASTE , objective jointly extract three elements opinion triplet , i.e. , aspect span , associated sentiment , Figure   : Dependency Parse Tree example review sentence Table   Sentence Target Triplets Overlapping Triplets Ambience good , main course service disappointing . (         POS ) (           NEG ) (           NEG ) (           NEG ) (           NEG ) Table   : Triplet representation Pointer-network based decoding corresponding opinion span , modeling interdependence . Towards goal , ﬁrst intro- duce triplet representation scheme , followed problem formulation . present Pointer Network-based decoding framework , PASTE , ﬁnally discuss model variants . exhaustive experiments , investigate utility approach present performance comparison strong state-of-the-art baselines .  .  Triplet Representation order address limitations BIEOS tagging-based approaches facilitate joint ex- traction three elements opinion triplet , represent triplet  -point tuple , consist- ing start end positions aspect span , start end positions opinion span , sentiment ( POS/NEG/NEU ) expressed towards aspect . allows us model relative context aspect-opinion pair possible extracted isolation . helps jointly extract sentiment asso- ciated pair . example sentence triplets represented proposed scheme shown Table   . may noted , scheme easily represent triplets overlapping aspect opinion spans , possibly varying lengths .  .  Problem Formulation , eap ) , ( sop formally deﬁne ASTE task , given re- view sentence = { w  , w  , ... , wn } n words , goal extract set opinion triplets ) , sentii ] } |T | = { ti | ti = [ ( sap i=  ,  ti represents ith triplet |T | repre- sents length triplet set . ith triplet , eap sap respectively denote start end positions constituent aspect span , sop   eop respectively denote start end positions  constituent opinion span , sentii repre- , eop  sents sentiment polarity associated . , sentii ∈ { P OS , N EU , N EU } , P OS , N EG , N EU respectively repre- sent positive , negative , neutral sentiments .  .  PASTE Framework present PASTE , Pointer network- based decoding framework task Aspect Sentiment Triplet Extraction . Figure   gives overview proposed architecture .  . .  Sentence Encoder previously motivated , association aspect , opinion , connecting senti- ment highly contextual . factor note- worthy sentences containing multiple triplets with/without varying sentiment polarities and/or overlapping aspect/opinion spans . Long Short Memory Networks ( LSTMs ) ( Hochreiter Schmidhuber ,      ) known context modeling capabilities . Similar ( Nayak Ng ,      ; Chen et al. ,      ) , employ Bi- directional LSTM ( Bi-LSTM ) encode input sentences . use pre-trained word vectors di- mension dw obtain word-level features . note Figure   aspect spans often characterized noun phrases , whereas opinion spans often composed adjective phrases . Re- ferring dependency tree ﬁgure , aspect opinion spans belonging opinion triplet often connected head word . observations motivate us use part-of-speech ( POS ) dependency- based ( DEP ) features word . speciﬁcally , use two embedding layers , Epos ∈ R|POS| × dpos , Edep ∈ R|DEP| × ddep obtain POS DEP-features dimensions dpos ddep respectively , |POS| |DEP| representing length POS-tag DEP-tag Figure   : Model architecture PASTE , Pointer Network-based decoding framework ASTE . sets input sentences . three features concatenated obtain input vector representa- tion xi ∈ Rdw+dpos+ddep corresponding ith word given sentence = { w  , w  , ... , wn } . vectors passed Bi-LSTM ∈ Rdh . obain contextualized representations , dh represents hidden state dimension triplet generating LSTM decoder detailed next section . Accordingly , hidden state di- mension forward backward LSTM Bi-LSTM encoder set dh/  . BERT-based variant model , Bi- LSTM gets replaced BERT ( Devlin et al. ,      ) sentence encoder . pre-trained word vec- tors accordingly replaced BERT token em- beddings . append POS DEP fea- tures vectors    -dim . token-level outputs ﬁnal layer BERT .  . .  Pointer Network-based Decoder Referring Figure   , opinion triplets decoded using LSTM-based Triplet Decoder , takes account history previously generated pairs/tuples aspect opinion spans , order avoid repetition . time step , generates ∈ Rdh used hidden representation hD two Bi-LSTM + FFN-based Pointer Networks respectively predict aspect opinion spans , exploiting interdependence . tuple representation tupt thus obtained concatenated hD passed FFN-based Senti- ment Classiﬁer predict connecting sentiment , thereby decoding entire opinion triplet tth time step . elaborate component proposed decoder framework greater depth : Span Detection Pointer Networks pointer network consists Bi-LSTM , hidden dimension dp , followed two feed- forward layers ( FFN ) top respectively predict start end locations entity span . use two pointer networks produce tuple hidden vectors corresponding aspect opinion spans triplet decoded time step t. concatenate hD encoder hidden state vectors pass input ﬁrst Bi-LSTM . output hidden state vector corresponding ith token sentence thus obtained simultaneously fed two FFNs sigmoid generate pair scores range     . repeating process tokens , normalized probabilities ith token start end positions aspect span ( sp  respectively ) obtained using softmax operations two sets scores thus generated . p  refers ﬁrst pointer net- work . Similar scores corresponding opinion span obtained using second pointer net- work , p  ; difference apart hD , also concatenate output vectors ﬁrst Bi-LSTM encoder hidden states  pass input second Bi-LSTM . helps us model interdependence aspect-opinion pair . scores used ob- tain hidden state representations apt ∈ R dp opt ∈ R dp corresponding pair aspect opinion spans thus predicted time step t. request readers kindly refer appendix elaborate implementation details . ep   introduce term generation direc- tion refers order gener- ate hidden representations two entities , i.e . aspect opinion spans . allows us deﬁne two variants model . variant discussed far uses p  detect aspect span predicting opinion span using p  , henceforth referred PASTE-AF ( AF stands aspect ﬁrst ) . Similarly , obtain second variant PASTE-OF ( opinion ﬁrst ) reversing generation direction . two components model remain variants . Triplet Decoder Attention Modeling decoder consists LSTM hidden dimension dh whose goal generate se- quence opinion triplets , , deﬁned Section  .  . Let tupt = apt ( cid:    ) opt ; tupt ∈ R dp denote tuple ( aspect , opinion ) representation obtained pointer networks time step t. , tupprev = ( cid:   ) j < tupj ; tup  = ( cid:    )   ∈ R dp repre- sents cumulative information tuples predicted current time step . obtain attention-weighted context representation ∈ Rdh ) using input sentence time step ( sE Bahdanau et al . (      ) Attention  . order pre- vent decoder generating tuple , pass tupprev input LSTM along ∈ Rdh , hidden repre- sE  sentation predicting triplet time step : generate hD = LSTM ( sE hD ( cid:    ) tupprev , hD t−  ) Sentiment Classiﬁer Finally , concatenate tupt , hD pass  feed-forward network soft- max generate normalized probabilities { P OS , N EG , N EU } ∪ { N E } , thereby pre- dicting sentiment label sentit current triplet . Interaction entire predicted spans aspect opinion thus captured sentiment identiﬁcation . P OS , N EG , N EU respectively represent positive , negative , neutral sentiments . N E dummy sentiment acts implicit stopping criteria decoder . training , triplet sen- timent N E predicted , ignore subse- quent predictions , none contribute loss . Similarly , inference , ignore triplet predicted N E sentiment .  Please refer appendix implementation details .  . .  Training training model , minimize sum negative log-likelihood loss classifying sen- timent four pointer locations corresponding aspect opinion spans : L = −   × J  ( cid:   ) J ( cid:   ) [ log ( sm ap , j · em ap , j ) m=  + log ( sm j=  op , j · em op , j ) + log ( senm j ) ] , represents mth training instance batch size , j represents jth decod- ing time step J length longest target sequence among instances current batch . sp , ep ; p ∈ { ap , op } sen respectively represent softmax scores corresponding true start end positions aspect opin- ion spans associated true sentiment label . , sop , eop Inferring Triplets , eap   . .  Let sap ; ∈ [   , n ] represent ob-  tained pointer probabilities ith token given sentence ( length n ) start end positions aspect span opinion span re- spectively . First , choose start ( j ) end ( k ) positions aspect span constraint   ≤ j ≤ k ≤ n sap k maximized . choose start end positions opinion span similarly overlap aspect span . Thus , obtain one set four pointer probabilities . repeat process obtain second set , time choosing opinion span aspect span . Finally , choose set ( aspect opinion spans ) gives higher product four probabilities . j × eap   Experiments  .  Datasets Evaluation Metrics conduct experiments ASTE-Data- V  dataset created Xu et al . (     b ) . de- rived ASTE-Data-V  ( Peng et al. ,      ) presents challenging scenario   .   % sentences containing triplets overlap- ping aspect opinion spans . dataset contains triplet-annotated sentences two domains : lap- top restaurant , corresponding original datasets released SemEval Challenge ( Pon- tiki et al. ,     a , b , c ) . noted opinion term annotations originally de- rived ( Fan et al. ,      ) .   Lap belongs Dataset Train Dev Test # Pos .               Lap # Neg .             # Neu .           # Pos .                Rest # Neg .             # Neu .           # Pos .               Rest # Neg .            # Neu .          # Pos .                Rest # Neg .           # Neu .          Restaurant ( ) # Neg .              # Neu .            # Pos .               Table   : ASTE-Data-V  Statistics : # Triplets various sentiment polarities Laptop Restaurant Single Multi MultiPol Overlap # Sent . Single Multi MultiPol Overlap # Sent .                                                                                                                                                                 Dataset Train Dev Test Total Table   : Statistics Laptop Restaurant datasets ASTE-Data-V  : Single Multi respectively represent # sentences single multiple triplets . MultiPol Overlap subsets Multi . MultiPol representing # sentences containing least two triplets different sentiment polarities . Overlap represents # sentences aspect/opinion overlapped triplets . # Sent . represents total . sentences overall . laptop domain henceforth referred Laptop .   Rest ,   Rest ,   Rest belong restaurant domain . dataset comes pre-deﬁned split training , development , test sets . Similar prior works , report results individual datasets . Additionally , also conduct experiments combined restaurant dataset , henceforth referred Restaurant . Tables     present dataset statistics . consider precision , recall , micro-F  evaluation metrics triplet extraction task . predicted triplet considered true positive three predicted elements exactly match ground-truth opinion triplet .  .  Experimental Setup non-BERT experiments , word embeddings initialized ( kept trainable ) using pre-trained    -dim . Glove vectors ( Pennington et al. ,      ) , accordingly dw set    . dpos ddep set    . dh set     , accordingly hidden state dimensions LSTMs ( backward forward ) Bi-LSTM-based encoder set     . dp set     . BERT experiments , uncased version pre-trained BERT-base ( Devlin et al. ,      ) ﬁne-tuned encode sentence . model variants trained end-to-end Tesla P   -PCIE   GB GPU Adam optimizer ( learning rate :   −  , weight decay :   −  ) . dropout rate  .  applied embeddings avoid overﬁtting  . make codes datasets publicly available  .  Please refer appendix details .  https : //github.com/rajdeep   /PASTE/  .  Baselines • Wang et al . (      ) ( CMLA ) Dai Song (      ) ( RINANTE ) propose different methods co-extract aspects opinion terms re- view sentences . Li et al . (      ) propose uni- ﬁed tagging scheme-based method extracting opinion target-sentiment pairs . Peng et al . (      ) modiﬁes methods jointly extract targets sentiment , opinion spans . applies MLP-based classiﬁer determine validity possible generated triplets . modiﬁed versions referred CMLA+ , RINANTE+ , Li-uniﬁed-R , respectively . • Peng et al . (      ) propose BiLSTM+GCN- based approach co-extract aspect-sentiment pairs , opinion spans . use inference strategy conﬁrm cor- rectness generated triplets . • OTE-MTL ( Zhang et al. ,      ) uses multi- task learning framework jointly detect aspects , opinions , sentiment dependencies . • JET ( Xu et al. ,     b ) ﬁrst end-to-end approach task ASTE leverages novel position-aware tagging scheme . One variants , JETt , however handle aspect-overlapped triplets . Similarly , JETo , can- handle opinion-overlapped triplets . • GTS ( Wu et al. ,      ) models ASTE novel grid-tagging task . However , given predicts sentiment relation possible word pairs , uses relaxed ( majority-based ) matching criteria determine ﬁnal triplets . Model CMLA+ RINANTE+ Li-uniﬁed-R ( Peng et al. ,      ) JETo ( =   ) JETo ( =   ) OTE-MTL GTS-BiLSTM w/o DE PASTE-AF PASTE-OF BERT JETo ( =   ) JETo ( =   ) GTS-BERT PASTE-AF w/ BERT-PT PASTE-OF w/ BERT-PT P .  .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .    Laptop F   .     .     .     .     .     .     .     .     .     .    R .  .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .    Dev F  - - - -  .     .     .     .     .     .     .     .     .     .     .     .     .    P . - - - -  .    -  .     .     .     .     .    -  .     .     .     .     .    Restaurant R . - - - -  .    -  .     .     .     .    F  - - - -  .    -  .     .     .     .     .    -  .     .     .     .     .     .    -  .     .     .     .     .    Dev F  - - - -  .    -  .     .     .     .     .    -  .     .     .     .     .    Table   : Comparative results Laptop (   Lap ) Restaurant datasets ASTE-Data-V  . Bolded values represent best F  scores . Underlined scores obtained Post-trained BERT . Model P . CMLA+  .    RINANTE+  .     .    Li-uniﬁed-R  .    ( Peng et al. ,      )  .    OTE-MTL JETo ( =   )  .    GTS-BiLSTM w/o DE  .     .    PASTE-AF  .    PASTE-OF BERT JETo ( =   ) GTS-BERT PASTE-AF w/ BERT-PT PASTE-OF w/ BERT-PT  .     .     .     .     .     .      Rest F   .     .     .     .     .     .     .     .     .    R .  .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .    Dev F  - - - -  .     .     .     .     .     .     .     .     .     .     .    P .  .     .     .     .     .     .     .     .     .     .     .     .     .     .     .      Rest F   .     .     .     .     .     .     .     .     .    R .  .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .    Dev F  - - - -  .     .     .     .     .     .     .     .     .     .     .    P .  .     .     .     .     .     .     .     .     .     .     .     .     .     .     .      Rest F   .     .     .     .     .     .     .     .     .    R .  .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .    Dev F  - - - -  .     .     .     .     .     .     .     .     .     .     .    Table   : Comparative results individual restaurant datasets ASTE-Data-V   .  Experimental Results training model variants , best weights selected based F  scores development set . report median scores   runs experiment . Performance comparisons Lap- top (   Lap ) combined Restaurant datasets reported Table   , whereas individual restaurant datasets reported Table   . tables divided two sections ; for- mer comparing results without BERT , latter comparing BERT . scores CMLA+ , RINANTE+ , Li-uniﬁed-R , ( Peng et al. ,      ) taken Xu et al . (     b ) . replicate results OTE-MTL ASTE-Data- V  report average scores    runs experiment . JET , compare best reported results individual datasets ; i.e . JETo ( =   )   Lap ( w/o BERT ) , JETo ( =   )   Lap ( w/ BERT ) , JETo ( =   )   Rest ,   Rest ,   Rest ( w/ w/o BERT ) . How- ever , owing resource constraints known opti- mization issues codes , could repli- cate results Restaurant dataset beyond =   ( w/ w/o BERT ) . GTS uses dou- ble embeddings ( Xu et al. ,      ) ( general Glove vectors + domain-speciﬁc embeddings trained fastText ) . fair comparison , replicate results without using domain-speciﬁc embed- dings ( DE ) . w/ w/o BERT , report median scores   runs experiment . also report F  scores development set corresponding test set results . Model JETo ( =   ) OTE-MTL GTS-BiLSTM w/o DE PASTE-AF PASTE-OF BERT JETo ( =   ) GTS-BERT PASTE-AF PASTE-OF Laptop Single Multi MultiPol Overlap  .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .    Restaurant Single Multi MultiPol Overlap  .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .     .    Table   : Comparison F  scores different splits Laptop Restaurant datasets ASTE-Data-V  Table   , variants , PASTE-AF PASTE-OF , perform comparably sub- stantially outperform non-BERT baselines . Laptop , achieve   .  % F  gains OTE- MTL , whereas Restaurant , obtain  .  % F  gains GTS-BiLSTM . draw similar conclu- sions Table   , except narrowly outperformed JETo ( =   )   Rest . better performance may attributed better Recall scores around   .  % recall gains ( av- eraged across variants ) respective strongest baselines ( terms F  ) Laptop Restaurant datasets . observation es- tablishes better efﬁcacy PASTE modeling interactions three opinion factors able identify ground-truth triplets data , compared baselines . BERT , comfortably outperform JET datasets . Although narrowly beat GTS-BERT Laptop , outperforms us restaurant datasets . owing fact GTS-BERT obtains substantial improvement scores GTS since grid-tag prediction task pre-training tasks BERT dis- criminative nature . hand , observe huge jumps ( F  gains  .  % ,  .  % ,  .  % ,  .  % Laptop , Rest   , Rest   , Rest   datasets respectively , noticeably improvement datasets lesser training data ; gains Restaurant ) since BERT known unsuitable generative tasks . envisage improve model replacing BERT BART ( Lewis et al. ,      ) , strong sequence-to-sequence pretrained model NLG tasks . Finally , motivated Xu et al . (      ,     a ) , also demonstrate utility leveraging domain- speciﬁc language understanding task reporting results BERT-PT ( task-agnostic post-training pre-trained BERT domain- speciﬁc data ) tables . achieve substantial performance improvement , use scores draw conclusions order ensure fair comparison baselines .   Analysis & Discussion  .  Robustness Analysis order better understand relative advan- tage proposed approach compared baselines opinion triplet extraction task , investigate reason behind better recall scores , Table   compare F  scores various splits test sets de- ﬁned Table   . observe core architecture ( w/o BERT ) , PASTE consistently out- performs baselines Laptop Restau- rant datasets comes handling sentences multiple triplets , especially overlap- ping aspect/opinion spans . establishes fact PASTE better previous tagging-based approaches terms modeling aspect-opinion span-level interdependence extraction process . important observation con- sidering industry-readiness ( Mukherjee et al. ,     b ) proposed approach since model robust towards challenging data instances . however perform poorly comes identi- fying triplets varying sentiment polarities sentence . understandable since utilize specialized sentiment mod- eling technique . future , propose utilize word-level Valence , Arousal , Dominance scores ( Mukherjee et al. ,     a ) additional features better capture sentiment opinion phrase . work , propose new perspective solve ASTE investigating utility tagging- free scheme , prior tagging-based methods . Hence , becomes imperative analyze perform terms identifying individual Dataset Laptop Restaurant Model JETo ( =   ) OTE-MTL GTS-BiLSTM w/o DE PASTE-AF PASTE-OF JETo ( =   ) OTE-MTL GTS-BiLSTM w/o DE PASTE-AF PASTE-OF Aspect R .  .     .     .     .     .     .     .     .     .     .    P .  .     .     .     .     .     .     .     .     .     .    F   .     .     .     .     .     .     .     .     .     .    Opinion R .  .     .     .     .     .     .     .     .     .     .    P .  .     .     .     .     .     .     .     .     .     .    F   .     .     .     .     .     .     .     .     .     .    Sentiment % Acc .  .     .     .     .     .     .     .     .     .     .    Table   : Comparative results aspect , opinion sentiment prediction Laptop Restaurant datasets Dataset Laptop Restaurant Model PASTE-AF P .  .    - POS & DEP  .     .    w/ Random  .    - POS & DEP  .     .    w/ Random PASTE-OF R .  .     .     .     .     .     .    F  % F  ↓  .     .     .     .     .     .    -  .  %   .  % -  .  %  .  % Table   : Ablation Results elements opinion triplet . Table   presents comparison . encouraging note substantially outperform baselines aspect opinion span detection sub-tasks . How- ever , highlighted , outperformed comes sentiment detection .  .  Ablation Study : Since Decoder learns decode sequence triplets left right without repetition , training models sort target triplets order generation direction ; i.e . train- ing PASTE-AF/PASTE-OF , target triplets sorted ascending order aspect/opinion start positions . ablation , sort triplets ran- domly training models report ob- tained scores Table   . average drop  .  % F  scores model variants establish importance sorting triplets training models . experimenting without POS DEP features , observe average drop  .  % F  scores , thereby demonstrating utility ASTE task . experiment- ing BERT , although features helped Laptop Rest   datasets , overall observe signiﬁcant improvement .   Related Works ABSA collection several ﬁne-grained sen- timent analysis tasks , Aspect Extraction ( Li et al. ,     b ,      ) , Aspect-level Sentiment Classiﬁcation ( Li et al. ,     a ; Xue Li ,      ) , Aspect-oriented Opinion Extraction ( Fan et al. ,      ) , E E-ABSA ( Li et al. ,      ; et al. ,      ) , Aspect-Opinion Co-Extraction ( Wang et al. ,      ; Dai Song ,      ) . However , none works offer complete picture aspects discussed . Towards end , Peng et al . (      ) recently coined task Aspect Senti- ment Triplet Extraction ( ASTE ) , proposed  -stage pipeline solution . recent end-to-end approaches OTE-MTL ( Zhang et al. ,      ) , GTS ( Wu et al. ,      ) fail guarantee senti- ment consistency multi-word aspect/opinion spans , since depend word-pair dependen- cies . JET ( Xu et al. ,     b ) hand re- quires two different models trained detect aspect-overlapped opinion-overlapped triplets . Different tagging-based methods , propose tagging-free solution ASTE task .   Conclusion investigate utility tagging-free scheme task Aspect Sentiment Triplet Extrac- tion using Pointer network-based decoding frame- work . Addressing limitations previous tagging-based methods , proposed architecture , PASTE , exploits aspect-opinion inter- dependence span detection process , also models span-level interactions senti- ment prediction , thereby truly capturing inter- relatedness three elements opin- ion triplet . demonstrate better efﬁcacy PASTE , especially recall , predicting mul- tiple and/or overlapping triplets , experiment- ing ASTE-Data-V  dataset . Acknowledgements research supported IMPRINT-  , Science Engineering Research Board ( SERB ) , India . References Dzmitry Bahdanau , Kyunghyun Cho , Yoshua Ben- gio .      . Neural machine translation jointly  rd Inter- learning align translate . national Conference Learning Representations , ICLR      , San Diego , CA , USA , May  -  ,      , Conference Track Proceedings . Yubo Chen , Yunqi Zhang , Changran Hu , Yongfeng Huang .      . Jointly extracting explicit implicit relational triples reasoning pattern enhanced bi- Proceedings      nary pointer network . Conference North American Chapter Association Computational Linguistics : Human Language Technologies , pages     –     , Online . Association Computational Linguistics . Zhuang Chen Tieyun Qian .      . Relation-aware collaborative learning uniﬁed aspect-based sen- timent analysis . Proceedings   th Annual Meeting Association Computational Lin- guistics , pages     –     , Online . Association Computational Linguistics . Hongliang Dai Yangqiu Song .      . Neural as- pect opinion term extraction mined rules weak supervision . Proceedings   th An- nual Meeting Association Computational Linguistics , pages     –     , Florence , Italy . Asso- ciation Computational Linguistics . Jacob Devlin , Ming-Wei Chang , Kenton Lee , Kristina Toutanova .      . BERT : Pre-training deep bidirectional transformers language under- Proceedings      Conference standing . North American Chapter Association Computational Linguistics : Human Language Technologies , Volume   ( Long Short Papers ) , pages     –     , Minneapolis , Minnesota . Associ- ation Computational Linguistics . Zhifang Fan , Zhen Wu , Xin-Yu Dai , Shujian Huang , Jiajun Chen .      . Target-oriented opinion words extraction target-fused neural sequence Proceedings      Conference labeling . North American Chapter Association Computational Linguistics : Human Language Technologies , Volume   ( Long Short Papers ) , pages     –     , Minneapolis , Minnesota . Associ- ation Computational Linguistics . Hao Fei , Fei Li , Bobo Li , Donghong Ji .      . Encoder-decoder based uniﬁed semantic role label- ing label-aware syntax . volume    , pages      –      . Ruidan , Wee Sun Lee , Hwee Tou Ng , Daniel Dahlmeier .      . interactive multi-task learn- ing network end-to-end aspect-based sentiment analysis . Proceedings   th Annual Meet- ing Association Computational Linguis- tics , pages    –    , Florence , Italy . Association Computational Linguistics . Sepp Hochreiter Jürgen Schmidhuber .      . Neural Comput. , Long short-term memory .   (   ) :    –     . Diederik P. Kingma Jimmy Ba .      . Adam :  rd Inter- method stochastic optimization . national Conference Learning Representations , ICLR      , San Diego , CA , USA , May  -  ,      , Conference Track Proceedings . Mike Lewis , Yinhan Liu , Naman Goyal , Mar- jan Ghazvininejad , Abdelrahman Mohamed , Omer Levy , Veselin Stoyanov , Luke Zettlemoyer .      . BART : Denoising sequence-to-sequence pre- training natural language generation , translation , comprehension . Proceedings   th An- nual Meeting Association Computational Linguistics , pages     –     , Online . Association Computational Linguistics . Kun Li , Chengbo Chen , Xiaojun Quan , Qing Ling , Yan Song .      . Conditional augmentation aspect term extraction via masked sequence-to- sequence generation . Proceedings   th An- nual Meeting Association Computational Linguistics , pages     –     , Online . Association Computational Linguistics . Xin Li , Lidong Bing , Wai Lam , Bei Shi .     a . Transformation networks target-oriented senti- ment classiﬁcation . Proceedings   th An- nual Meeting Association Computational Linguistics ( Volume   : Long Papers ) , pages    –     , Melbourne , Australia . Association Compu- tational Linguistics . Xin Li , Lidong Bing , Piji Li , Wai Lam .      . uniﬁed model opinion target extraction target sentiment prediction . Thirty-Third AAAI Con- ference Artiﬁcial Intelligence , AAAI      , Thirty-First Innovative Applications Artiﬁcial In- telligence Conference , IAAI      , Ninth AAAI Symposium Educational Advances Artiﬁcial Intelligence , EAAI      , Honolulu , Hawaii , USA , January    - February   ,      , pages     –     . AAAI Press . Xin Li , Lidong Bing , Piji Li , Wai Lam , Zhimou Yang .     b . Aspect term extraction history attention selective transformation . Proceed- ings Twenty-Seventh International Joint Con- ference Artiﬁcial Intelligence , IJCAI      , July   -   ,      , Stockholm , Sweden , pages     –     . ijcai.org . Rajdeep Mukherjee , Atharva Naik , Sriyash Poddar , So- ham Dasgupta , Niloy Ganguly .     a . Under- standing role affect dimensions detecting emotions tweets : multi-task approach .  Proceedings   th International ACM SIGIR Conference Research Development Infor- mation Retrieval , page     –     , New York , NY , USA . Association Computing Machinery . Rajdeep Mukherjee , Shreyas Shetty , Subrata Chat- topadhyay , Subhadeep Maji , Samik Datta , Pawan Goyal .     b . Reproducibility , replicabil- ity beyond : Assessing production readiness aspect based sentiment analysis wild .  Advances Information Retrieval , pages   –    , Cham . Springer International Publishing .  co-extraction aspect opinion terms . Proceedings Thirty-First AAAI Conference Artiﬁcial Intelligence , February  -  ,      , San Fran- cisco , California , USA , pages     –     . AAAI Press . Tapas Nayak Hwee Tou Ng .      . Effective mod- eling encoder-decoder architecture joint entity relation extraction . AAAI . Haiyun Peng , Lu Xu , Lidong Bing , Fei Huang , Wei Lu , Luo Si .      . Knowing , : near complete solution aspect-based sentiment analysis . AAAI . Jeffrey Pennington , Richard Socher , Christopher Manning .      . GloVe : Global vectors word representation . Proceedings      Confer- ence Empirical Methods Natural Language Processing ( EMNLP ) , pages     –     , Doha , Qatar . Association Computational Linguistics . Maria Pontiki , Dimitris Galanis , John Pavlopoulos , Harris Papageorgiou , Ion Androutsopoulos , Suresh Manandhar .     a . SemEval-     task   : Aspect based sentiment analysis . Proceedings  th International Workshop Semantic Evalua- tion ( SemEval      ) , pages   –   , Dublin , Ireland . Association Computational Linguistics . Zhen Wu , Chengcan Ying , Fei Zhao , Zhifang Fan , Xinyu Dai , Rui Xia .      . Grid tagging scheme aspect-oriented ﬁne-grained opinion extraction . Findings Association Computational Linguistics : EMNLP      , pages     –     , On- line . Association Computational Linguistics . Hu Xu , Bing Liu , Lei Shu , Philip Yu .      . BERT post-training review reading comprehension aspect-based sentiment analysis . Proceedings      Conference North American Chap- ter Association Computational Linguistics : Human Language Technologies , Volume   ( Long Short Papers ) , pages     –     , Minneapolis , Minnesota . Association Computational Linguis- tics . Hu Xu , Bing Liu , Lei Shu , Philip Yu .     a . DomBERT : Domain-oriented language model aspect-based sentiment analysis . Findings Association Computational Linguistics : EMNLP      , pages     –     , Online . Association Computational Linguistics . Maria Pontiki , Dimitris Galanis , John Pavlopoulos , Harris Papageorgiou , Ion Androutsopoulos , Suresh Manandhar .     b . SemEval-     task   : Aspect based sentiment analysis . Proceedings  th International Workshop Semantic Evalua- tion ( SemEval      ) , pages   –   , Dublin , Ireland . Association Computational Linguistics . Hu Xu , Bing Liu , Lei Shu , Philip S. Yu .      . Dou- ble embeddings CNN-based sequence labeling aspect extraction . Proceedings   th An- nual Meeting Association Computational Linguistics ( Volume   : Short Papers ) , pages    –     , Melbourne , Australia . Association Compu- tational Linguistics . Lu Xu , Hao Li , Wei Lu , Lidong Bing .     b . Position-aware tagging aspect sentiment triplet extraction . Proceedings      Conference Empirical Methods Natural Language Process- ing ( EMNLP ) , pages     –     , Online . Associa- tion Computational Linguistics . Wei Xue Tao Li .      . Aspect based sentiment analysis gated convolutional networks . Pro- ceedings   th Annual Meeting Associa- tion Computational Linguistics ( Volume   : Long Papers ) , pages     –     , Melbourne , Australia . Association Computational Linguistics . Chen Zhang , Qiuchi Li , Dawei Song , Benyou Wang .      . multi-task learning framework opinion triplet extraction . Findings Associ- ation Computational Linguistics : EMNLP      , pages    –    , Online . Association Computa- tional Linguistics . Maria Pontiki , Dimitris Galanis , John Pavlopoulos , Harris Papageorgiou , Ion Androutsopoulos , Suresh Manandhar .     c . SemEval-     task   : Aspect based sentiment analysis . Proceedings  th International Workshop Semantic Evalua- tion ( SemEval      ) , pages   –   , Dublin , Ireland . Association Computational Linguistics . Nitish Srivastava , Geoffrey Hinton , Alex Krizhevsky , Ilya Sutskever , Ruslan Salakhutdinov .      . Dropout : simple way prevent neural net- J. Mach . Learn . Res. , works overﬁtting .    (   ) :    –     . Yi Tay , Luu Anh Tuan , Siu Cheung Hui .      . Learning attend via word-aspect associative fu- Pro- sion aspect-based sentiment analysis . ceedings Thirty-Second AAAI Conference Artiﬁcial Intelligence , ( AAAI-   ) ,   th innova- tive Applications Artiﬁcial Intelligence ( IAAI-   ) ,  th AAAI Symposium Educational Ad- vances Artiﬁcial Intelligence ( EAAI-   ) , New Or- leans , Louisiana , USA , February  -  ,      , pages     –     . AAAI Press . Wenya Wang , Sinno Jialin Pan , Daniel Dahlmeier , Xiaokui Xiao .      . Coupled multi-layer attentions Appendix A.  Pointer Network-based Decoder Referring Figure   , opinion triplets decoded using LSTM-based Triplet Decoder , takes account history previously generated pairs/tuples aspect opinion spans , order avoid repetition . time step , generates ∈ Rdh used hidden representation hD two Bi-LSTM + FFN-based Pointer Networks respectively predict aspect opinion spans , exploiting interdependence . tuple representation tupt thus obtained concatenated hD passed FFN-based Senti- ment Classiﬁer predict connecting sentiment , thereby decoding entire opinion triplet tth time step . elaborate component proposed decoder framework greater depth . A. .  Span Detection Pointer Networks pointer network consists Bi-LSTM , hidden dimension dp , followed two feed- forward layers ( FFN ) top respectively predict start end locations entity span . use two pointer networks produce tuple hidden vectors corresponding aspect opinion spans triplet decoded time step t. concatenate hD encoder hidden state vectors pass input ﬁrst Bi-LSTM . output hidden state vector corresponding ith token sentence thus obtained simultaneously fed two FFNs sigmoid generate pair scores ˜sp   ˜ep   range     follows : ˜sp  = Wp  hp  + bp  , ˜ep  = Wp  e hp  + bp  e e ∈ Rdp×  , bp  ∈ Rdp×  , Wp  , Wp  , bp  e respectively weights bias parame- ters two FFNs ﬁrst pointer network ( p  ) . repeating process tokens sentence , normalized probabilities ith token start end positions aspect span ( sp  respectively ) obtained using softmax operations two sets scores thus generated ( two FFNs ) follows : ep   Sp  = softmax ( ˜Sp  ) , Ep  = softmax ( ˜Ep  ) Similar equations used second pointer network ( p  ) generate normalized probabil- ities , sp  , ith token start end positions opinion span respectively ; ep   difference apart concatenating hD , also concatenate output vectors hp    ﬁrst Bi-LSTM encoder hidden states  pass input second Bi-LSTM . vector representations aspect opinion spans time step obtained follows : apt = opt = n ( cid:   ) i=  n ( cid:   ) i=  hp  sp   ( cid:    ) hp  sp   ( cid:    ) n ( cid:   ) i=  n ( cid:   ) i=  hp  ep   ; apt ∈ R dp hp  ep   ; opt ∈ R dp introduce term generation direc- tion refers order gener- ate hidden representations two entities , i.e . aspect opinion spans . allows us deﬁne two variants model . variant discussed far uses p  detect aspect span predicting opinion span using p  , henceforth referred PASTE-AF ( AF stands aspect ﬁrst ) . Similarly , obtain second variant PASTE-OF ( opinion ﬁrst ) reversing generation direction . two components model remain variants . A.  Attention Modeling use Badhanau Attention ( Bahdanau et al. ,      ) obtain context representation input sentence ( sE ∈ Rdh ) time step follows : ˜tupprev = Wtup tupprev + btup = WuhE ui  = W˜q ˜tupprev + b˜q ; ˜ai ˜qi t−  + bq ; ai = WqhD qi = v˜a tanh ( ˜qi = va tanh ( qi + ui ) + ui ) ˜αt = softmax ( ˜at ) ; αt = softmax ( ) sE = n ( cid:   ) i=  ˜αi + αi     , W˜q , Wq , Wu ∈ Rdh×dh , v˜a , va ∈ Rdh learnable attention parameters , b˜q , bq ∈ Rdh bias vectors . First , obtain ˜tupprev tupprev using linear embedding layer , Wtup ∈ R dp×dh btup weights bias parameters . use ˜tupprev hD t−  separately obtain two attentive context vectors , ˜qt qt respectively . concate- nated along tupprev deﬁne current con- text LSTM-based decoder . correspond- ing normalized attention scores , ˜αt αt , averaged obtain attention-weighted sentence representation decoding time step . A.  Experimental Setup non-BERT experiments , word embeddings initialized ( kept trainable ) using pre-trained    -dim . Glove vectors ( Pennington et al. ,      ) , accordingly dw set     . dimensions POS DEP embeddings , i.e . dpos ddep set    . decoder ( LSTM ) hidden dimension dh set     , accordingly hidden state dimensions backward for- ward LSTMs Bi-LSTM-based encoder set     . set hidden dimension dp Bi-LSTMs pointer networks     . BERT experiments , uncased version pre-trained BERT-base ( Devlin et al. ,      ) ﬁne-tuned encode sentence . model variants trained end-to-end Adam optimizer ( Kingma Ba ,      )   −  learning rate ,   −  weight de- cay . Dropout (  .  ) ( Srivastava et al. ,      ) ap- plied embeddings avoid overﬁtting . non- BERT model variants trained     epochs batch size    . BERT-based variants trained    epochs batch size    . Model selected according best F  score development data used evaluate test data . run model ﬁve times report median scores . experiments run Tesla P   -PCIE   GB GPU . 