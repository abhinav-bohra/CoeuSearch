Aspect-Category-Opinion-Sentiment Quadruple Extraction with Implicit Aspects and Opinions Hongjie Cai∗ Rui Xia∗† Jianfei Yu School of Computer Science and Engineering, Nanjing University of Science and Technology, China {hjcai, rxia, jfyu}@njust.edu.cn Abstract Product reviews contain a large number of im- plicit aspects and opinions. However, most of the existing studies in aspect-based senti- ment analysis ignored this problem. In this work, we introduce a new task, named Aspect- Category-Opinion-Sentiment (ACOS) Quadru- ple Extraction, with the goal to extract all aspect-category-opinion-sentiment quadruples in a review sentence and provide full support for aspect-based sentiment analysis with im- plicit aspects and opinions. We further con- struct two new datasets Restaurant-ACOS and Laptop-ACOS for this new task. The for- mer is an extension of the SemEval Restau- rant dataset; the latter is a brand new Lap- top dataset with much larger size than the Se- mEval Laptop dataset. Both contain the an- notations of not only aspect-category-opinion- sentiment quadruples but also implicit aspects and opinions. We ﬁnally benchmark the task with four baseline systems. Experiments demonstrate the feasibility of the new task and its advantage in extracting and describ- ing implicit aspects and implicit opinions in ABSA. The two datasets and source code of four systems are publicly released at https: //github.com/NUSTM/ACOS. 1 Introduction As a ﬁne-grained sentiment analysis task, aspect- based sentiment analysis (ABSA) has received con- tinuous attention. Its core task is to extract the opinion target described by an entity and its aspect (collectively referred to as aspect) from product re- views, and identify the sentiment toward the aspect (Liu, 2012). The standard aspect-based sentiment analysis task includes two basic subtasks: aspect extraction and aspect-based sentiment classiﬁca- tion. By integrating the two subtasks, one can ∗ Equal contribution. † Corresponding author. Figure 1: An example of the Aspect-Category-Opinion- Sentiment Quadruple Extraction task. Restaurant Laptop Explicit Aspect & Explicit Opinion Implicit Aspect & Explicit Opinion Explicit Aspect & Implicit Opinion Implicit Aspect & Implicit Opinion 63.34% 56.06% 19.47% 17.54% 12.38% 27.55% 14.83% 8.24% Table 1: The percentage of review sentences with ex- plicit and implicit aspect/opinion. identify an aspect-sentiment pair (g, s), where g is an aspect term, and s is the sentiment polarity toward the aspect. (Hu and Liu, 2004; Qiu et al., 2011) pointed out that the correlation between the aspect term and the opinion term is helpful for better ABSA. The following studies in this direc- tion includes aspect-opinion co-extraction (Wang et al., 2016a, 2017; Yu et al., 2018; Li et al., 2018; Dai and Song, 2019), aspect-opinion pair extrac- tion (Chen et al., 2020a; Zhao et al., 2020), and aspect-opinion-sentiment triple extraction (Peng et al., 2020; Xu et al., 2020; Wu et al., 2020; Mao et al., 2021), etc. However, most of the existing studies only con- sidered the extraction of explicit aspects and opin- ions, while ignored the implicit ones. In fact, prod- uct reviews contain a large amount of implicit as- pects and opinions. Table 1 summarizes the per- centage of implicit aspects and opinions in the Review SentenceLooks nice, and the surfaceis smooth, but certain appstake seconds to respond.Aspect-Category-Opinion-SentimentQuadruple Extractionsurface-Design-smooth-PositiveNULL-Design-nice-Positiveapps-Software-NULL-NegativeSemEval Restaurant dataset and our new Laptop dataset. It can be seen that nearly 44% of the re- view sentences contain implicit aspects or implicit opinions in the Laptop domain, and the percent- age of sentences containing both implicit aspects and implicit opinions also exceeds 8%. Similar percentages can be observed in the Restaurant do- main. Although some studies have attempted to solve the implicit aspect problem (Liu et al., 2005; Poria et al., 2014; Chen and Chen, 2016; Wan et al., 2020) or the implicit opinion problem (Lazhar and Guiyassa, 2016) from respective perspectives, there is still a lack of a uniﬁed framework that fully dis- cusses and solves the implicit aspect and implicit opinion problems. In this work, we introduce a new task named Aspect-Category-Opinion-Sentiment (ACOS) Quadruple Extraction, with the goal to extract all aspect-category-opinion-sentiment quadruples in a review sentence, and provide full support for aspect-level sentiment analysis with implicit aspects and opinions. As shown in Figure 1, in the review sentence “Looks nice and the surface is smooth, but certain apps take seconds to respond”, surface is an aspect, Design is its category, smooth is the opinion toward this aspect, and Positive is the corresponding sentiment. The four elements are combined into an explicit quadruple surface- Design-smooth-Positive. In addition to that, there are two other quadruples that need to be extracted: Null-Design-nice-Positive which contains an implicit aspect, and apps-Software-Null-Negative which contains an implicit opinion. The new ACOS Quadruple Extraction task has the following two challenges: • In term of dataset, so far there was no avail- able dataset that is fully annotated with aspect- category-opinion-sentiment quadruples includ- ing all implicit aspects and opinions; • In terms of modeling complexity, the task in- cludes two extraction problems (aspect extrac- tion, opinion extraction) and two classiﬁcation problems (category classiﬁcation, sentiment clas- siﬁcation). It is challenging to effectively model the four subtasks together to construct quadru- ples containing implicit aspects and implicit opinions. To address these issues, we further construct two new datasets, Restaurant-ACOS and Laptop- ACOS, for the new task. The former is an exten- sion of the existing SemEval Restaurant dataset, based on which we add the annotation of im- plicit aspects, implicit opinions, and the quadru- ples. The latter is a brand new one collected from the Amazon Laptop domain. It has twice size of the SemEval Loptop dataset, and is annotated with quadruples containing all explicit/implicit aspects and opinions. We ﬁnally benchmark the task by establish- ing four baseline systems, Double-Propagation- ACOS, JET-ACOS, TAS-BERT-ACOS and Extract-Classify-ACOS, by adapting the repre- sentative approaches in aspect-opinion pair extrac- tion, aspect-category-opinion triple extraction or aspect-opinion-sentiment triple extraction to ACOS Quadruple Extraction. The experiments on the two ACOS datasets demonstrate the feasibility of the new ACOS Quadruple Extraction task and its ef- fectiveness in extracting and describing implicit aspects and implicit opinions. The contributions of this work can be summa- rized as follows: • We introduce a new task named Aspect- Category-Opinion-Sentiment Quadruple Extrac- tion, to address the implicit aspects/opinions is- sues in ABSA; • We construct two new datasets for the task, with ACOS quadruple annotations including implicit aspects/opinions; • We benchmark the task with four baseline sys- tems. The experiments demonstrate the new task’s advantage in addressing the implicit as- pect/opinion issues. 2 Task We ﬁrst deﬁne the four elements of the ACOS Quadruple Extraction task based on (Liu, 2012). (Peng et al., 2020; Mao et al., 2021) provided good summaries of recent tasks and terminology in ABSA. For simplicity, in this paper we use aspect, category, opinion and sentiment to denote aspect term, aspect category, opinion term and sentiment polarity, respectively. They are deﬁned as follows: • Aspect denotes an entity and its aspect indicat- ing the opinion target, which is normally a word or phrase in the text; • Category represents a unique predeﬁned cate- gory for the aspect in a particular domain; • Opinion refers the subjective statement on an aspect, which is normally a subjective word or phrase in the text; • Sentiment is the predeﬁned semantic orientation (e.g., Positive, Negative, or Neutral) toward the aspect. Aspect-Category-Opinion-Sentiment (ACOS) Quadruple Extraction is then deﬁned as a task to extract a set of aspect-category-opinion-sentiment quadruples described in a review sentence contain- ing n words r=[w1, . . . , wn]: SACOS = {. . . , ai-cj-ok-sl, . . .}, (1) where ai-cj-ok-sl denotes an aspect-category- opinion-sentiment quadruple, ai is the extracted aspect, cj ∈ C is its category, ok is the extracted opinion, and sl ∈ {Positive, Neutral, Negative} is its corresponding sentiment.1 Note that a review sentence usually contains mul- tiple aspects and opinions. The ACOS Quadru- ple Extraction task does not only identify four el- ements, but also combine them into a set of valid quadruples, meanwhile considering implicit as- pects/opinions. As the implicit aspect/opinion is not explicitly expressed as a word or phrase, in case of implicit aspect we set a as NULL and use category c to describe the opinion target, and in case of implicit opinion we set o as NULL and use sentiment s to describe the semantic orientation. 3 Datasets We construct two new datasets, Restaurant-ACOS and Laptop-ACOS, for the ACOS Quadruple Ex- traction task. 3.1 Source The Restaurant-ACOS dataset is constructed based on the SemEval 2016 Restaurant dataset (Pontiki et al., 2016) and its expansion datasets (Fan et al., 2019; Xu et al., 2020). Laptop-ACOS is a brand new Laptop dataset collected from the Amazon platform at the years of 2017 and 2018 (covering ten types of laptops under six brands such as ASUS, acer, Samsung, Lenovo, MBP, MSI and so on). It contains 4,076 review sentences, much larger than the SemEval Laptop datasets. 1Similarly, the previous representative tasks in ABSA can also be denoted by the combination of the above elements, e.g., aspect-sentiment (AS) pair extraction (Mitchell et al., 2013; Zhang et al., 2015), aspect-opinion (AO) pair extraction (Chen et al., 2020a; Zhao et al., 2020), aspect-opinion-sentiment (AOS) triple extraction (Peng et al., 2020; Xu et al., 2020; Wu et al., 2020; Mao et al., 2021; Chen et al., 2021), aspect- category-sentiment (ACS) triple extraction (Wan et al., 2020), etc. #Categories #Sentences s EA & EO IA & EO EA & IO IA & IO All e l p u r d a u Q # #Quadruples #Sentences Restaurant-ACOS Laptop-ACOS 13 2286 2429 (66.40%) 530 (14.49%) 350 (9.57%) 349 (9.54%) 3658 121 4076 3269 (56.77%) 910 (15.80%) 1237 (21.48%) 342 (5.94%) 5758 1.60 1.42 Table 2: Statistics of our two ACOS Quadruple datasets. EA, EO, IA and IO denote explicit aspect, explicit opinion, implicit aspect, and implicit opinion, respectively. #Categories represents the number of as- pect categories which are consistent with that in (Pon- tiki et al., 2016). 3.2 Annotation The SemEval 2016 Restaurant dataset (Pontiki et al., 2016) was annotated with explicit and im- plicit aspects, categories, and sentiment. (Fan et al., 2019; Xu et al., 2020) further added the opinion annotations. We integrate their annotations to con- struct aspect-category-opinion-sentiment quadru- ples and further annotate the implicit opinions. For Laptop-ACOS, we annotate the four ele- ments and their corresponding quadruples all by ourselves. We employ the aspect categories de- ﬁned in the SemEval 2016 Laptop dataset. Two PhD students familiar with aspect-based sentiment analysis are selected as annotators for independent annotation with the annotation tool introduced by (Yang et al., 2017a). The strict quadruple match- ing F1 score between two annotators is 75.86%, which indicates a substantial agreement between two annotators (Kim and Klinger, 2018). In case of disagreement, a third expert will be asked to make the ﬁnal decision. 3.3 Statistics and Analysis The basic statistics of the two datasets are reported in Table 2. The Restaurant-ACOS dataset con- tains 2286 sentences with 3658 quadruples, and the Laptop-ACOS dataset contains 4076 sentences with 5758 quadruples. As we have mentioned, a large percentage of the quadruples contain implicit aspects or implicit opinions. By comparing two datasets, it can be observed that Laptop-ACOS has higher percentage of implicit opinions than Restaurant-ACOS. In Table 3, we further compare our two ACOS datasets with the existing representative datasets Sentence Aspect Category Opinion Sentiment AS AO AOS ACS Pair Pair Triple Triple Quadruple ACOS Restaurant-2014 (Pontiki et al., 2014) Laptop-2014 (Pontiki et al., 2014) Restaurant-2016 (Pontiki et al., 2016) Laptop-2016 (Pontiki et al., 2016) Restaurant-2014-AO (Fan et al., 2019) Restaurant-2016-AO (Fan et al., 2019) Restaurant-2014-AOS (Xu et al., 2020) Restaurant-2016-AOS (Xu et al., 2020) Restaurant-ACOS (ours) Laptop-ACOS (ours) 3841 1910 2295 2612 2125 1407 2068 1393 2286 4076 4827 3012 3122 - 3503 1968 3399 1946 3110 4958 4738 - 3001 3705 - - - - 2967 4992 - - - - 3610 2146 3443 2101 3335 5378 4534 3012 3122 3705 - - 3399 1946 3110 4958 - - - - - - 4827 3012 3182 - - - - - - - 4092 2294 3399 3908 3908 1946 2247 2247 3155 3571 3575 5035 5726 5731 - - 3364 - - - - - 3335 5227 - - - - - - - - 3658 5758 Table 3: The comparison between the sizes of our two ACOS Quadruple datasets and existing representative ABSA datasets. AS, AO, AOS, and ACS denote Aspect-Sentiment, Aspect-Opinion, Aspect-Opinion-Sentiment, and Aspect-Category-Sentiment, respectively. in ABSA. Restaurant 2014/2016 and Laptop 2014/2016 denote the SemEval 2014/2016 Restau- rant and Laptop datasets, respectively. Restaurant 2014/2016 contains the annotations of aspect, cate- gory and sentiment. It should be noted the category deﬁnitions in two datasets are different. Laptop 2014 contains only the annotations of aspect and sentiment, while Laptop 2016 contains only the annotations of category and sentiment. Restaurant-2014-AO and Restaurant-2016-AO are two aspect-opinion pair datasets proposed by (Fan et al., 2019), based on Restaurant 2014 and 2016, respectively. They removed the sentences with implicit aspects and added the opinion an- notations. (Xu et al., 2020) further added senti- ment which was originally included in Resturant 2014/2016 to Restaurant-2014/2016-AO, and ob- tained two aspect-opinion-sentiment triple datasets: Restaurant-2014-AOS and Restaurant-2016-AOS. For Restaurant-ACOS, we integrate the above annotations to construct ACOS quadruples. But it should be noted that we keep the sentences with implicit aspects in Restaurant-2016, and further an- notate the implicit opinions. As a result, the size (including sentences, AO pairs and AOS triples) of Restaurant-ACOS is about 1.6 times that of Restaurant-2016-AO and Restaurant-2016-AOS. The new Laptop-ACOS has 4076 review sen- tences. The numbers of annotations for aspect, category, opinion and sentiment are 4958, 4992, 5378 and 4958, respectively. By combining these elements, we construct 5035 AS pairs, 5726 AO pairs, 5731 AOS triples, 5227 ACS triples and 5758 ACOS quadruples, nearly twice the size of Restaurant-ACOS.2 2It is worth noting that the Restaurant-ACOS and Laptop- 4 Methods We benchmark the ACOS Quadruple Extrac- tion task with four baseline systems, namely, JET-ACOS, TAS- Double-Propagation-ACOS, BERT-ACOS and Extract-Classify-ACOS, by adapting the representative approaches in aspect- opinion pair extraction, aspect-category-opinion triple extraction or aspect-opinion-sentiment triple extraction to ACOS Quadruple Extraction. 4.1 Double-Propagation-ACOS Since Double Propagation (DP) is one of the rep- resentative rule-based methods for aspect-opinion- sentiment triple extraction (Qiu et al., 2011), we propose to adapt it to our ACOS quadruple extrac- tion task by ﬁrst extracting all the aspect-opinion- sentiment triples, followed by assigning the aspect category for each extracted triple. We name the adapted approach as Double-Propagation-ACOS. Speciﬁcally, we ﬁrst follow the DP algorithm to extract the aspect-opinion-sentiment triples, where we utilize the syntactic relations between aspects and opinions to iteratively extract them in each review, and rely on the sentiment lexicon to assign sentiments (i.e., Positive, Negative, and Neutral) to aspects and opinions in a bootstrapping manner. Second, to identify the aspect category of each extracted triple, we use the following strategy: if the aspect in the triple is in the training set, we take its most co-occurred aspect category as the ﬁnal aspect category; otherwise, we adopt the aspect ACOS datasets are available for all subtasks in ABSA, includ- ing aspect-based sentiment classiﬁcation, aspect-sentiment pair extraction, aspect-opinion pair extraction, aspect-opinion- sentiment triple extraction, aspect-category-sentiment triple extraction, etc. category of the nearest aspect in the input review as the ﬁnal aspect category. Based on the two steps mentioned above, we can extract the ACOS quadruples in each review sentence. 4.2 JET-ACOS As one of the state-of-the-art approaches for aspect- opinion-sentiment triple extraction, JET (Xu et al., 2020) introduced an end-to-end framework to this task, by combining the identiﬁcation of aspects, their corresponding opinions, and their sentiment polarities with a position-aware tagging scheme3. Similar to Double-Propagation-ACOS, we adapt JET to our task by ﬁrst extracting the triple with JET, followed by predicting the aspect category for each extracted triple. Speciﬁcally, we ﬁrst obtain the candidate aspect- opinion-sentiment triples based on JET, and then design a BERT-based model to get the aspect cat- egory of the extracted triples. Given the review sentence r, we ﬁrst feed it to BERT to get the context-aware token representation H as follows: H =[h[CLS], hr, h[SEP]], (2) where hr = [h1, . . . , hn] is the output represen- tation for r. Next, given an extracted triple a-o-s, we can obtain the representation of the aspect and the opinion as ua = avg(ha) and uo = avg(ho), where avg(ha) and avg(ho) are the average vec- tors of words in the aspect ha and the opinion ho, respectively. We then concatenate ua and uo, and feed it to a fully-connected layer with the Sigmoid function for each category c: yc = Sigmoid(W (cid:62) c [ua; uo] + bc). (3) Given a-o-s and c, yc = 1 indicates a valid quadru- ple, and yc = 0 indicates an invalid quadruple. In the training stage, we adopt the standard bi- nary cross-entropy loss for optimization. In the inference stage, we combine the extracted aspect- opinion-sentiment triples from JET and our pre- dicted aspect categories to get all the quadruples from each review sentence. 3JET contains two variants, i.e., JETt and JETo. JETt aims to identify the aspects, the offset of their corresponding opinions, and their sentiment polarity; whereas JETo aims to identify the opinions, the offset of their corresponding aspects, and their sentiment polarity. We employ JETo to extract the aspect-opinion-sentiment triple, as it has been shown to obtain better performance than JETt. 4.3 TAS-BERT-ACOS TAS-BERT (Wan et al., 2020) is one of the state-of- the-art method for aspect-category-sentiment triple extraction, which integrates aspect category-based sentiment classiﬁcation and aspect extraction in a uniﬁed framework by attaching the aspect category and the sentiment polarity to the review sentence and using it as the input of BERT. To adapt TAS- BERT to our ACOS extraction task, we propose to adopt the input transformation strategy in TAS- BERT to perform category-sentiment conditional aspect-opinion co-extraction, following by ﬁltering out the invalid aspect-opinion pairs to form the ﬁnal quadruples. Speciﬁcally, given a review sentence r, an aspect category c ∈ C, and a sentiment s ∈ S, the input is constructed as follows: x =[[CLS], r, [SEP], c, s, [SEP]], (4) We then feed x to BERT to get the context-aware token representation H: H =[h[CLS], hr, h[SEP], hcs, h[SEP]], (5) where hr = [h1, . . . , hn] is the output representa- tion for r, hcs is the output representation for the concatenation of c and s, and h[CLS] is used for category-sentiment veriﬁcation. We then perform aspect-opinion co-extraction over H by modeling it as a single sequence label- ing task. Speciﬁcally, we employ a modiﬁed Begin- Inside-Outside (BIO) tagging scheme, which con- sists of ﬁve tags: {BA, IA, BO, IO, O}, indicating the beginning and inside of the aspect, the begin- ning and inside of the opinion, and others. We feed hr to a CRF layer to extract the aspects and opin- ions in r with respect to the input category c and sentiment s as follows: Y ao = [yao 1 , . . . , yao n ] = CRF(h1, . . . , hn); (6) Next, we perform Cartesian Product on the ex- tracted aspects and opinions to obtain a set of can- didate aspect-category-opinion-sentiment quadru- ples: SACOS = {a1-c1-o1-s1, ..., a|A|-c|C|-o|O|-s|S|}, (7) where |A| and |O| are the number of extracted as- pects and opinions, |C| and |S| are the number of detected categories and sentiment. Training Validation Testing Restaurant-ACOS Laptop-ACOS 1531 2934 170 326 585 816 Table 4: The division of training, validation, and testing sets. We further apply two binary classiﬁcation tasks on the [CLS] tokens to predict whether there is implicit aspect or implicit opinion. Thus, we can obtain the potential aspect set SA, opinion set SO, and perform Cartesian Product on SA and SO to obtain a set of candidate aspect-opinion pairs: SAO = {a1-o1, ..., a|A|-o|O|}. (10) Next, we model the category-sentiment classiﬁ- cation as a multiple multi-class classiﬁcation prob- lem. Speciﬁcally, for each category c, we concate- nate the average vectors of each aspect-opinion pair a-o, and feed them to a fully-connected layer with Softmax function as follows: saoc = Softmax(W (cid:62) aoc[ua; uo] + baoc), (11) where saoc ∈ {Positive, Negative, Neutral, Invalid} denotes its sentiment given current a-o and c, or indicates an invalid quadruple. 5 Experiments We evaluate the performance of four baselines sys- tems on two ACOS quadruple datasets. 5.1 Experimental Settings and Evaluation Metrics In Extract-Classify-ACOS, we adopt BERTbase (Devlin et al., 2018) as the basic encoder, which consists of 12 stacked Transformer blocks. During training, we use the AdamW optimizer of BERT with weight decay ﬁx. The maximum length of the review sentence is set to 128, covering all sentences in two datasets. We set the batch size and learning rates in aspect opinion co-extraction and category- sentiment classiﬁcation as [32, 2e-5] and [16, 3e- 5], respectively. The dropout rate is set as 0.1. The batch size and learning rate in the category classiﬁcation of JET-ACOS and the aspect-opinion pair ﬁltering in TAS-BERT-ACOS are all set as [8, 5e-5], other settings of these two modules are the same as Extract-Classify-ACOS. Figure 2: The Structure of Extract-Classify-ACOS. On the basis of SACOS, we average the vectors of tokens in the aspect and opinion, and then feed their concatenation [ua; uo] to a quadruple ﬁlter: yacos = Sigmoid(W (cid:62)[ua; uo] + b), (8) where yacos = 1 indicates a valid quadruple, and yacos = 0 indicates an invalid quadruple. 4.4 Extract-Classify-ACOS Finally, we propose Extract-Classify-ACOS by adapting one of the representative aspect-opinion co-extraction system (Wang et al., 2017) to our ACOS quadruple extraction task. Speciﬁcally, the ﬁrst step performs aspect-opinion co-extraction, and the second step predicts category-sentiment given the extracted aspect-opinion pairs. As shown in Figure 2, we ﬁrst insert two [CLS] tokens at the beginning and the end of the review sentence r, and then feed the transformed input to BERT to obtain the context-aware token represen- tations H as follows: H =[h[CLS], hr, h[CLS]], (9) Similar to the method in TAS-BERT-ACOS, the explicit aspect-opinion co-extraction is based on a CRF layer with the modiﬁed BIO tagging scheme. We divide the original dataset into a training set, a validation set and a testing set according to Table 4. ………Explicit Aspect Opinion Co-Extraction[CLS]Looks nice, and the surface … to respond.[CLS]BERTℎ2…ℎ𝑛−1Aspect-Opinion PairingCategory-Sentiment ClassificationCandidate Aspect-Opinion PairsℎCLSImplicit AspectPredictionℎCLSImplicit OpinionPredictionℎ1ℎ𝑛Candidate Aspects𝑎|A|𝑎1…𝑜1Candidate Opinions𝑜|𝑂|………𝑎1-𝑐𝑗1-𝑜2-𝑠𝑙1𝑎2-𝑐𝑗2-𝑜1-𝑠𝑙2…Valid Aspect-Category-Opinion-Sentiment Quadruples…𝑎1-o1𝑎1-o2𝑎1-o|𝑂|𝑎|𝐴|-o1𝑎|𝐴|-o2𝑎|𝐴|-o|𝑂|Method Restaurant-ACOS R P F1 Laptop-ACOS R P F1 Double-Propagation-ACOS JET-ACOS TAS-BERT-ACOS Extract-Classify-ACOS 0.3467 0.5981 0.2629 0.3854 0.1508 0.2894 0.4629 0.5296 0.2104 0.3901 0.3353 0.4461 0.1304 0.4452 0.4715 0.4556 0.0057 0.1625 0.1922 0.2948 0.0800 0.2381 0.2731 0.3580 Table 5: Main results of the Aspect-Category-Opinion-Sentiment Quadruple Extraction task. Method Restaurant-ACOS Laptop-ACOS EA & EO IA & EO EA & IO IA & IO EA & EO IA & EO EA & IO IA & IO Double-Propagation-ACOS JET-ACOS TAS-BERT-ACOS Extract-Classify-ACOS 0.2602 0.5230 0.3360 0.4496 N/A N/A 0.3184 0.3466 N/A N/A 0.1403 0.2386 N/A N/A 0.3976 0.3370 0.0980 0.3570 0.2610 0.3539 N/A N/A 0.4154 0.3900 N/A N/A 0.1090 0.1682 N/A N/A 0.2115 0.1858 Table 6: F1 score on testing subsets with different aspect & opinion types. EA, EO, IA and IO denote explicit aspect, explicit opinion, implicit aspect and implicit opinion, respectively. N/A means the model can not deal with the corresponding type. In evaluation, a quadruple is viewed as correct if and only if the four elements as well as their combination are exactly the same as those in the gold quadruple. On this basis, we calculate the Precision and Recall, and use F1 score as the ﬁnal evaluation metric for AOCS Quadruple Extraction. 5.2 Main Results Table 5 reports the ACOS quadruple extraction performance of four different systems on the two datasets. It can be seen that Double-Propagation- ACOS gets the lowest performance. It is reasonable that only using rules is somehow difﬁcult to iden- tify multiple implicit elements and their complex combinations in reviews. JET-ACOS and TAS-BERT-ACOS achieve com- parable F1 performance: the former is better on Restaurant-ACOS dataset and the latter is better on Laptop-ACOS. Extract-Classify-ACOS achieves the best per- formance among four baseline systems. It out- performs JET-ACOS by 5.60 percentage points on Restaurant-ACOS and outperforms TAS-BERT- ACOS by 8.49 percentage points on Laptop-ACOS, respectively. The main advantage is that Extract- Classify-ACOS can achieve robustly higher recall score. In comparison, JET-ACOS has higher or comparable precision score but its recall is much lower. It is also worth noting that the F1 score of Extract-Classify-ACOS on both datasets are not high (0.4461 and 0.3580). It is reasonable because the evaluation metric is based on exact matching and the ACOS Quadruple Extraction is a more com- plicated task than the traditional ABSA tasks. 5.3 Effectiveness of Modeling of Implicit Aspects/Opinions As we have mentioned, a large percentage of re- view sentences contain implicit aspects/opinions. Therefore, efﬁcient modeling of implicit as- pects/opinions is of great importance. To investigate the ability of different systems in addressing the implicit aspects/opinion problem, in Table 6 we split the testing set into four subsets and observe the performance on different subsets: 1) EA & EO denotes the subset with explicit as- pects and explicit opinions; 2) IA & EO denotes the subset with implicit aspects and explicit opin- ions; 3) EA & IO denotes the subset with explicit aspects and implicit opinions; 4) IA & IO denotes the subset with both implicit aspects and implicit opinions. Among four systems, Double-Propagation- ACOS and JET-ACOS can only address EA & EO, while TAS-BERT-ACOS and Extract-Classify- ACOS can support both implicit aspects and im- plicit opinions. They show comparable ability in modeling the implicit aspects/opinions. Extract- Classify-ACOS is better in case of IA & EO and EA & IO on Restaurant-ACOS, while TAS-BERT- ACOS is better in case of IA & EO and IA & IO on Laptop-ACOS. But Extract-Classify-ACOS per- forms signiﬁcantly better in case of EA & EO on two datasets. We further compare the performance on differ- Aspect & Opinion Type EA & EO IA & EO EA & IO IA & IO Review Sentence Keyboard is comfortable and screen is sharp. Nice, I ordered this just for simple web browsing and personal use. I noticed the battery went down to 67% for no reason. We waited for an hour to be seated. AS Pair AO Pair ACS Triple AOS Triple RACL (Chen and Qian, 2020) SDRN (Chen et al., 2020a) TAS-BERT (Wan et al., 2020) JET (Xu et al., 2020) JET-ACOS ACOS Quadruple TAS-BERT-ACOS Extract-Classify-ACOS screen-Pos (cid:51) Keyboard-Pos (cid:51) screen-sharp (cid:51) Keyboard-comfortable (cid:51) screen-Design&Feature-Pos (cid:51) Keyboard-Usability-Pos (cid:51) screen-sharp-Pos (cid:51) Keyboard-comfortable-Pos (cid:51) screen-Performance-sharp-Pos (cid:55) Keyboard-Usability-comfortable-Pos (cid:51) screen-Design&Feature-sharp-Pos (cid:51) Keyboard-Usability-comfortable-Pos (cid:51) screen-Design&Feature-sharp-Pos (cid:51) Keyboard-Usability-comfortable-Pos (cid:51) N/A N/A (cid:55) N/A N/A (cid:55) (cid:55) N/A battery-Performance-Neg (cid:51) N/A N/A N/A N/A (cid:55) N/A N/A battery-Performance-NULL-Neg (cid:51) NULL-Service-NULL-Neg (cid:51) NULL-General-Nice-Pos (cid:51) battery-Performance-NULL-Neg (cid:51) NULL-Service-NULL-Neg (cid:51) Table 7: The predictions of some representative approaches in ﬁve ABSA tasks on review sentences with different aspect & opinion types. EA, EO, IA and IO denote explicit aspect, explicit opinion, implicit aspect and implicit opinion, respectively. N/A stands for non-available; (cid:51) and (cid:55) denote correct and false predictions, respectively. ent subsets. The result shows that the worst perfor- mance is obtained on EA & IO rather than IA & IO. One possible reason is that the categories cor- responding to IA & IO are relatively regular than EA & IO, and is easier to predict. 5.4 Case study In Table 7, we further conduct case study by comparing the predictions of some representa- tive approaches on ﬁve ABSA tasks including Aspect-Sentiment (AS) Pair extraction, Aspect- Opinion (AO) Pair extraction, Aspect-Category- Sentiment (ACS) Triple extraction, Aspect- Opinion-Sentiment (AOS) Triple extraction, and ACOS extraction. We choose four different sentences according to whether the aspect/opinion is explicit or implicit, and observe the predictions obtained by different It can be observed that: 1) RACL approaches. (Chen and Qian, 2020) accurately extracts the AS pairs in case of EA & EO, but it does not sup- port implicit aspects and it fails to make predic- tions in case of EA & IO on our testing sentence; 2) SDRN (Chen et al., 2020a) is only capable of aspect-opinion pair extraction in case of EA & EO; 3) JET (Xu et al., 2020) can only extract aspect- opinion-sentiment triples in case of EA & EO; 4) Although TAS-BERT (Wan et al., 2020) supports aspect-category-sentiment triple extraction for ei- ther implicit aspect or implicit opinion, it fails to give accurate predictions in case of IA & EO and IA & IO on our testing sentences; 5) As for the three ACOS baseline systems, JET-ACOS is only capa- ble of ACOS quadruple extraction in case of EA & EO, and has a false prediction. TAS-BERT-ACOS and Extract-Classify-ACOS support ACOS quadru- ple extraction in case of both implicit aspects and implicit opinions. TAS-BERT-ACOS performs bet- ter than JET-ACOS but still fails in the case of IA & EO. Extract-Classify-ACOS performs generally the best and produces more accurate predictions in all cases. 6 Related Work Aspect-based sentiment analysis (ABSA) has drawn wide attention during the last decade. As a core task of ABSA, aspect-based sentiment clas- siﬁcation (ABSC) which aims to detect the senti- ment of a given aspect has been extensively studied in the literature (Jiang et al., 2011; Vo and Zhang, 2015; Tang et al., 2015; Wang et al., 2016b; Tang et al., 2016; Zhang et al., 2016; Yang et al., 2017b; Ma et al., 2017; Zhang et al., 2018; Wang et al., 2018, 2019; Xu et al., 2019; Tang et al., 2020; Chen et al., 2020b). In recent years, on the basis of traditional ABSC, a series of expansion tasks have appeared in this ﬁeld. We divide these work into the following four categories: Aspect-Sentiment Pair Extraction. It also can be viewed as joint aspect extraction and ABSC. (Mitchell et al., 2013) ﬁrst explored the open- domain aspect-sentiment extraction task by de- signing a variety of conditional random ﬁeld- based models based on traditional discrete fea- tures. With the recent trend of deep learning, re- searchers have proposed various neural pipeline approaches (Zhang et al., 2015; Hu et al., 2019) or joint learning approaches for this task (Li et al., 2019; Luo et al., 2019; He et al., 2019; Chen and Qian, 2020). Aspect-Opinion Pair Extraction. (Hu and Liu, 2004) ﬁrst addressed the task in a pipeline manner. (Chen et al., 2020a) proposed to extract aspect- opinion pairs with a double-channel recurrent net- work while taking the correlation between aspects and opinions into consideration. (Zhao et al., 2020) designed a span-based multi-task learning frame- work to extract aspect-opinion pairs jointly. The work on aspect-opinion co-extraction (Wang et al., 2016a, 2017; Yu et al., 2018) can be viewed as the ﬁrst stage of aspect-opinion pair extraction. Aspect-Opinion-Sentiment Triple Extraction. Considering the relation between aspect and opin- ion, (Hu and Liu, 2004) designed a feature-based opinion summary system, which identiﬁes explicit aspect, opinion and sentiment, and integrates them into review opinion summaries. (Qiu et al., 2011) further proposed a Double Propagation method to utilize the syntactic relations between aspects and opinions to iteratively extract the aspect-opinion- sentiment triples. More recently, (Peng et al., 2020) proposed a two-stage framework to ﬁrst extract aspect-sentiment pairs and opinions separately, fol- lowed by matching them to obtain aspect-opinion- sentiment triples. (Xu et al., 2020) further proposed an end-to-end position-aware tagging scheme to model the relations among aspect, opinion and sen- timent. (Wu et al., 2020) proposed a Grid Tagging Scheme to address this problem. (Mao et al., 2021; Chen et al., 2021) transformed the triple extrac- tion task into multi-turn machine reading compre- hension task and achieved state-of-the-art perfor- mances. Aspect-Category-Sentiment Triple Extrac- tion. Previous two categories only focus on explicit aspect-based sentiment analysis, while ignoring the implicit aspects. To address this issue, (Liu et al., 2005) designed rule-based method to ﬁnd the cor- responding implicit aspects through the opinion existing in the review sentence. With the recent advances of pre-trained models, (Wan et al., 2020) proposed a BERT-based architecture to address this task in an end-to-end fashion. Since the problem of implicit aspect and implicit opinion has not been systematically addressed in previous studies, in this work we introduce a new task for Aspect-Category-Opinion-Sentiment (ACOS) Quadruple Extraction with implicit as- pects and opinions, construct two ACOS Quadruple datasets, and benchmark the task with four baseline systems. 7 Conclusions and Future Work In this paper, we introduce a new task, Aspect- Category-Opinion-Sentiment (ACOS) Quadruple Extraction, aiming to systematically address the implicit aspect/opinion problem. We construct two new datasets for this task, with ACOS annotations including implicit aspects and implicit opinions. We ﬁnally benchmark the task with four baseline systems. Experiments demonstrate the advantages of the new task in aspect-based sentiment analysis with implicit aspects/opinions. The focus of this paper is the introduction of the new task and datasets. The proposed four base- line systems are relatively simple and leave much room for further improvements. We welcome fu- ture work proposing stronger models on this task. We also welcome the usage of our datasets on the other ABSA tasks. Acknowledgments This work was supported by the Natural Sci- ence Foundation of China (No. 62076133 and 62006117), and the Natural Science Foundation of Jiangsu Province for Young Scholars (No. BK20200463) and Distinguished Young Scholars (No. BK20200018). References Huan-Yuan Chen and Hsin-Hsi Chen. 2016. Implicit polarity and implicit aspect recognition in opinion In Proceedings of the 54th Annual Meet- mining. ing of the Association for Computational Linguistics (ACL), pages 20–25. Shaowei Chen, Jie Liu, Yu Wang, Wenzheng Zhang, and Ziming Chi. 2020a. Synchronous double- channel recurrent network for aspect-opinion pair extraction. In Proceedings of the 58th Annual Meet- ing of the Association for Computational Linguistics (ACL), pages 6515–6524. Shaowei Chen, Yu Wang, Jie Liu, and Yuelin Wang. 2021. Bidirectional machine reading comprehen- sion for aspect sentiment triplet extraction. In Pro- ceedings of the 35th AAAI Conference on Artiﬁcial Intelligence (AAAI), pages 12666–12674. Xiao Chen, Changlong Sun, Jingjing Wang, Shoushan Li, Luo Si, Min Zhang, and Guodong Zhou. 2020b. Aspect sentiment classiﬁcation with document-level In Proceedings of sentiment preference modeling. the 58th Annual Meeting of the Association for Com- putational Linguistics (ACL), pages 3667–3677. Zhuang Chen and Tieyun Qian. 2020. Relation-aware collaborative learning for uniﬁed aspect-based sen- timent analysis. In Proceedings of the 58th Annual Meeting of the Association for Computational Lin- guistics (ACL), pages 3685–3694. Hongliang Dai and Yangqiu Song. 2019. Neural aspect and opinion term extraction with mined arXiv preprint rules as weak supervision. arXiv:1907.03750. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understand- ing. arXiv preprint arXiv:1810.04805. Zhifang Fan, Zhen Wu, Xinyu Dai, Shujian Huang, and Jiajun Chen. 2019. Target-oriented opinion words extraction with target-fused neural sequence label- ing. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Com- putational Linguistics (NAACL), pages 2509–2518. Ruidan He, Wee Sun Lee, Hwee Tou Ng, and Daniel Dahlmeier. 2019. An interactive multi-task learn- ing network for end-to-end aspect-based sentiment analysis. In Proceedings of the 57th Annual Meet- ing of the Association for Computational Linguistics (ACL), pages 504–515. Minghao Hu, Yuxing Peng, Zhen Huang, Dongsheng Li, and Yiwei Lv. 2019. Open-domain targeted sen- timent analysis via span-based extraction and clas- siﬁcation. In Proceedings of the 57th Annual Meet- ing of the Association for Computational Linguistics (ACL), pages 537–546. Minqing Hu and Bing Liu. 2004. Mining and summa- rizing customer reviews. In Proceedings of the tenth ACM SIGKDD international conference on Knowl- edge discovery and data mining, pages 168–177. Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and Tiejun Zhao. 2011. Target-dependent twitter senti- ment classiﬁcation. In Proceedings of the 49th an- nual Meeting of the association for computational linguistics (ACL), pages 151–160. Evgeny Kim and Roman Klinger. 2018. Who feels what and why? annotation of a literature corpus with semantic roles of emotions. In Proceedings of the 27th International Conference on Computational Linguistics (COLING), pages 1345–1359. Farek Lazhar and Yamina Tlili Guiyassa. 2016. Mining explicit and implicit opinions from reviews. Int. J. Data Min. Model. Manag., 8:75–92. Xin Li, Lidong Bing, Piji Li, and Wai Lam. 2019. A uniﬁed model for opinion target extraction and tar- get sentiment prediction. In Proceedings of the 33rd AAAI Conference on Artiﬁcial Intelligence (AAAI), pages 6714–6721. Xin Li, Lidong Bing, Piji Li, Wai Lam, and Zhimou Yang. 2018. Aspect term extraction with history at- tention and selective transformation. arXiv preprint arXiv:1805.00760. Bing Liu. 2012. Sentiment analysis and opinion min- ing. Synthesis lectures on human language technolo- gies, pages 1–167. Bing Liu, Minqing Hu, and Junsheng Cheng. 2005. Opinion observer: analyzing and comparing opin- ions on the web. In Proceedings of the 14th interna- tional conference on World Wide Web (WWW), pages 342–351. Huaishao Luo, Tianrui Li, Bing Liu, and Junbo Zhang. 2019. Doer: Dual cross-shared rnn for aspect term-polarity co-extraction. arXiv preprint arXiv:1906.01794. Dehong Ma, Sujian Li, Xiaodong Zhang, and Houfeng Wang. 2017. Interactive attention networks for aspect-level sentiment classiﬁcation. arXiv preprint arXiv:1709.00893. Yue Mao, Yi Shen, Chao Yu, and Longjun Cai. 2021. A joint training dual-mrc framework for arXiv preprint aspect based sentiment analysis. arXiv:2101.00816. Margaret Mitchell, Jacqui Aguilar, Theresa Wilson, and Benjamin Van Durme. 2013. Open domain tar- In Proceedings of the 2013 Con- geted sentiment. ference on Empirical Methods in Natural Language Processing (EMNLP), pages 1643–1654. Haiyun Peng, Lu Xu, Lidong Bing, Fei Huang, Wei Lu, and Luo Si. 2020. Knowing what, how and why: A near complete solution for aspect-based sentiment analysis. In Proceedings of the 34th AAAI Confer- ence on Artiﬁcial Intelligence (AAAI), pages 8600– 8607. Maria Pontiki, Dimitrios Galanis, Haris Papageor- giou, Ion Androutsopoulos, Suresh Manandhar, Mo- hammad Al-Smadi, Mahmoud Al-Ayyoub, Yanyan Zhao, Bing Qin, Orph´ee De Clercq, et al. 2016. Semeval-2016 task 5: Aspect based sentiment anal- ysis. In International workshop on semantic evalua- tion, pages 19–30. Maria Pontiki, Dimitris Galanis, John Pavlopoulos, Ion Androutsopoulos, and Harris Papageorgiou, Suresh Manandhar. 2014. SemEval-2014 task 4: As- pect based sentiment analysis. In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 27–35, Dublin, Ireland. As- sociation for Computational Linguistics. Soujanya Poria, Erik Cambria, Lun-Wei Ku, Chen Gui, and Alexander Gelbukh. 2014. A rule-based ap- proach to aspect extraction from product reviews. In Proceedings of the second workshop on natural language processing for social media (SocialNLP), pages 28–37. Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2011. Opinion word expansion and target extraction through double propagation. Computational linguis- tics, 37(1):9–27. Duyu Tang, Bing Qin, Xiaocheng Feng, and target- Ting Liu. 2015. dependent sentiment classiﬁcation. arXiv preprint arXiv:1512.01100. Effective lstms for Duyu Tang, Bing Qin, and Ting Liu. 2016. Aspect level sentiment classiﬁcation with deep memory net- work. arXiv preprint arXiv:1605.08900. Hao Tang, Donghong Ji, Chenliang Li, and Qiji Zhou. 2020. Dependency graph enhanced dual- transformer structure for aspect-based sentiment In Proceedings of the 58th Annual classiﬁcation. Meeting of the Association for Computational Lin- guistics (ACL), pages 6578–6588. Duy-Tin Vo and Yue Zhang. 2015. Target-dependent twitter sentiment classiﬁcation with rich automatic In Proceedings of the 24th International features. Joint Conference on Artiﬁcial Intelligence (IJCAI), pages 1347–1353. Zhen Wu, Chengcan Ying, Fei Zhao, Zhifang Fan, Xinyu Dai, and Rui Xia. 2020. Grid tagging scheme for end-to-end ﬁne-grained opinion extraction. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, pages 2576–2585. Hu Xu, Bing Liu, Lei Shu, and S Yu Philip. 2019. Bert post-training for review reading comprehension and aspect-based sentiment analysis. In Proceedings of the 2019 Conference of the North American Chap- ter of the Association for Computational Linguistics (NAACL), pages 2324–2335. Lu Xu, Hao Li, Wei Lu, and Lidong Bing. 2020. Position-aware tagging for aspect sentiment triplet extraction. arXiv preprint arXiv:2010.02609. Jie Yang, Yue Zhang, Linwei Li, and Xingxuan Li. 2017a. Yedda: A lightweight collaborative text span annotation tool. arXiv preprint arXiv:1711.03759. Min Yang, Wenting Tu, Jingxuan Wang, Fei Xu, and Xiaojun Chen. 2017b. Attention based lstm for tar- get dependent sentiment classiﬁcation. In Proceed- ings of the Thirty-First AAAI Conference on Artiﬁ- cial Intelligence (AAAI), pages 5013–5014. Hai Wan, Yufei Yang, Jianfeng Du, Yanan Liu, Kunxun Qi, and Jeff Z Pan. 2020. Target-aspect-sentiment joint detection for aspect-based sentiment analysis. In Proceedings of the 34th AAAI Conference on Ar- tiﬁcial Intelligence (AAAI), pages 9122–9129. Jianfei Yu, Jing Jiang, and Rui Xia. 2018. Global in- ference for aspect and opinion terms co-extraction IEEE/ACM based on multi-task neural networks. Transactions on Audio, Speech, and Language Pro- cessing, 27(1):168–177. Lei Zhang, Shuai Wang, and Bing Liu. 2018. Deep learning for sentiment analysis: A survey. Wiley Interdisciplinary Reviews: Data Mining and Knowl- edge Discovery, 8(4):e1253. Meishan Zhang, Yue Zhang, and Duy-Tin Vo. 2015. Neural networks for open domain targeted sentiment. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 612–621. Meishan Zhang, Yue Zhang, and Duy-Tin Vo. 2016. Gated neural networks for targeted sentiment anal- ysis. In Proceedings of the 30th AAAI Conference on Artiﬁcial Intelligence (AAAI), pages 3087–3093. He Zhao, Longtao Huang, Rong Zhang, Quan Lu, et al. 2020. Spanmlt: A span-based multi-task learning framework for pair-wise aspect and opinion terms extraction. In Proceedings of the 58th Annual Meet- ing of the Association for Computational Linguistics (ACL), pages 3239–3248. Jingjing Wang, Changlong Sun, Shoushan Li, Xi- aozhong Liu, Luo Si, Min Zhang, and Guodong Zhou. 2019. Aspect sentiment classiﬁcation towards question-answering with reinforced bidirectional at- tention network. In Proceedings of the 57th Annual Meeting of the Association for Computational Lin- guistics (ACL), pages 3548–3557. Shuai Wang, Sahisnu Mazumder, Bing Liu, Mianwei Zhou, and Yi Chang. 2018. Target-sensitive mem- ory networks for aspect sentiment classiﬁcation. In Proceedings of the 56th Annual Meeting of the Asso- ciation for Computational Linguistics (ACL), pages 957–967. Wenya Wang, Sinno Jialin Pan, Daniel Dahlmeier, and Xiaokui Xiao. 2016a. Recursive neural conditional random ﬁelds for aspect-based sentiment analysis. arXiv preprint arXiv:1603.06679. Wenya Wang, Sinno Jialin Pan, Daniel Dahlmeier, and Xiaokui Xiao. 2017. Coupled multi-layer attentions for co-extraction of aspect and opinion terms. In Proceedings of the 31st AAAI Conference on Arti- ﬁcial Intelligence (AAAI), pages 3316–3322. Yequan Wang, Minlie Huang, Xiaoyan Zhu, and Li Zhao. 2016b. Attention-based lstm for aspect- level sentiment classiﬁcation. In Proceedings of the 2016 conference on empirical methods in natural language processing (EMNLP), pages 606–615. 