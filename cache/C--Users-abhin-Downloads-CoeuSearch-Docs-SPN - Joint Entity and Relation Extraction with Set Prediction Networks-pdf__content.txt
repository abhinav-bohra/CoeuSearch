Joint Entity and Relation Extraction with Set Prediction Networks Dianbo Sui♥ ♠ Yubo Chen♥ Kang Liu♥ ♠ Jun Zhao♥ ♠ Xiangrong Zeng ♦ Shengping Liu ♦ ♥ National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China ♠ University of Chinese Academy of Sciences, Beijing, China ♦ Beijing Unisound Information Technology Co., Ltd, Beijing, China {dianbo.sui, yubo.chen, kliu, jzhao}@nlpr.ia.ac.cn, {zengxiangrong, liushengping}@unisound.com 0 2 0 2 v o N 5 ] L C . s c [ 2 v 5 7 6 1 0 . 1 1 0 2 : v i X r a Abstract The joint entity and relation extraction task aims to extract all relational triples from a sentence. In essence, the rela- tional triples contained in a sentence are unordered. How- ever, previous seq2seq based models require to convert the set of triples into a sequence in the training phase. To break this bottleneck, we treat joint entity and relation extraction as a direct set prediction problem, so that the extraction model can get rid of the burden of predicting the order of multiple triples. To solve this set prediction problem, we propose net- works featured by transformers with non-autoregressive par- allel decoding. Unlike autoregressive approaches that gener- ate triples one by one in a certain order, the proposed net- works directly output the ﬁnal set of triples in one shot. Fur- thermore, we also design a set-based loss that forces unique predictions via bipartite matching. Compared with cross- entropy loss that highly penalizes small shifts in triple or- der, the proposed bipartite matching loss is invariant to any permutation of predictions; thus, it can provide the proposed networks with a more accurate training signal by ignoring triple order and focusing on relation types and entities. Ex- periments on two benchmark datasets show that our pro- posed model signiﬁcantly outperforms current state-of-the- art methods. Training code and trained models will be avail- able at http://github.com/DianboWork/SPN4RE. Introduction A relational triple consists of two entities connected by a se- mantic relation, which is in the form of (subject, relation, ob- ject). The extraction of relational triples from unstructured raw texts is a key technology for automatic knowledge graph construction, which has received growing interest in recent years. There have been several studies addressing technical so- lutions for relational triple extraction. Early researches, such as Zelenko, Aone, and Richardella (2003); Chan and Roth (2011), employ a pipeline manner to extract both of entities and relations, where entities are recognized ﬁrst and then the relation between the extracted entities is predicted. Such a pipeline approach ignores the relevance of entity identiﬁ- cation and relation prediction (Li and Ji 2014) and tends to suffer from the error propagation problem. To model cross-task dependencies explicitly and prevent error propagation in the pipeline approach, subsequent stud- ies propose joint entity and relation extraction. These stud- ies can be roughly categorized into three main paradigms. The ﬁrst stream of work, such as Miwa and Bansal (2016); Gupta, Sch¨utze, and Andrassy (2016); Zhang, Zhang, and Fu (2017), treats joint entity and relation extraction task as an end-to-end table ﬁlling problem. Although these meth- ods represent entities and relations with shared parame- ters in a single model, they extract the entities and rela- tions separately and produce redundant information (Zheng et al. 2017). The second stream of work, such as Zheng et al. (2017); Dai et al. (2019); Wei et al. (2020), trans- forms joint entity and relation extraction into sequence la- beling. To do this, human experts need to design a complex tagging schema. The last stream of work, including Zeng et al. (2018, 2019); Nayak and Ng (2020); Zeng, Zhang, and Liu (2020), is driven by the sequence-to-sequence (seq2seq) model (Sutskever, Vinyals, and Le 2014) to generate rela- tional triples directly, which is a ﬂexible framework to han- dle overlapping triples and does not require the substantial effort of human experts. We follow the seq2seq based models for joint entity and relation extraction. Despite the success of existing seq2seq based models, they are still limited by the autoregressive de- coder and the cross-entropy loss. The reasons are as follows: the relational triples contained in a sentence have no intrin- sic order in essence. However, in order to adapt the autore- gressive decoder, whose output is a sequence, the unordered target triples must be sorted in a certain order during the training phase. Meanwhile, cross-entropy is a permutation- sensitive loss function, where a penalty is incurred for every triple that is predicted out of the position. Consequently, cur- rent seq2seq base models not only need to learn how to gen- erate triples, but also are required to consider the extraction order of multiple triples. In this work, we formulate the joint entity and relation ex- traction task as a set prediction problem, avoiding consider- ing the order of multiple triples. In order to solve the set pre- diction problem, we propose an end-to-end network featured by transformers with non-autoregressive parallel decoding and bipartite matching loss. In detail, there are three parts in the proposed set prediction networks (SPN): a sentence encoder, a set generator, and a set based loss function. First of all, we adopt the BERT model (Devlin et al. 2019) as the encoder to represent the sentence. Then, since an autoregres- sive decoder must generate items one by one in order, such a             decoder is not suitable for generating unordered sets. In con- trast, we leverage the transformer-based non-autoregressive decoder (Gu et al. 2018) as the set generator, which can pre- dict all triples at once and avoid sorting triples. Finally, in order to assign a predicted triple to a unique ground truth triple, we propose bipartite matching loss function inspired by the assigning problem in operation research (Kuhn 1955; Munkres 1957; Edmonds and Karp 1972). Compared with cross-entropy loss that highly penalizes small shifts in triple order, the proposed loss function is invariant to any permu- tation of predictions; thus it is suitable for evaluating the dif- ference between ground truth set and prediction set. In a nutshell, our main contributions are: • We formulate the joint entity and relation extraction task as a set prediction problem. • We combine non-autoregressive parallel decoding with bipartite matching loss function to solve this problem. • Our proposed method yields state-of-the-art results on two benchmark datasets, and we perform various exper- iments to verify the effectiveness of the method. Related Work Relation Extraction Relation extraction is a long-standing natural language pro- cess task of mining factual knowledge from free texts. When giving a sentence with annotated entities, this task degener- ates into a simple task, namely relation classiﬁcation. Some studies, such as Zeng et al. (2014); Xu et al. (2015), lever- aged CNN or RNN to solve the relation classiﬁcation task. However, these methods ignore the extraction of entities from sentences and could not truly extract relational facts. When giving a sentence without any annotated entities, researchers proposed several methods to extract entities and relations jointly. Existing studies on multiple relation extrac- tion task can be divided into four paradigms: (1) Pipeline based methods, such as Zelenko, Aone, and Richardella (2003); Chan and Roth (2011), ﬁrstly recognize entities and then conduct relation classiﬁcation; (2) Table ﬁlling based methods, like Miwa and Bansal (2016); Gupta, Sch¨utze, and Andrassy (2016); Zhang, Zhang, and Fu (2017), represent entities and relations with shared parameters, but extract the entities and relations separately; (3) Tagging based meth- ods, such as Zheng et al. (2017); Dai et al. (2019); Wei et al. (2020), treat this task as a sequence labeling problem and need to design complex tagging schema; (4) Seq2seq based methods, like Zeng et al. (2018, 2019); Nayak and Ng (2020); Zeng, Zhang, and Liu (2020), apply seq2seq model to generate relational triples directly. Our work is in line with seq2seq based methods. In contrast with the previous stud- ies, we reckon the triples in a sentence are in the form of a set instead of a sequence, and treat the joint entity and relation extraction as a set prediction problem. Non-Autoregressive Model Non-autoregressive models (Gu et al. 2018; Lee, Mansi- mov, and Cho 2018; Ma et al. 2019) generate all the to- kens of a target in parallel and can speed up inference. Non- autoregressive models are widely explored in natural lan- guage and speech processing tasks such as neural machine translation (Gu et al. 2018) and automatic speech recogni- tion (Chen et al. 2019). To the best of our knowledge, this is the ﬁrst work to apply non-autoregressive models to in- formation extraction. In this work, we resort to the non- autoregressive model to generate the set of triples in one shot. Method The goal of joint entity and relation extraction is to identify all possible relational triples in a given sentence. Formally, given an raw sentence X, the conditional probability of the target triple set Y = {(s1, r1, o1), ..., (sn, rn, on)} is: P (Y |X; θ) = pL(n|X) n (cid:89) i=1 p(Yi|X, Yj(cid:54)=i; θ) (1) where pL(n|X) model the size of the target triple set, and p(Yi|X, Yj(cid:54)=i; θ) means that a target triple Yi is related not only to the given sentence X, but also to the other triples Yj(cid:54)=i. In this paper, this conditional probability is parameterized using set prediction networks (SPN), which are shown in Figure 1. Three key components of the proposed networks will be elaborated in the following section. Concretely, we ﬁrst introduce the sentence encoder, which represents each token in a given sentence based on its bidirectional con- text. Then, we present how to use the non-autoregressive decoder to generate a set of triples in a single pass. Finally, we describe a set-based loss, dubbed as bipartite matching loss, which forces unique matching between predicted and ground truth triples. Sentence Encoder The goal of this component is to obtain the context-aware representation of each token in a sentence. Given the im- pressive performance of recent deep transformers (Vaswani et al. 2017) trained on variants of language modeling, we utilize the BERT model (Devlin et al. 2019) as the sentence encoder. The input sentence is segmented with tokens by the byte pair encoding (Sennrich, Haddow, and Birch 2016), and then fed into the BERT model. The output of the BERT model is the context-aware embedding of tokens, and is de- noted as He ∈ Rl×d, where l is the sentence length (includ- ing [CLS] and [SEP], two special start and end markers), and d is the number of hidden units in the BERT model. Non-Autoregressive Decoder for Triple Set Generation We regard joint entity and relation extraction as a set prediction problem and use the transformer-based non- autoregressive decoder (Gu et al. 2018) to directly gener- ate the triple set. Previous studies (Zeng et al. 2018, 2019; Nayak and Ng 2020; Zeng, Zhang, and Liu 2020) transform the triple set to a triple sequence and then leverage the au- toregressive decoder to generate triples one by one. In such Figure 1: The main architecture of set prediction networks. The set prediction networks predict the ﬁnal set of triples in parallel by combining a BERT encoder with a non-autoregressive decoder. In the training phrase, bipartite matching uniquely assigns predictions with ground truths to provide accurate training signals. a way, the conditional probability of the target triple set in Equation 1 is modiﬁed into: P (Y |X; θ) = n (cid:89) i=1 p(Yi|X, Yj<i; θ) (2) In contrast, we use the non-autoregressive decoder to di- rect model the Equation 1. Compared with previous seq2seq based method, the non-autoregressive decoder can not only avoid learning the extraction order of multiple triples, but also generate triples based on bidirectional information, not just left-to-right information. Input. Before decoding starts, the decoder need to know the size of the target set, in other words, pL(n|X) in Equa- tion 1 is required to be modeled at ﬁrst. In this work, we simplify the pL(n|X) into a constant by requiring the non- autoregressive decoder to generate a ﬁxed-size set of m pre- dictions for each sentence, where m is set to be signiﬁcantly larger than the typical number of triples in a sentence. In- stead of copying tokens from the encoder side (Gu et al. 2018), the input of the decoder is initialized by m learnable embeddings that we refer to as triple queries. Note that all sentences share the same triple queries. Architecture. The non-autoregressive decoder is com- posed of a stack of N identical transformer layers. In each transformer layer, there are multi-head self attention mech- anism to model the relationship between triples, and multi- head inter attention mechanism to fuse the information of the given sentence. Notably, compared with autoregressive decoder, the non-autoregressive decoder does not have the constraint of an autoregressive factorization of the output, so there is no need to prevent earlier decoding steps from accessing information from later steps. Thus, there is no ca- sual mask used in the multi-head self attention mechanism. Instead, we use the unmasked self-attention. The m triple queries are transformed into m output em- beddings by the non-autoregressive decoder, which are de- noted as Hd ∈ Rm×d. The output embeddings Hd are then independently decoded into relation types and entities by feed forward networks (FFN), resulting m ﬁnal predicted triples. Concretely, given an output embedding hd ∈ Rd in Hd, the predicted relation type is obtained by: pr = softmax(Wrhd) (3) and the predicted entities (subject and object) are decoded by separately predicting the starting and ending indices with four l-class classiﬁers: ps−start = softmax(vT ps−end = softmax(vT po−start = softmax(vT po−end = softmax(vT 1 tanh(W1hd + W2He)) 2 tanh(W3hd + W4He)) 3 tanh(W5hd + W6He)) 4 tanh(W7hd + W8He)) (4) (5) (6) (7) where Wr ∈ Rt×d, {Wi ∈ Rd×d}8 i=1 are learnable parameters, t is the total number of relation types (including a special relation type ∅ to indicate no triple), l is the sentence length, and He is the output of the BERT model. i=1 and {vi ∈ Rd}4 Bipartite Matching Loss The main difﬁculty of training is to score the predicted triples with respect to the ground truths. It is not proper to apply cross-entropy loss function to measure the differ- ence between two sets, since cross-entropy loss is sensitive to the permutation of the predictions. Inspired by the assign- ing problem in operation research (Kuhn 1955), we propose a set prediction loss that can produce an optimal bipartite matching between predicted and ground truth triples. EmbEmbEmbEmbEmbBERT ModelEmbEmbEmbEmbSentenceTriple QueriesFFNFFNFFNFFNNon-Autoregressive DecoderNPredictionsGround-TruthsFeed Forward NetworkMulti-Head Self-AttentionSentence EncoderMulti-Head Inter-AttentionEntities,RelationNoTripleEntities,RelationNoTriple(s2, r2, o2)(s1, r1, o1)∅∅Bipartite Matching LossNotations. Let us denote by Y = {Yi}n i=1 the set of ground truth triples, and ˆY = { ˆYi}m i=1 the set of m pre- dicted triples, where m is larger than n. We consider Y also as a set of size m padded with ∅ (no triple). Each element i of the ground truth set can be seen as a Yi = (ri, sstart ), where ri is the target rela- i tion type (which may be ∅) and sstart , oend , send i i are the starting or ending indices of subject s or object o. Each element i of the set of predicted triples is denoted as ˆYi = (pr i , ps−start ), which is i i calculated based on Equation 3-7. , po−end i , ps−end i , po−start , ostart i , ostart i , oend i , send i i Loss. The process of computing bipartite matching loss is divided into two steps: ﬁnding an optimal matching and computing the loss function. To ﬁnd an optimal matching between the set of ground truth triples Y and the set of predicted triples ˆY, we search for a permutation of elements π(cid:63) with the lowest cost: m (cid:88) Cmatch(Yi, ˆYπ(i)) (8) π(cid:63) = arg min π∈Π(m) i=1 where Π(m) is the space of all m-length permutations. Cmatch(Yi, ˆYπ(i)) is a pair-wise matching cost between the ground truth Yi and the predicted triple with index π(i). By taking into account both the prediction of relation type and the predictions of entity spans, we deﬁne Cmatch(Yi, ˆYπ(i)) as: π(i)(ri) ) Cmatch(Yi, ˆYπ(i)) = −1{ri(cid:54)=∅}[pr (sstart i (send i (ostart i (oend i + ps−start π(i) + ps−end π(i) + po−start π(i) + po−end π(i) )] ) (9) ) This optimal assignment π(cid:63) is computed in polynomial time (O(m3)) via the Hungarian algorithm 1. In detail, we can view the set of ground truth Y as a set of people in the assignment problem, the set of predicted triples ˆY as a set of jobs. The cost of assigning Yi (the people i) with ˆYj (the job j) is deﬁned as Cmatch(Yi, ˆYj). The optimal matching with the minimum total cost is easy to be computed via the classical Hungarian algorithm. The second step is to compute the loss function for all pairs matched in the previous step. We deﬁne the loss as: L(Y, ˆY) = m (cid:88) {− log pr π(cid:63)(i)(ri) i=1 π(cid:63)(i) + 1{ri(cid:54)=∅}[− log ps−start − log ps−end π(cid:63)(i) (send − log po−start i (ostart i ) ) (sstart i ) (10) π(cid:63)(i) − log po−end π(cid:63)(i) (oend where π(cid:63) is the optimal assignment computed in the ﬁrst step (Equation 11). )]} i 1https://en.wikipedia.org/wiki/Hungarian algorithm Experiments In this section, we carry out an extensive set of experiments with the aim of answering the following research questions: • RQ1: What is the overall performance of the proposed set prediction networks (SPN) in joint entity and relation extraction? • RQ2: How does each design of our model matter? • RQ3: What is the performance of the proposed model in sentences annotated with different numbers of triples? • RQ4: How does our proposed model adapt to different overlapping patterns? In the remainder of this section, we describe the datasets, experimental setting, and all baselines. Datasets We evaluate the proposed method on two widely used joint entity and relation extraction datasets: New York Times (NYT) (Riedel, Yao, and McCallum 2010) and WebNLG (Gardent et al. 2017) 2. The statistics of these datasets are shown in Table 1. NYT. This dataset is produced by the distantly supervised method, which automatically aligns Freebase with 1987- 2007 New York Times news articles. There are 24 predeﬁned relation types in total. Following previous studies (Zheng et al. 2017; Zeng et al. 2018), we ignore the noise in this dataset and treat it as a supervised dataset. Since there are many versions of the NYT dataset, we adopted the prepro- cessed dataset used in Zeng et al. (2018), which is publicly available. WebNLG. This data is originally created for Natural Lan- guage Generation (NLG) task. In this dataset, an instance in- cludes a set of triples and several standard sentences written by humans. Every standard sentence contains all triples of this instance. There are 246 predeﬁned relation types in this dataset. Overlap Between Triples. According to different over- lapping patterns of triples, sentences are split into three categories (Zeng et al. 2018): Normal, Entity Pair Overlap (EPO) and Single Entity Overlap (SEO). A sentence belongs to Normal class if none of its triples have overlapped enti- ties. A sentence belongs to EPO class if some of its triples have overlapped entity pairs. And a sentence belongs to SEO class if some of its triples have an overlapped entity and these triples don’t have overlapped entity pair. Note that a sentence can belongs to both EPO class and SEO class. Category Normal EPO SEO ALL NYT Train 37013 9782 14735 56195 Test 3266 978 1297 5000 WebNLG Train Test 246 1596 227 26 457 3406 703 5019 Table 1: The statistics of NYT and WebNLG. 2These datasets are available at https://github.com/ xiangrongzeng/copy re Models NovelTagging (Zheng et al. 2017) CopyRE-One (Zeng et al. 2018) CopyRE-Mul(Zeng et al. 2018) GraphRel-1p (Fu, Li, and Ma 2019) GraphRel-2p (Fu, Li, and Ma 2019) CopyRRL (Zeng et al. 2019) WDec(Nayak and Ng 2020) PNDec(Nayak and Ng 2020) CopyMTL-One (Zeng, Zhang, and Liu 2020) CopyMTL-Mul (Zeng, Zhang, and Liu 2020) Attention as Relation (Liu et al. 2020) CasRel (Wei et al. 2020) SPN (Ours) Partial Matching Exact Matching Precision Recall 31.7 53.1 56.6 57.3 60.0 67.2 - - - - - 89.5 91.7 62.4 59.4 61.0 62.9 63.9 77.9 - - - - - 89.7 93.3 F1 42 56.0 58.7 60.0 61.9 72.1 - - - - - 89.6 92.5 Precision Recall - - - - - - 88.1 80.6 72.7 75.7 88.1 90.1† 92.5 - - - - - - 76.1 77.3 69.2 68.7 78.5 88.5† 92.2 F1 - - - - - - 81.7 78.9 70.9 72.0 83.0 89.3 † 92.3 Table 2: Precision (%) , Recall (%) and F1 score (%) of our proposed SPN and state-of-the-art mehtods on the NYT test set. † indicates that the result is reproduced by us. Models NovelTagging CopyRE-One CopyRE-Mul GraphRel-1p GraphRel-2p CopyRRL CasRel SPN (Ours) Precision Recall 19.3 28.9 36.4 39.2 41.1 59.9 90.1 93.6 52.5 32.2 37.7 42.3 44.7 63.3 93.4 93.1 F1 28.3 30.5 37.1 40.7 42.9 61.6 91.8 93.4 Table 3: Precision (%) , Recall (%) and F1 score (%) of our proposed SPN and state-of-the-art mehtods on the WebNLG test set. Evaluation Metrics We adopt standard micro-F1 to evaluate the performance. A triple is regarded as correct if the relation type and the two corresponding entities are all correct. Notably, there are two ways to judge whether the extracted entities are correct. One is Partial Matching, where the extracted entities are re- garded as correct if the predictions of subject and object are the same as the head words of the ground truth. Since the head word of entity is not annotated in most situations, the last word of entity is treated as the head word. The other is Exact Matching. In this way, only if the predictions of sub- ject and object are identical to the ground truth, the extracted entities are treated as correct. Note that the training data un- der partial matching is different from the one under exact matching. Under partial matching, only head words of en- tities are annotated, while the whole entities are annotated under exact matching. Implementation Details To conduct a fair comparison, we use the cased base version of BERT in our experiments, which contains 110M param- eters. The initial learning rate of BERT is set to 0.00001, and the initial learning of the non-autoregressive decoder is set to 0.00002. The number of stacked bidirectional trans- former blocks in non-autoregressive decoder is set to 3. We use the dropout strategy to mitigate overﬁtting, the dropout rate is set to 0.1. Meanwhile, We apply gradient clipping to prevent exploding gradients. The set prediction networks are trained by minimizing the loss function deﬁned in Equation 10 through stochastic gradient descent over shufﬂed mini- batch with the AdamW update rule (Loshchilov and Hut- ter 2017). All experiments are conducted with an NVIDIA GeForce RTX 2080 Ti. Baselines The following state-of-the-art (SoTA) models have been compared in the experiments. • NovelTagging (Zheng et al. 2017) introduces a novel tag- ging scheme that transforms the joint entity and relation extraction task into a sequence labeling problem. • CopyRE (Zeng et al. 2018) is a seq2seq based model with copy mechanism, which can effectively extract overlap- ping triples. • GraphRel (Fu, Li, and Ma 2019) is a two phases model based on graph convolutional networks (GCN), where a relation-weighted GCN is utilized to model the interaction between entities and relations. • CopyRRL (Zeng et al. 2019) combines the reinforcement learning with a seq2seq model to automatically learn the extraction order of triples. In such a way, the interactions among triples can be considered. • CopyMTL (Zeng, Zhang, and Liu 2020) is a multi-task learning framework, where conditional random ﬁeld is used to identify entities, and a seq2seq model is adopted to extract relational triples. • WDec (Nayak and Ng 2020) fuses a seq2seq model with a new representation scheme, which enables the decoder to generate one word at a and can handle full entity names of different length and overlapping entities. Models Element CasRel (Wei et al. 2020) SPN (Ours) (s,o) r Overall (s, o) r Overall NYT Precsoion Recall 90.1 93.8 89.5 92.7 95.7 91.7 89.2 96.0 89.7 93.2 96.3 93.3 F1 89.7 94.9 89.6 92.9 96.0 92.5 WebNLG Precision Recall 91.7 91.5 90.1 95.4 95.7 93.6 95.3 96.6 93.4 95.0 95.2 93.1 F1 93.5 94.0 91.8 95.2 95.4 93.4 Table 4: Results on extracting elements of relational triples. • PNDec (Nayak and Ng 2020) is a modiﬁcation of seq2seq model. Pointer networks are used in the decoding frame- work to identify the entities in the sentence using their start and end locations. • Attention as Relation (Liu et al. 2020) contains a condi- tional random ﬁeld based entity extraction module and a supervised multi-head self attention based relation detec- tion module. • CasRel (Wei et al. 2020) is a novel cascade binary tag- ging framework, where all possible subjects are identiﬁed in the ﬁrst stage, and then for each identiﬁed subject, all possible relations and the corresponding objects are si- multaneously identiﬁed by a relation speciﬁc tagger. This work achieves the SoTA results. Note that Li and Tian (2020) claimed that they have achieved the SoTA results in WebNLG, but we ﬁnd that the model they proposed is only designed for relation classiﬁca- tion. Therefore, we do not compare our method with REDN (Li and Tian 2020). Main Results To start, we address the research question RQ1. Table 2 and Table 3 show the results of our model against baselines on two benchmark datasets. Overall, our proposed model sig- niﬁcantly outperforms baselines on these datasets. In NYT dataset, Our proposed model outperforms all the baselines in both partial matching and exact matching and achieves 2.9% and 3.0% improvements in F1 score respec- tively over the current SoTA method (Wei et al. 2020). Com- bined with Table 4, we ﬁnd that our proposed model outper- forms the SoTA model (Wei et al. 2020) in both entity pair extraction and relation type extraction, demonstrating the ef- fectiveness of our proposed model. We also ﬁnd that there is an obvious gap between the F1 score on relation type ex- traction and entity pair extraction, but a trivial gap between entity pair extraction and overall extraction. It reveals that entity pair extraction is the main bottleneck of joint entity and relation extraction in NYT dataset. In WebNLG dataset, since there is no uniﬁed version of data under exact matching, we only compare our proposed networks with baselines under partial matching metric. In general, our proposed model achieves the best F1 score un- der partial matching, which is 93.4%. There is 1.6% im- provement compared with the result of the SoTA model (Wei et al. 2020), which is 91.8%. Compared with the SoTA Bipartite Matching Loss, Num of Decoder Layers = 3 Bipartite Matching Loss, Num of Decoder Layers = 2 Bipartite Matching Loss, Num of Decoder Layers = 1 Cross-Entropy Loss, Num of Decoder Layers = 3 Precision Recall F1 93.3 92.7 91.9 87.2 91.7 92.5 91.3 92.0 90.9 91.4 80.9 84.0 Table 5: Results of ablation studies on NYT dataset. model, We ﬁnd our model to be more balanced in terms of precision and recall. A further analysis combined with Table 4 shows that our proposed model exhibits balanced results of precision and recall in both entity pair extraction and relation type extraction, while there is an obvious gap between pre- cision and recall in the results of CasRel (Wei et al. 2020). We conjecture that this is largely due to that the number of triple queries is set to be signiﬁcantly larger than the typical number of triples in a sentence, which ensures that enough triples can be recalled. In addition, we observe that the re- sults of entity pair extraction and relation type extraction are much higher than that of joint entity and relation extraction, which means that the accurate combination of entity pair ex- traction and relation type extraction is the key to improve the joint entity and relation extraction. Ablation Studies Next, we turn to the research question RQ2. We conduct ablation studies to investigate the importance of the non- autoregressive decoder and the bipartite matching loss. To evaluate the importance of the non-autoregressive decoder, we change the number of decoder layers. To evaluate the importance of bipartite matching loss, we replacing bipar- tite matching loss with cross-entropy loss. Table 5 shows the results. We ﬁnd that increasing the number of layers of the non-autoregressive decoder can achieve better results. When the number of decoder lay- ers is set to 1, 2, and 3, the best results are 91.4%, 92.0% and 92.15%, respectively. We conjecture that this is largely due to that with the deepening of the non-autoregressive de- coder layers, more multi-head self attention modules allow for better modeling of relationships between triple queries, and more multi-head inter attention modules allow for more Models CopyRE-One (Zeng et al. 2018) CopyRE-Mul (Zeng et al. 2018) GraphRel-1p (Fu, Li, and Ma 2019) GraphRel-2p (Fu, Li, and Ma 2019) CopyRRL (Zeng et al. 2019) CasRel (Wei et al. 2020) SPN (Ours) NYT WebNLG N=1 N=2 N=3 N=4 N≥5 N=1 N=2 N=3 N=4 N≥5 13.2 66.6 30.0 67.1 29.4 69.1 32.1 71.0 55.7 71.7 90.9 88.2 93.8 90.9 65.2 59.2 63.8 66.0 63.4 89.3 89.5 52.6 58.6 59.5 61.5 72.6 90.3 93.4 49.7 52.0 54.4 57.4 72.5 91.9 94.2 33.0 42.5 46.3 48.3 62.2 90.8 91.3 48.7 53.6 53.9 55.1 77.9 94.2 95.5 22.2 31.7 34.7 37.0 64.4 94.2 96.4 20.3 30.0 37.5 41.1 45.9 83.7 90.6 14.2 24.2 30.8 32.1 57.2 92.4 94.7 Table 6: Partial matching F1 score of conducting extraction in sentences that contains different numbers of triples. We divide the sentences of the test sets into 5 sub-classes. Each class contains sentences that have 1,2,3,4 or ≥5 triples. complete integration of sentence information into triple queries. Compared our proposed bipartite matching loss with widely used cross-entropy loss, we ﬁnd that there is 8.9% improvement, which indicates bipartite matching loss is very suitable for joint entity and relation extraction. We hypoth- esize that in order to adopt to cross-entropy loss, the model is required to consider the generative order of triples, which places an unnecessary burden on the model. Detailed Results on Sentences with Different Number of Triples In this section, we answer the research question RQ3. To do this, we compare the models’ ability of extracting rela- tional facts from sentences annotated with different num- bers of triples. We divide the sentences in test sets into 5 sub-classes. Each class contains sentences that have 1, 2, 3, 4 or ≥5 triples. The results are shown in Table 6. In gen- eral, our proposed model achieves the best results in all sub-classes. Besides, we observe that though the our pro- posed model gains considerable improvements on all ﬁve sub-classes compared to the SoTA model (Wei et al. 2020), the greatest improvement of F1 score on the two datasets both come from the most difﬁcult sub-class (N≥5), in par- ticular, there is 6.9% improvement in the NYT data. Such results indicate that our proposed model is more suitable for complicated scenarios than the current SoTA model. Detailed Results on Different Overlapping Patterns Finally, to address the research question RQ4, we conduct further experiments on NYT dataset to verify the ability of our proposed model in handling the overlapping problem. Figure 2 shows the results of our proposed model and base- line models in Normal, Single Entity Overlap (SEO) and En- tity Pair Overlap (EPO) classes. Overall, our proposed model performs better than all baseline models in all three classes. In details, there are 3.5%, 2.6% and 2.1% improvements compared with the SoTA model (Wei et al. 2020) in Normal, SEO and EPO classes, respectively. Such results show that our proposed model is very effective in handling the overlapping prob- lem, which is widely existed in joint entity and relation ex- traction. In addition, We also observe that the performance of all seq2seq based models, such as CopyRE (Zeng et al. Figure 2: F1 score of extracting relational triples from sen- tences with different overlapping pattern in NYT dataset. 2018) and CopyRRL(Zeng et al. 2019), on Normal, EPO and SEO presents a decreasing trend, which indicates that the Normal class presents a relatively easiest pattern while EPO and SEO classes are the relatively harder ones for these seq2seq based models to extract. In contrast, our proposed model attains consistently strong performance over all three overlapping patterns. Conclusion and Future Work In this paper, we introduce set prediction networks for joint entity and relation extraction. Compared with previous seq2seq based models, We formulate the joint entity and re- lation extraction task as a set prediction problem. In such a way, the extraction model will be relieved of predicting the extraction order of multiple triples. To solve the set predic- tion problem, We combine non-autoregressive parallel de- coding with bipartite matching loss function. We conduct extensive experiments on two widely used datasets to val- idate the effectiveness of the proposed set prediction net- works. Experimental results show that our proposed net- works outperforms state-of-the-art baselines over different scenarios. This challenging task is far from being solved. We ﬁnd that relation types exhibit an imbalanced or long-tailed distribution in NYT dataset and WebNLG dataset. Our fu- ture work will concentrate on how to combine cost-sensitive learning with the proposed set prediction networks. References Chan, Y. S.; and Roth, D. 2011. Exploiting syntactico- semantic structures for relation extraction. In Proceedings of the 49th Annual Meeting of the Association for Computa- tional Linguistics: Human Language Technologies. Chen, N.; Watanabe, S.; Villalba, J.; and Dehak, N. 2019. Non-Autoregressive Transformer Automatic Speech Recog- nition. arXiv preprint arXiv:1911.04908 . Dai, D.; Xiao, X.; Lyu, Y.; Dou, S.; She, Q.; and Wang, H. 2019. Joint extraction of entities and overlapping relations using position-attentive sequence labeling. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence. Devlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Con- ference of the North American Chapter of the Association for Computational Linguistics: Human Language Technolo- gies. Edmonds, J.; and Karp, R. M. 1972. Theoretical improve- ments in algorithmic efﬁciency for network ﬂow problems. Journal of the ACM (JACM) 19(2): 248–264. Fu, T.-J.; Li, P.-H.; and Ma, W.-Y. 2019. GraphRel: Mod- eling text as relational graphs for joint entity and relation In Proceedings of the 57th Annual Meeting of extraction. the Association for Computational Linguistics. Gardent, C.; Shimorina, A.; Narayan, S.; and Perez- Beltrachini, L. 2017. Creating training corpora for nlg micro-planning. In Proceedings of the 55th Annual Meet- ing of the Association for Computational Linguistics. Gu, J.; Bradbury, J.; Xiong, C.; Li, V. O.; and Socher, R. 2018. Non-Autoregressive Neural Machine Translation. In International Conference on Learning Representations. Gupta, P.; Sch¨utze, H.; and Andrassy, B. 2016. Table ﬁll- ing multi-task recurrent neural network for joint entity and In Proceedings of COLING 2016, the relation extraction. 26th International Conference on Computational Linguis- tics: Technical Papers. Kuhn, H. W. 1955. The Hungarian method for the assign- ment problem. Naval research logistics quarterly 2(1-2): 83–97. Lee, J.; Mansimov, E.; and Cho, K. 2018. Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Reﬁnement. In Proceedings of the 2018 Conference on Em- pirical Methods in Natural Language Processing. Li, C.; and Tian, Y. 2020. Downstream Model Design of Pre-trained Language Model for Relation Extraction Task. arXiv preprint arXiv:2004.03786 . Li, Q.; and Ji, H. 2014. Incremental joint extraction of entity mentions and relations. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics. Liu, J.; Chen, S.; Wang, B.; Zhang, J.; Li, N.; and Xu, T. 2020. Attention as Relation: Learning Supervised Multi- head Self-Attention for Relation Extraction. In Proceedings of the Twenty-Ninth International Joint Conference on Arti- ﬁcial Intelligence. Loshchilov, I.; and Hutter, F. 2017. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101 . Ma, X.; Zhou, C.; Li, X.; Neubig, G.; and Hovy, E. 2019. FlowSeq: Non-Autoregressive Conditional Sequence Gener- ation with Generative Flow. In Proceedings of the 2019 Con- ference on Empirical Methods in Natural Language Pro- cessing and the 9th International Joint Conference on Natu- ral Language Processing. Miwa, M.; and Bansal, M. 2016. End-to-End Relation Ex- traction using LSTMs on Sequences and Tree Structures. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. Munkres, J. 1957. Algorithms for the assignment and trans- portation problems. Journal of the society for industrial and applied mathematics 5(1): 32–38. Nayak, T.; and Ng, H. T. 2020. Effective Modeling of Encoder-Decoder Architecture for Joint Entity and Relation Extraction. In Proceedings of The Thirty-Fourth AAAI Con- ference on Artiﬁcial Intelligence. Riedel, S.; Yao, L.; and McCallum, A. 2010. Modeling rela- tions and their mentions without labeled text. In Joint Euro- pean Conference on Machine Learning and Knowledge Dis- covery in Databases, 148–163. Springer. Sennrich, R.; Haddow, B.; and Birch, A. 2016. Neural Ma- chine Translation of Rare Words with Subword Units. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. Sutskever, I.; Vinyals, O.; and Le, Q. V. 2014. Sequence to sequence learning with neural networks. In Advances in neural information processing systems. Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, Ł.; and Polosukhin, I. 2017. At- tention is all you need. In Advances in neural information processing systems. Wei, Z.; Su, J.; Wang, Y.; Tian, Y.; and Chang, Y. 2020. A Novel Cascade Binary Tagging Framework for Relational Triple Extraction. In Proceedings of the 58th Annual Meet- ing of the Association for Computational Linguistics. Xu, Y.; Mou, L.; Li, G.; Chen, Y.; Peng, H.; and Jin, Z. 2015. Classifying relations via long short term memory net- works along shortest dependency paths. In Proceedings of the 2015 Conference on Empirical Methods in Natural Lan- guage Processing. Zelenko, D.; Aone, C.; and Richardella, A. 2003. Kernel methods for relation extraction. Journal of machine learning research 3(Feb): 1083–1106. Zeng, D.; Liu, K.; Lai, S.; Zhou, G.; and Zhao, J. 2014. Relation Classiﬁcation via Convolutional Deep Neural Net- work. In Proceedings of COLING 2014, the 25th Interna- tional Conference on Computational Linguistics: Technical Papers. Zeng, D.; Zhang, H.; and Liu, Q. 2020. CopyMTL: Copy Mechanism for Joint Extraction of Entities and Relations with Multi-Task Learning. In Proceedings of the AAAI Con- ference on Artiﬁcial Intelligence. Zeng, X.; He, S.; Zeng, D.; Liu, K.; Liu, S.; and Zhao, J. 2019. Learning the extraction order of multiple relational facts in a sentence with reinforcement learning. In Proceed- ings of the 2019 Conference on Empirical Methods in Nat- ural Language Processing and the 9th International Joint Conference on Natural Language Processing. Zeng, X.; Zeng, D.; He, S.; Liu, K.; and Zhao, J. 2018. Ex- tracting relational facts by an end-to-end neural model with copy mechanism. In Proceedings of the 56th Annual Meet- ing of the Association for Computational Linguistics. Zhang, M.; Zhang, Y.; and Fu, G. 2017. End-to-end neural relation extraction with global optimization. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Zheng, S.; Wang, F.; Bao, H.; Hao, Y.; Zhou, P.; and Xu, B. 2017. Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. Hungarian Algorithm The Hungarian method is a combinatorial optimization algorithm that solves the assignment problem in polynomial time. The Hungarian algorithm consists of the four steps below. The ﬁrst two steps are executed once, while Steps 3 and 4 are repeated until an optimal assignment is found. The input of the algorithm is an m × m by m square matrix, called cost matrix. Step 1: Subtract row minima. For each row, ﬁnd the lowest element and subtract it from each element in that row. Step 2: Subtract column minima. Similarly, for each column, ﬁnd the lowest element and subtract it from each element in that column. Step 3: Cover all zeros with a minimum number of lines. Cover all zeros in the resulting matrix using a minimum number of horizontal and vertical lines. If m lines are required, an optimal assignment exists among the zeros. The algorithm stops. If less than m lines are required, continue with Step 4. Step 4: Create additional zeros Find the smallest element (call it k) that is not covered by a line in Step 3. Subtract k from all uncovered elements, and add k to all elements that are covered twice. An Example of Bipartite Matching Loss We use an example to illustrate how bipartite matching loss function works. In this example, we assume that there are only three relation types that we are interested in. These three relation types are leader name, located in and capital Of. As shown in this paper, a special relation type ∅ is also required. Furthermore, we assume that the non-autoregressive decoder generate 3 triples for each sen- tence, in other words, m is set to 3. The sentence, the ground-truths and the predictions are presented as follows: Sentence Aarhus airport serves the city of Aarhus , which is led by Jacob Bundsgaard . Ground-truths (Aarhus, leader name, Jacob Bundsgaard) (Aarhus Airport, located in, Aarhus) ∅ (padding a no triple to match m) The indices of Aarhus Airport, Aarbus and Jacob Bundsgaard are (0, 1), (6, 6) and (12, 13) respectively. We also convert each relations type to a unique integer. In detail, leader name, located in, capital Of and ∅ are converted to 0, 1, 2, 3 respectively. In such a way, ground-truths are represented as: Y0 = {0, 6, 6, 12, 13} Y1 = {1, 0, 1, 6, 6} Y2 = {3} Predictions We assume that the outputs of the set prediction networks are as follow: ˆY0 = { pr 0 ps−start 0 ps−end 0 po−start 0 po−end 0 } ˆY1 = { pr 1 ps−start 1 ps−end 1 po−start 1 po−end 1 } ˆY2 = { pr 2 ps−start 2 ps−end 2 po−start 2 po−end 2 } : (0.1, 0.3, 0.4, 0.2) : (0.9, 0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) : (0.2, 0.8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) : (0.1, 0.1, 0, 0, 0, 0, 0.7, 0, 0, 0, 0, 0, 0.1, 0, 0) : (0, 0.1, 0, 0, 0, 0, 0.6, 0, 0, 0, 0, 0, 0.1, 0.2, 0) : (0.5, 0.25, 0.15, 0.1) : (0.1, 0, 0, 0, 0, 0, 0.8, 0, 0, 0, 0, 0, 0.1, 0, 0) : (0.2, 0.3, 0, 0, 0, 0, 0.5, 0, 0, 0, 0, 0, 0, 0, 0) : (0.2, 0.1, 0, 0, 0, 0, 0.2, 0, 0, 0, 0, 0, 0.5, 0, 0) : (0, 0.4, 0, 0, 0, 0, 0.3, 0, 0, 0, 0, 0, 0, 0.3, 0) : (0.1, 0.3, 0.4, 0.2) : (0.4, 0, 0, 0, 0, 0, 0.5, 0, 0, 0, 0, 0, 0.1, 0, 0) : (0.1, 0.4, 0, 0, 0, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0) : (0.3, 0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.7, 0, 0) : (0, 0.2, 0, 0, 0, 0, 0.4, 0, 0, 0, 0, 0, 0, 0.4, 0) Bipartite Matching Loss Recall that the loss is deﬁned as: L(Y, ˆY) = m (cid:88) i=1 {− log pr π(cid:63)(i)(ri) (sstart i ) π(cid:63)(i) + 1{ri(cid:54)=∅}[− log ps−start − log ps−end π(cid:63)(i) (send − log po−start i (ostart i ) ) π(cid:63)(i) − log po−end π(cid:63)(i) (oend Based on the optimal assignment π(cid:63), the value of loss func- tion is: L(Y, ˆY) ={− log pr (6) − log ps−end 1(0) − log ps−start )]} i 1 1 (6) − log po−start 1 + {− log pr − log po−start 0 + {− log pr 2(3)} (12) − log po−end 1 (13)} 0(1) − log ps−start 0 (6) − log po−end 0 (6)} (0) − log ps−end (1) 0 ={− log(0.5) − log(0.8) − log(0.5) − log(0.5) − log(0.3)} + {− log(0.3) − log(0.9) − log(0.8) − log(0.7) − log(0.6)} + {− log(0.2)} =7.52 The process of computing bipartite matching loss is divided into two steps: ﬁnding an optimal matching and computing the loss function. (1). Finding an optimal matching We search for a permutation of elements π(cid:63) with the lowest cost to ﬁnd an optimal matching between the set of ground truth triples Y and the set of predicted triples ˆY: π(cid:63) = arg min π∈Π(m) m (cid:88) i=1 Cmatch(Yi, ˆYπ(i)) (11) To do this, we need to determine the cost matrix, which is the input of Hungarian algorithm. The (i, j)-entry of cost matrix is Cmatch(Yi, ˆYj), where Cmatch(Yi, ˆYj) is deﬁne as: j (ri) ) Cmatch(Yi, ˆYj) = −1{ri(cid:54)=∅}[pr (sstart i (send ) i (ostart i (oend i + ps−start j + ps−end j + po−start j + po−end j )] ) Each entry of cost matrix is computed as follows: Cmatch(Y0, ˆY0) = −[0.1 + 0 + 0 + 0.1 + 0.2] = −0.4 Cmatch(Y0, ˆY1) = −[0.5 + 0.8 + 0.5 + 0.5 + 0.3] = −2.6 Cmatch(Y0, ˆY2) = −[0.1 + 0.5 + 0.5 + 0.7 + 0.3] = −2.1 Cmatch(Y1, ˆY0) = −[0.3 + 0.9 + 0.8 + 0.7 + 0.6] = −3.3 Cmatch(Y1, ˆY1) = −[0.25 + 0.1 + 0.3 + 0.2 + 0.3] = −1.15 Cmatch(Y1, ˆY2) = −[0.3 + 0.4 + 0.4 + 0 + 0.4] = −1.5 Cmatch(Y2, ˆY0) = 0 Cmatch(Y2, ˆY1) = 0 Cmatch(Y2, ˆY2) = 0 The cost matrix is denoted as follows: ˆY1 -2.6 -1.15 0 ˆY0 -0.4 -3.3 0 Y0 Y1 Y2 C = (cid:32) (cid:33) ˆY2 -2.1 -1.5 0 Via Hugarian algorithm, the optimal assignment π(cid:63) corre- sponding to the cost matrix is ground − truths :[0, 1, 2] −→ predictions :[1, 0, 2] which has the minimum total cost (-5.9 = (-2.6)+(-3.3)+0). (2). Computing the loss function based on the optimal assignment. 