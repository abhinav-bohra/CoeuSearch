A Uniﬁed Generative Framework for Aspect-Based Sentiment Analysis Hang Yan1,∗, Junqi Dai1,∗, Tuo Ji1, Xipeng Qiu1,2†, Zheng Zhang3 1Shanghai Key Laboratory of Intelligent Information Processing, Fudan University 1School of Computer Science, Fudan University 2Pazhou Lab, Guangzhou, China 3New York University {hyan19,jqdai19,tji19,xpqiu}@fudan.edu.cn zz@nyu.edu Abstract Aspect-based Sentiment Analysis (ABSA) aims to identify the aspect terms, their corre- sponding sentiment polarities, and the opinion terms. There exist seven subtasks in ABSA. Most studies only focus on the subsets of these subtasks, which leads to various compli- cated ABSA models while hard to solve these subtasks in a uniﬁed framework. In this pa- per, we redeﬁne every subtask target as a se- quence mixed by pointer indexes and senti- ment class indexes, which converts all ABSA subtasks into a uniﬁed generative formulation. Based on the uniﬁed formulation, we exploit the pre-training sequence-to-sequence model BART to solve all ABSA subtasks in an end- to-end framework. Extensive experiments on four ABSA datasets for seven subtasks demon- strate that our framework achieves substantial performance gain and provides a real uniﬁed end-to-end solution for the whole ABSA sub- tasks, which could beneﬁt multiple tasks1. 1 Introduction Aspect-based Sentiment Analysis (ABSA) is the ﬁne-grained Sentiment Analysis (SA) task, which aims to identify the aspect term (a), its correspond- ing sentiment polarity (s), and the opinion term (o). For example, in the sentence “The drinks are al- ways well made and wine selection is fairly priced”, the aspect terms are “drinks” and “wine selection”, and their sentiment polarities are both “positive”, and the opinion terms are “well made” and “fairly priced”. Based on the combination of the a, s, o, there exist seven subtasks in ABSA. We summa- rize these subtasks in Figure 1. Speciﬁcally, their deﬁnitions are as follows: ∗Equal contribution. † Corresponding author. 1Code is available at https://github.com/yhcc/ BARTABSA. Figure 1: Illustration of seven ABSA subtasks. • Aspect Term Extraction(AE): Extracting all the aspect terms from a sentence. • Opinion Term Extraction (OE): Extracting all the opinion terms from a sentence. • Aspect-level Sentiment Classiﬁcation (ALSC): Predicting the sentiment polarities for every given aspect terms in a sentence. • Aspect-oriented Opinion Extraction (AOE): Extracting the paired opinion terms for every given aspect terms in a sentence. • Aspect Term Extraction and Sentiment Clas- siﬁcation (AESC): Extracting the aspect terms as well as the corresponding sentiment polarities si- multaneously. • Pair Extraction (Pair): Extracting the aspect terms as well as the corresponding opinion terms simultaneously. • Triplet Extraction (Triplet): Extracting all as- pects terms with their corresponding opinion terms and sentiment polarity simultaneously. Although these ABSA subtasks are strongly re- lated, most of the existing work only focus 1∼3 subtasks individually. The following divergences make it difﬁcult to solve all subtasks in a uniﬁed framework. 1. Input: Some subtasks ( AE, OE, AESC, Pair SubtaskInputOutputTask TypeAspect Term Extraction(AE)Sa1, a2ExtractionOpinion Term Extraction(OE)So1,o2ExtractionAspect-level Sentiment Classification(ALSC)S+ a1s1ClassificationS + a2s2Aspect-oriented Opinion Extraction(AOE)S+ a1o1ExtractionS+ a2o2Aspect Term Extraction and Sentiment Classification(AESC)S(a1, s1), (a2, s2)Extraction & ClassificationPairExtraction(Pair)S(a1, o1), (a2, o2)ExtractionTripletExtraction(Triplet)S(a1,o1, s1), (a2, o2,s2)Extraction & ClassificationS:The drinksare always well madeand wine selectionis fairly priced . PositivePositivea1o1a2o2s1s2and Triplet) only take the text sentence as in- put, while the remained subtasks ( ALSC and AOE) take the text and a given aspect term as input. 2. Output: Some tasks (AE, OE, ALSC, AOE) only output a certain type from a, s or o, while the remained tasks (AESC, Pair and Triplet) return compound output as the combination of a, s and o. 3. Task Type: There are two kinds of tasks: ex- traction task (extracting aspect and opinion) and classiﬁcation task (predicting sentiment). Because of the above divergences, a myriad of previous works only focus on the subset of these subtasks. However, the importance of solving the whole ABSA subtasks in a uniﬁed framework re- mains signiﬁcant. Recently, several works make attempts on this track. Some methods(Peng et al., 2020; Mao et al., 2021) apply the pipeline model to output the a, s, o from the inside sub-models separately. However, the pipeline process is not end-to-end. Another line follows the sequence tag- ging method by extending the tagging schema (Xu et al., 2020). However, the compositionality of candidate labels hinders the performance. In con- clusion, the existing methods can hardly solve all the subtasks by a uniﬁed framework without re- lying on the sub-models or changing the model structure to adapt to all ABSA subtasks. Motivated by the above observations, we pro- pose a uniﬁed generative framework to address all the ABSA subtasks. We ﬁrst formulate all these subtasks as a generative task, which could han- dle the obstacles on the input, output, and task type sides and adapt to all the subtasks without any model structure changes. Speciﬁcally, we model the extraction and classiﬁcation tasks as the pointer indexes and class indexes generation, re- spectively. Based on the uniﬁed task formulation, we use the sequence-to-sequence pre-trained model BART (Lewis et al., 2020) as our backbone to gen- erate the target sequence in an end-to-end process. To validate the effectiveness of our method, we conduct extensive experiments on public datasets. The comparison results demonstrate that our pro- posed framework outperforms most state-of-the-art (SOTA) models in every subtask. In summary, our main contributions are as fol- lows: • We formulate both the extraction task and clas- siﬁcation task of ABSA into a uniﬁed index gen- eration problem. Unlike previous uniﬁed models, our method needs not to design speciﬁc decoders for different output types. • With our re-formulation, all ABSA subtasks can be solved in sequence-to-sequence framework, which is easy-to-implement and can be built on the pre-trained models, such as BART. • We conduct extensive experiments on four pub- lic datasets, and each dataset contains a subset of all ABSA subtasks. To the best of our knowledge, it is the ﬁrst work to evaluate a model on all ABSA tasks. • The experimental results show that our pro- posed framework signiﬁcantly outperforms recent SOTA methods. 2 Background 2.1 ABSA Subtasks In this section, we ﬁrst review the existing studies on single output subtasks, and then turn to studies focusing on the compound output subtasks. 2.1.1 Single Output Subtasks Some researches mainly focus on the single output subtasks. The AE, OE, ALSC and AOE subtasks only output one certain type from a, s or o. AE Most studies treat AE subtask as a se- quence tagging problem (Li and Lam, 2017; Xu et al., 2018; Li et al., 2018b). Recent works ex- plore sequence-to-sequence learning on AE sub- task, which obtain promissing results especially with the pre-training language models (Ma et al., 2019; Li et al., 2020). OE Most studies treat OE subtask as an auxiliary task (Wang et al., 2016a, 2017; Wang and Pan, 2018; Chen and Qian, 2020; He et al., 2019). Most works can only extract the unpaired aspect and opinion terms2. In this case, opinion terms are independent of aspect terms. ALSC Tang et al. (2016a) use the long short term memory (LSTM) network to enhance the interac- tions between aspects and context words. Wang et al. (2016b); Liu and Zhang (2017); Ma et al. (2017); Tay et al. (2018) incorporate the attention mechanism into the LSTM-based neural network models to model relations of aspects and their con- textual words. Other model structures such as con- volutional neural network (CNN) (Li et al., 2018a; Xue and Li, 2018), gated neural network (Zhang et al., 2016; Xue and Li, 2018), memory neural 2It is also referred to as the AE-OE co-Extraction. network (Tang et al., 2016b; Chen et al., 2017) have also been applied. AOE This subtask is ﬁrst introduced by Fan et al. (2019) and they propose the datasets for this sub- task. Most studies apply sequence tagging method for this subtask (Wu et al., 2020; Pouran Ben Vey- seh et al., 2020). 2.1.2 Compound Output Subtasks Some researchers pay more attention and efforts to the subtasks with compound output. We review them as follows: AESC. One line follows pipeline method to solve this problem. Other works utilize uniﬁed tagging schema (Mitchell et al., 2013; Zhang et al., 2015; Li et al., 2019) or multi-task learning (He et al., 2019; Chen and Qian, 2020) to avoid the error-propagation problem (Ma et al., 2018). Span- based AESC works are also proposed recently (Hu et al., 2019), which can tackle the sentiment incon- sistency problem in the uniﬁed tagging schema. Pairs Zhao et al. (2020) propose to extract all (a, o) pair-wise relations from scratch. They propose a multi-task learning framework based on the span- based extraction method to handle this subtask. Triplet This subtask is proposed by Peng et al. (2020) and gains increasing interests recently. Xu et al. (2020) design the position-aware tagging schema and apply model based on CRF (Lafferty et al., 2001) and Semi-Markov CRF (Sarawagi and Cohen, 2004). However, the time complexity lim- its the model to detect the aspect term with long- distance opinion terms. Mao et al. (2021) formulate Triplet as a two-step MRC problem, which applies the pipeline method. 2.2 Sequence-to-Sequence Models The sequence-to-sequence framework has been long studied in the NLP ﬁeld to tackle various tasks (Sutskever et al., 2014; Cho et al., 2014; Vinyals et al., 2015; Luong et al., 2015). Inspired by the success of PTMs (pre-trained models) (Qiu et al., 2020; Peters et al., 2018; Devlin et al., 2019; Brown et al., 2020), Song et al. (2019); Raffel et al. (2020); Lewis et al. (2020) try to pre-train sequence-to- sequence models. Among them, we use the BART (Lewis et al., 2020) as our backbone, while the other sequence-to-sequence pre-training models can also be applied in our architecture to use the pointer mechanism (Vinyals et al., 2015), such as MASS (Song et al., 2019). BART is a strong sequence-to-sequence pre- trained model for Natural Language Generation (NLG). BART is a denoising autoencoder com- posed of several transformer (Vaswani et al., 2017) encoder and decoder layers. It is worth noting that the BART-Base model contains a 6-layer encoder and 6-layer decoder, which makes it similar number of parameters3 with the BERT-Base model. BART is pretrained on denoising tasks where the input sentence is noised by some methods, such as mask- ing and permutation. The encoder takes the noised sentence as input, and the decoder will restore the original sentence in an autoregressive manner. 3 Methodology Although there are two types of tasks among the seven ABSA subtasks, they can be formulated un- der a generative framework. In this part, we ﬁrst introduce our sequential representation for each ABSA subtask. Then we detail our method, which utilizes BART to generate these sequential repre- sentations. 3.1 Task Formulation As depicted in Figure 1, there are two types of tasks, namely the extraction and classiﬁcation, whose target can be represented as a sequence of pointer indexes and class indexes, respectively. Therefore, we can formulate these two types of tasks in a uniﬁed generative framework. We use a, s, o, to represent the aspect term, sentiment polarity,and opinion term, respectively. Moreover, we use the superscript s and e to denote the start index and end index of a term. For example, os, ae represent the start index of an opinion term o and the end index of an aspect term a. We use the sp to denote the index of sentiment polarity class. The target sequence for each subtask is as follows: 1, ae • AE : Y = [as • OE : Y = [os 1, oe • AESC : Y = [as • Pair: Y = [as 1, ae • Triplet : Y = [as i , sp oe The above subtasks only rely on the input sen- tence, while for the ALSC and AOE subtasks, they also depend on a speciﬁc aspect term a. Instead of putting the aspect term on the input side, we put i , ae i , ...], i , oe i , ...], 1, ..., as 1, ..., as 1, sp 1, oe 1, ..., as 1, ..., os 1, sp 1, ae 1, oe 1, os 1, os 1, ae i , sp i , ae i , os i , ae 1, ..., as i , ...], i , oe i , ae i ,...], i , os i , i , ...], 3Because of the cross-attention between encoder and de- coder, the number of parameters of BART is about 10% larger than its counterpart of BERT (Lewis et al., 2020). Figure 2: Overall architecture of the framework. This shows an example generation process for the Triplet subtask where the source is “<s>the battery life is good </s>” and the target is “2 3 5 5 8 6”(Only partial decoder sequence is shown where the 6 (</s>) should be the next generation index). The “Index2Token Conversion” converts the index to tokens. Speciﬁcally, the pointer index will be converted to its corresponding token in the source text, and the class index will be converted to corresponding class tokens. Embedding vectors in ll boxes are retrieved from same embedding matrix. We use different position embeddings in the source and target for better generation performance. [y1, ..., ym], where y0 is the start-of-the-sentence token. Therefore, different ABSA subtasks can be formulated as: P (Y |X) = m (cid:89) t=1 P (yt|X, Y<t). (1) To get the index probability distribution Pt = P (yt|X, Y<t) for each step, we use a model com- posed of two components: (1) Encoder; (2) De- coder. Encoder The encoder part is to encode X into vectors He. We use the BART model, therefore, the start of sentence (<s>) and the end of sentence (</s>) tokens will be added to the start and end of X, respectively. We ignore the <s> token in our equations for simplicity. The encoder part is as follows: He = BARTEncoder([x1, ..., xn]), (2) where He ∈ Rn×d, and d is the hidden dimension. Decoder The decoder part takes the encoder out- puts He and previous decoder outputs Y<t as inputs to get Pt. However, the Y<t is an index sequence. Therefore, for each yt in Y<t, we ﬁrst need to use the following Index2Token module to conduct a Figure 3: Target sequences for different subtasks. The underlined indexes are given in advance. We convert the sentiment class index to the corresponding class to- ken for better understanding. them on the target side so that the target sequences are as follows: • ALSC : Y = [as, ae, sp], 1, oe • AOE : Y = [as, ae, os 1, ..., os i , oe i , ...], where the underlined tokens are given during infer- ence. Detailed target sequence examples for each subtask are presented in Figure 3. 3.2 Our Model As our discussion in the last section, all subtasks can be formulated as taking the X = [x1, ..., xn] as input and outputting a target sequence Y = IGBARTEncoderbatterylifeisgoodthe<s>2Position Embeddings:battery3life5good5goodBARTDecoderEncoder input:Token Embeddings:+++++<s>+</s>+1234506IGIGIGIGIG8+++++12340+++++123456Sentiment class⨂Prob.12345789⨂Dot-productIndex2Token ConversionIndex GeneratorEmbeddingDecoder input:Target:NEUPOSNEGthebatteryislifegoodNEUPOSNEG</s>6Pointer indexesClass indexes+The wine listis interestingand has good values ,buttheserviceis dreadfulPositivePositivePosition index:Token:0 1 2 3 4 5 6 7 8 9 10 11 12 13 14PositiveSubtaskTarget SequenceAE1, 2, 12, 12,</s> OE4, 4, 7, 8, 14, 14, </s>ALSC1, 2, POS, </s>12, 12, POS, </s>AOE1, 2, 4,4,7,8,</s>12, 12, 14, 14, </s>AESC1, 2, POS, 12, 12, NEG, </s>Pair1, 2, 4, 4, 1, 2, 7, 8, 12, 12, 14, 14, </s>Triplet1, 2, 4, 4, POS, 1, 2, 7, 8, POS, 12, 12, 14, 14, POS, </s>Dataset D17 D19 D20a D20b 14res #s #a #o train 3044 3699 3484 test 800 1134 1008 train 1627 2643 500 865 test train 1300 323 dev test 496 train 1266 310 dev 492 test - - - - - - - - - - - - - - 14lap #o #a #s 3048 2373 2504 800 654 674 1158 1634 343 482 #p - - - - 15res #p - - - - #o #a #s 1315 1199 1210 685 542 510 754 1076 325 436 #p - - - - - - - - - - - - 2145 920 524 228 862 339 2338 906 577 219 994 328 - - - - - - 1265 593 148 337 490 318 1460 605 148 346 148 543 - - - - - - #s - - 16res #a #o #p - - - - - - - 1079 1512 - - 329 457 - - 1289 - 316 - 465 - 1394 - 339 - 514 - - - - - - 923 842 238 210 455 320 1013 857 249 210 485 326 Subtasks AE, OE, ALSC, AESC AOE AE, OE, ALSC, AOE, AESC, Pair, Triplet AE, OE, ALSC, AOE, AESC, Pair, Triplet - - - - - - - - Table 1: The statistics of four datasets, where the #s, #a, #o, #p denote the numbers of sentences, aspect terms, opinion terms, and the <a, o> pairs, respectively. We use “-” to denote the missing data statistics of some datasets. The “Subtasks” column refers to the ABSA subtasks that can be applied on the corresponding dataset. conversion ˆyt = (cid:40) Xyt, Cyt−n, if yt is a pointer index, if yt is a class index, (3) where C = [c1, ..., cl] is the class token list4. After that, we use the BART decoder to get the last hidden state t = BARTDecoder(He; ˆY<t), hd (4) t ∈ Rd. With hd where hd probability distribution Pt as follows: t , we predict the token Ee = BARTTokenEmbed(X), ˆHe = MLP(He), ¯He = α ˆHe + (1 − α)Ee, Cd = BARTTokenEmbed(C), Pt = Softmax([ ¯He; Cd]hd t ), (5) (6) (7) (8) (9) where Ee, He, ˆHe, ¯He ∈ Rn×d; Cd ∈ Rl×d; and Pt ∈ R(n+l) is the ﬁnal distribution on all indexes. During the training phase, we use the teacher forcing to train our model and the negative log- likelihood to optimize the model. Moreover, dur- ing the inference, we use the beam search to get the target sequence Y in an autoregressive manner. After that, we need to use the decoding algorithm to convert this sequence into the term spans and sentiment polarity. We use the Triplet task as an example and present the decoding algorithm in Al- gorithm 1, the decoding algorithm for other tasks are much depicted in the Supplementary Material. Algorithm 1 Decoding Algorithm for the Triplet Subtask Input: Number of tokens in the input sentence n, target sequence Y = [y1, ..., ym] and yi ∈ [1, n + |C|] Output: Target 1, os 1: L = {}, e = [], i = 1 2: while i <= m do yi = Y [i] 3: if yi > n then span 1, s1), ..., (as = i , si), ...} L i , oe set i , ae 1, ae 1, oe i , os {(as 4: 5: 6: 7: 8: L.add((e, Cyi−n)) e = [] else e.append(yi) 9: end if i+ = 1 10: 11: end while 12: return L 4 Experiments 4.1 Datasets We evaluate our method on four ABSA datasets. All of them are originated from the Semeval Chal- lenges (Pontiki et al., 2014a,b,c), where only the aspect terms and their sentiment polarities are la- beled. The ﬁrst dataset(D17 5) is annotated by Wang et al. (2017), where the unpaire opinion terms are la- beled. The second dataset(D19) is annotated by Fan et al. (2019), where they pair opinion terms with 4In our implement, yt ∈ [1, n + l]. The x1 has the pointer index 1. 5Each dataset only contains a subset of all ABSA subtasks. We use the published year of the dataset to distinguish them. Baselines E2E Task Formulation Backbone Datasets AE OE ALSC AOE AESC Pair Triplet SPAN-BERT IMN-BERT RACL-BERT IOG LOTN ONG RINANTE+ CMLA+ Li-uniﬁed+ Peng-two-stage JET-BERT Dual-MRC Ours - (cid:51) - (cid:51) (cid:51) (cid:51) - - - - (cid:51) - (cid:51) Span.Extraction Seq.Tagging Seq.Tagging Seq.Tagging Seq.Tagging Seq.Tagging Seq.Tagging Seq.Tagging Seq.Tagging Seq.Tagging Seq.Tagging Span.MRC BERT BERT BERT LSTM LSTM BERT D17 D17 D17 D19 D19 D19 (cid:51) (cid:51) (cid:51) - - - LSTM+CRF D20a,D20b D20a,D20b Attention D20a,D20b LSTM LSTM+GCN D20a,D20b D20a,D20b BERT BERT (cid:51) (cid:51) (cid:51) (cid:51) (cid:51) D17,D19,D20a,D20b (cid:51) D17,D19,D20a,D20b (cid:51) - (cid:51) (cid:51) - - - (cid:51) (cid:51) (cid:51) (cid:51) (cid:51) - (cid:51) (cid:51) (cid:51) (cid:51) - - - (cid:51) (cid:51) (cid:51) (cid:51) (cid:51) (cid:51) - - - (cid:51) (cid:51) (cid:51) - - - - - (cid:51) (cid:51) (cid:51) (cid:51) (cid:51) (cid:51) - - - (cid:51) (cid:51) (cid:51) (cid:51) (cid:51) (cid:51) (cid:51) - - - - - - (cid:51) (cid:51) (cid:51) (cid:51) (cid:51) (cid:51) (cid:51) - - - - - - (cid:51) (cid:51) (cid:51) (cid:51) (cid:51) (cid:51) (cid:51) Span.Generation BART Table 2: The baselines of our experiments. To further demonstrate that our proposed method is a real uniﬁed end- to-end ABSA framework, we present our work in the last row. “E2E” is short for End-to-End, which means the model should output all the subtasks’ results synchronously rather than requiring any preconditions, e.g., pipeline methods. The “Datasets” column refers to the datasets that this baseline is conducted. corresponding aspects. The third dataset(D20a) is from Peng et al. (2020). They reﬁne the data in <a, o, s> triplet form. The fourth dataset(D20b) from Xu et al. (2020) is the revised variant of Peng et al. (2020), where the missing triplets with overlapping opinions are corrected. We present the statistics for these four datasets in Table 1. 4.2 Baselines To have a fair comparison, we summarize top- performing baselines of all ABSA subtasks. Given different ABSA subtasks, datasets, and experimen- tal setups, existing baselines can be separated into three groups roughly as shown in Table 2. The baselines in the ﬁrst group are conducted on D17 dataset, covering the AE, OE, ALSC, and AESC subtasks. Span-based method SPAN-BERT (Hu et al., 2019) and sequence tagging method, IMN- BERT (He et al., 2019) and RACL-BERT (Chen and Qian, 2020), are selected. Speciﬁcally, the IMN-BERT model is reproduced by Chen and Qian (2020). All these baselines are implemented on BERT-Large. The baselines of the second group are conducted on D19 dataset, mainly focusing on AOE subtask. Interestingly, we ﬁnd that sequence tagging method is the main solution for this subtask (Fan et al., 2019; Wu et al., 2020; Pouran Ben Veyseh et al., 2020). The baselines of the third group are mainly con- ducted on D20a and D20b datasets, which could cover almost all the ABSA subtasks except for one certain subtask depending on the baseline struc- tures. For the following baselines: RINANTE (Dai and Song, 2019), CMLA (Wang et al., 2017), Li- uniﬁed (Li et al., 2019), the sufﬁx “+” in Table 2 denotes the corresponding model variant modiﬁed by Peng et al. (2020) for being capable of AESC, Pair and Triplet. 4.3 Implement Details Following previous studies, we use different met- rics according to different subtasks and datasets. Speciﬁcally, for the single output subtasks AE, OE, and AOE, the prediction span would be considered as correct only if it exactly matches the start and the end boundaries. For the ALSC subtask, we require the generated sentiment polarity of the given aspect should be the same as the ground truth. As for compound output subtasks, AESC, Pair and Triplet, a prediction result is correct only when all the span boundaries and the generated sentiment polarity are accurately identiﬁed. We report the precision (P), recall (R), and F1 scores for all experiments6. 4.4 Main Results On D17 dataset (Wang et al., 2017), we compare our method for AE, OE, ALSC, and AESC. The comparison results are shown in Table 3. Most of our results achieve better or comparable results to 6Due to the limited space, we would present detailed ex- periments for each dataset in the Supplementary Material. Model SPAN-BERT IMN-BERT RACL-BERT Dual-MRC Ours 14res 14lap 15res AE 86.71 84.06 86.38 86.60 87.07 OE - 85.10 87.18 - 87.29 ALSC AESC 73.68 71.75 70.72 75.67 75.42 81.61 75.95 82.04 75.56 73.56 AE 82.34 77.55 81.79 82.51 83.52 OE - 81.0 79.72 - 77.86 ALSC AESC 61.25 62.5 61.73 75.56 63.40 73.91 65.94 75.97 67.37 76.76 AE 74.63 69.90 73.99 75.08 75.48 OE - 73.29 76.0 - 76.49 ALSC AESC 62.29 50.28 60.22 70.10 74.91 66.05 65.08 73.59 66.61 73.91 Table 3: Comparison F1 scores for AE, OE, SC, and AESC on the D17 dataset (Wang et al., 2017). The baseline results are retrieved from Mao et al. (2021). We highlight the best results in bold. It is worth noting that all the baseline results are obtained via BERT-Large, while our results are obtained via BART-Base. Model IOG LOTN ONG Dual-MRC Ours 14res R 78.25 80.52 81.46 78.43 84.76 P 82.38 84.0 83.23 89.79 86.01 F1 80.23 82.21 82.33 83.73 85.38 P 73.43 77.08 73.87 78.21 83.11 14lap R 68.74 67.62 77.78 81.66 78.13 F1 70.99 72.02 75.77 79.90 80.55 P 72.19 76.61 76.63 77.19 80.12 15res R 71.76 70.29 81.14 71.98 80.93 F1 71.91 73.29 78.81 74.50 80.52 P 84.36 86.57 87.72 86.07 89.22 16res R 79.08 80.89 84.38 80.77 86.67 F1 81.60 83.62 86.01 83.33 87.92 Table 4: Comparison results for AOE on the D19 dataset (Fan et al., 2019). Baselines are from the original papers. We highlight the best results in bold. Model CMLA+ † RINANTE+ † Li-uniﬁed+ † Peng-two-stage † JET-BERT (cid:93) Dual-MRC† Ours 14res Pair 48.95 46.29 55.34 56.10 - 74.93 77.68 AESC 70.62 48.15 73.79 74.19 - 76.57 78.47 Triple. AESC 43.12 34.03 51.68 51.89 63.92 70.32 72.46 56.90 36.70 63.38 62.34 - 64.59 68.17 14lap Pair 44.10 29.70 52.56 53.85 - 63.37 66.11 Triple. AESC 32.90 20.0 42.47 43.50 50.0 55.58 57.59 53.60 41.30 64.95 65.79 - 65.14 69.95 15res Pair 44.60 35.40 56.85 56.23 - 64.97 67.98 Triple. AESC 35.90 28.0 46.69 46.79 54.67 57.21 60.11 61.20 42.10 70.20 71.73 - 70.84 75.69 16res Pair 50.00 30.70 53.75 60.04 - 75.71 77.38 Triple. 41.60 23.30 44.51 53.62 62.98 67.40 69.98 Table 5: Comparison F1 scores for AESC, Pair and Triplet on the D20a dataset (Peng et al., 2020). The baseline results with “†” are retrieved from Mao et al. (2021), and result with “(cid:93)” is from Xu et al. (2020). We highlight the best results in bold. Model CMLA+ RINANTE+ Li-uniﬁed+ Peng-two-stage JET-BERT Ours 14res R 47.13 39.38 67.35 63.66 55.94 64.99 P 39.18 31.42 41.04 43.24 70.56 65.52 F1 42.79 34.95 51.0 51.46 62.40 65.25 P 30.09 21.71 40.56 37.38 55.39 61.41 14lap R 36.92 18.66 44.28 50.38 47.33 56.19 F1 33.16 20.07 42.34 42.87 51.04 58.69 P 34.56 29.88 44.72 48.07 64.45 59.14 15res R 39.84 30.06 51.39 57.51 51.96 59.38 F1 37.01 29.97 47.82 52.32 57.53 59.26 P 41.34 25.68 37.33 46.96 70.42 66.6 16res R 42.1 22.3 54.51 64.24 58.37 68.68 F1 41.72 23.87 44.31 54.21 63.83 67.62 Table 6: Comparison results for Triplet on the D20b dataset (Xu et al., 2020). Baselines are from (Xu et al., 2020). We highlight the best results in bold. baselines. However, these baselines yield competi- tive results based on the BERT-Large pre-trained models. While our results are achieved on the BART-Base model with almost half parameters. This shows that our framework is more suitable for these ABSA subtasks. On D19 dataset (Fan et al., 2019), we compare our method for AOE. The comparison results are shown in Table 4. We can observe that our method achieves signiﬁcant P/R/F1 improvements on 14res, 15res, and 16res. Additionally, we notice that our F1 score on 14lap is close to the previous SOTA result. This is probably caused by the dataset do- main difference as the 14lap is the laptop comments while the others are restaurant comments. On D20a dataset (Peng et al., 2020), we com- pare our method for AESC, Pair, and Triplet. The comparison results are shown in Table 5. We can observe that our proposed method is able to outper- form other baselines on all datasets. Speciﬁcally, we achieve the better results for Triplet, which demonstrates the effectiveness of our method on capturing interactions among aspect terms, opinion terms, and sentiment polarities. We also observe that the Span-based methods show superior per- formance to sequence tagging methods. This may be caused by the higher compositionality of candi- date labels in sequence tagging methods (Hu et al., 2019). As the previous SOTA method, the Dual- MRC shows competitive performance by utilizing the span-based extraction method and the MRC mechanism. However, their inference process is not an end-to-end process. On D20b dataset (Xu et al., 2020), we compare our method for Triplet. The comparison results can be found in Table 6. Our method achieves the best results with nearly 7 F1 points improvements on 14res, 15res, and 16res. Our method achieves nearly 13, 9, 7, 12 points improvements on each dataset for the recall scores compared with other baselines. This also explains the drop performance of the precision score. Since D20b is reﬁned from D20a, we speciﬁcally compare the Triplet results of the corresponding dataset in D20a and D20b. Inter- estingly, we discover that all baselines have a much bigger performance change on 15res. We conjec- ture the distribution differences may be the cause reason. In conclusion, all the experiment results conﬁrm that our proposed method, which uniﬁes the training and the inference to an end-to-end gen- erative framework, provides a new SOTA solution for the whole ABSA task. mat like [as, ae, os, oe, sp], it is mandatory that one valid triplet prediction should be in length 5, noted as “5-len”, and obviously all end index should be larger than the corresponding start in- dex, noted as “ordered prediction”. We calculate number of non−5−len , referred to as the “Invalid total prediction total 5−len prediction size”, and the number of non−ordered prediction , re- ferred to as the “Invalid order”. The “Invalid token” means the as is not the start of a token, instead, it is the index of an inside subword. From Table 7, we can observe that BART could learn this task form easily as the low rate for all the three metrics, which demonstrate that the generative framework for ABSA is not only a theoretically uniﬁed task form but also a realizable framework in practical. We remove these invalid predictions in our imple- mentation of experiments. As shown in Table 4, we give some analysis on the impact of the beam size, as we are a generation method. However, the beam size seems to have little impact on the F1 scores. Errors 14res 14lap 15res 16res Invalid size 0.48% 0.77% 1.41% 1.40% Invalid order 1.75% 3.70% 3.26% 3.26% Invalid token 0.48% 0.78% 1.02% 1.02% Table 7: The errors for Triplet on the test set of the D20b. Pair Extraction F1 scores Triplet Extraction F1 scores e r o c s 1 F 75 72 69 66 63 e r o c s 1 F 69 66 63 60 57 14lap 14res 15res 16res 1 2 3 4 1 2 3 4 Beam Size Beam Size Figure 4: The F1 change curve with the increment of beam size on the dev set of D20b. The beam size seems to have little effect on the F1 scores. 5 Framework Analysis 6 Conclusion To better understand our proposed framework, we conduct analysis experiments on the D20b dataset (Xu et al., 2020). To validate whether our proposed framework could adapt to the generative ABSA task, we met- ric the invalid predictions for the Triplet. Speciﬁ- cally, since the Triplet requires the prediction for- This paper summarizes the seven ABSA subtasks and previous studies, which shows that there exist divergences on all the input, output, and task type sides. Previous studies have limitations on han- dling all these divergences in a uniﬁed framework. We propose to convert all the ABSA subtasks to a uniﬁed generative task. We implement the BART to generate the target sequence in an end-to-end process based on the uniﬁed task formulation. We conduct massive experiments on public datasets for seven ABSA subtasks and achieve signiﬁcant improvements on most datasets. The experimental results demonstrate the effectiveness of our method. Our work leads to several promising directions, such as sequence-to-sequence framework on other tasks, and data augmentation. Acknowledgements We would like to thank the anonymous reviewers for their insightful comments. The discussion with colleagues in AWS Shanghai AI Lab was quite fruitful. We also thank the developers of fastNLP7 and ﬁtlog8. This work was supported by the Na- tional Key Research and Development Program of China (No. 2020AAA0106700) and National Nat- ural Science Foundation of China (No. 62022027). Ethical Considerations For the consideration of ethical concerns, we would make detailed description as follows: (1) All the experiments are conducted on existing datasets, which are derived from public scientiﬁc papers. (2) We describe the characteristics of the datasets in a speciﬁc section. Our analysis is consistent with the results. (3) Our work does not contain identity character- istics. It does not harm anyone. (4) Our experiments do not need a lot of com- puter resources compared to pre-trained models. (5) We will open source all our code. References Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam Mc- Candlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learn- ers. 7https://github.com/fastnlp/fastNLP. FastNLP is a natural language processing python package. 8https://github.com/fastnlp/fitlog. Fit- log is an experiment tracking package Peng Chen, Zhongqian Sun, Lidong Bing, and Wei Yang. 2017. Recurrent attention network on mem- ory for aspect sentiment analysis. In Proceedings of the 2017 Conference on Empirical Methods in Nat- ural Language Processing, pages 452–461, Copen- hagen, Denmark. Association for Computational Linguistics. Zhuang Chen and Tieyun Qian. 2020. Relation-aware collaborative learning for uniﬁed aspect-based sen- timent analysis. In Proceedings of the 58th Annual Meeting of the Association for Computational Lin- guistics, pages 3685–3694, Online. Association for Computational Linguistics. Kyunghyun Cho, Bart van Merri¨enboer, Caglar Gul- cehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning phrase representations using RNN encoder–decoder for statistical machine translation. In Proceedings of the 2014 Conference on Empirical Methods in Nat- ural Language Processing (EMNLP), pages 1724– 1734, Doha, Qatar. Association for Computational Linguistics. Hongliang Dai and Yangqiu Song. 2019. Neural as- pect and opinion term extraction with mined rules as weak supervision. In Proceedings of the 57th An- nual Meeting of the Association for Computational Linguistics, pages 5268–5277, Florence, Italy. Asso- ciation for Computational Linguistics. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language under- In Proceedings of the 2019 Conference standing. of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171–4186, Minneapolis, Minnesota. Associ- ation for Computational Linguistics. Zhifang Fan, Zhen Wu, Xin-Yu Dai, Shujian Huang, and Jiajun Chen. 2019. Target-oriented opinion words extraction with target-fused neural sequence In Proceedings of the 2019 Conference labeling. of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 2509–2518, Minneapolis, Minnesota. Associ- ation for Computational Linguistics. Ruidan He, Wee Sun Lee, Hwee Tou Ng, and Daniel Dahlmeier. 2019. An interactive multi-task learn- ing network for end-to-end aspect-based sentiment analysis. In Proceedings of the 57th Annual Meet- ing of the Association for Computational Linguis- tics, pages 504–515, Florence, Italy. Association for Computational Linguistics. Minghao Hu, Yuxing Peng, Zhen Huang, Dongsheng Li, and Yiwei Lv. 2019. Open-domain targeted sen- timent analysis via span-based extraction and classi- In Proceedings of the 57th Annual Meet- ﬁcation. ing of the Association for Computational Linguis- tics, pages 537–546, Florence, Italy. Association for Computational Linguistics. John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. 2001. Conditional random ﬁelds: Probabilistic models for segmenting and labeling se- quence data. In Proceedings of the Eighteenth Inter- national Conference on Machine Learning (ICML 2001), Williams College, Williamstown, MA, USA, June 28 - July 1, 2001, pages 282–289. Morgan Kaufmann. Mike Lewis, Yinhan Liu, Naman Goyal, Mar- jan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. BART: Denoising sequence-to-sequence pre- training for natural language generation, translation, and comprehension. In Proceedings of the 58th An- nual Meeting of the Association for Computational Linguistics, pages 7871–7880, Online. Association for Computational Linguistics. Kun Li, Chengbo Chen, Xiaojun Quan, Qing Ling, and Yan Song. 2020. Conditional augmentation for aspect term extraction via masked sequence-to- sequence generation. In Proceedings of the 58th An- nual Meeting of the Association for Computational Linguistics, pages 7056–7066, Online. Association for Computational Linguistics. Xin Li, Lidong Bing, Wai Lam, and Bei Shi. 2018a. Transformation networks for target-oriented senti- ment classiﬁcation. In Proceedings of the 56th An- nual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 946– 956, Melbourne, Australia. Association for Compu- tational Linguistics. Xin Li, Lidong Bing, Piji Li, and Wai Lam. 2019. A uniﬁed model for opinion target extraction and target sentiment prediction. In The Thirty-Third AAAI Con- ference on Artiﬁcial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artiﬁcial In- telligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artiﬁcial Intelligence, EAAI 2019, Honolulu, Hawaii, USA, January 27 - February 1, 2019, pages 6714–6721. AAAI Press. Xin Li, Lidong Bing, Piji Li, Wai Lam, and Zhimou Yang. 2018b. Aspect term extraction with history attention and selective transformation. In Proceed- ings of the Twenty-Seventh International Joint Con- ference on Artiﬁcial Intelligence, IJCAI 2018, July 13-19, 2018, Stockholm, Sweden, pages 4194–4200. ijcai.org. Xin Li and Wai Lam. 2017. Deep multi-task learning for aspect term extraction with memory interaction. In Proceedings of the 2017 Conference on Empiri- cal Methods in Natural Language Processing, pages 2886–2892, Copenhagen, Denmark. Association for Computational Linguistics. Jiangming Liu and Yue Zhang. 2017. Attention mod- eling for targeted sentiment. In Proceedings of the 15th Conference of the European Chapter of the As- sociation for Computational Linguistics: Volume 2, Short Papers, pages 572–577, Valencia, Spain. As- sociation for Computational Linguistics. Thang Luong, Hieu Pham, and Christopher D. Man- ning. 2015. Effective approaches to attention-based In Proceedings of the neural machine translation. 2015 Conference on Empirical Methods in Natu- ral Language Processing, pages 1412–1421, Lis- bon, Portugal. Association for Computational Lin- guistics. Dehong Ma, Sujian Li, and Houfeng Wang. 2018. Joint learning for targeted sentiment analysis. In Proceed- ings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4737–4742, Brussels, Belgium. Association for Computational Linguistics. Dehong Ma, Sujian Li, Fangzhao Wu, Xing Xie, and Houfeng Wang. 2019. Exploring sequence-to- sequence learning in aspect term extraction. In Pro- ceedings of the 57th Annual Meeting of the Asso- ciation for Computational Linguistics, pages 3538– 3547, Florence, Italy. Association for Computa- tional Linguistics. Dehong Ma, Sujian Li, Xiaodong Zhang, and Houfeng Interactive attention networks for Wang. 2017. In Proceed- aspect-level sentiment classiﬁcation. ings of the Twenty-Sixth International Joint Con- ference on Artiﬁcial Intelligence, IJCAI 2017, Mel- bourne, Australia, August 19-25, 2017, pages 4068– 4074. ijcai.org. Yue Mao, Yi Shen, Chao Yu, and Longjun Cai. 2021. A joint training dual-mrc framework for aspect based sentiment analysis. CoRR, abs/2101.00816. Margaret Mitchell, Jacqui Aguilar, Theresa Wilson, and Benjamin Van Durme. 2013. Open domain tar- In Proceedings of the 2013 Con- geted sentiment. ference on Empirical Methods in Natural Language Processing, pages 1643–1654, Seattle, Washington, USA. Association for Computational Linguistics. Haiyun Peng, Lu Xu, Lidong Bing, Fei Huang, Wei Lu, and Luo Si. 2020. Knowing what, how and why: A near complete solution for aspect-based sen- In The Thirty-Fourth AAAI Con- timent analysis. ference on Artiﬁcial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artiﬁcial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artiﬁcial In- telligence, EAAI 2020, New York, NY, USA, Febru- ary 7-12, 2020, pages 8600–8607. AAAI Press. Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep contextualized word rep- In Proceedings of the 2018 Confer- resentations. ence of the North American Chapter of the Associ- ation for Computational Linguistics: Human Lan- guage Technologies, Volume 1 (Long Papers), pages 2227–2237, New Orleans, Louisiana. Association for Computational Linguistics. Maria Pontiki, Dimitris Galanis, John Pavlopoulos, Harris Papageorgiou, Ion Androutsopoulos, and Suresh Manandhar. 2014a. SemEval-2014 task 4: Aspect based sentiment analysis. In Proceedings of the 8th International Workshop on Semantic Evalua- tion (SemEval 2014), pages 27–35, Dublin, Ireland. Association for Computational Linguistics. Maria Pontiki, Dimitris Galanis, John Pavlopoulos, Harris Papageorgiou, Ion Androutsopoulos, and Suresh Manandhar. 2014b. SemEval-2014 task 4: Aspect based sentiment analysis. In Proceedings of the 8th International Workshop on Semantic Evalua- tion (SemEval 2014), pages 27–35, Dublin, Ireland. Association for Computational Linguistics. Maria Pontiki, Dimitris Galanis, John Pavlopoulos, Harris Papageorgiou, Ion Androutsopoulos, and Suresh Manandhar. 2014c. SemEval-2014 task 4: Aspect based sentiment analysis. In Proceedings of the 8th International Workshop on Semantic Evalua- tion (SemEval 2014), pages 27–35, Dublin, Ireland. Association for Computational Linguistics. Amir Pouran Ben Veyseh, Nasim Nouri, Franck Der- noncourt, Dejing Dou, and Thien Huu Nguyen. Introducing syntactic structures into target 2020. opinion word extraction with deep learning. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 8947–8956, Online. Association for Computa- tional Linguistics. Xipeng Qiu, TianXiang Sun, Yige Xu, Yunfan Shao, Ning Dai, and Xuanjing Huang. 2020. Pre-trained language processing: A sur- models for natural SCIENCE CHINA Technological Sciences, vey. 63(10):1872–1897. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a uniﬁed text-to-text trans- former. J. Mach. Learn. Res., 21:140:1–140:67. Sunita Sarawagi and William W. Cohen. 2004. Semi- markov conditional random ﬁelds for information extraction. In Advances in Neural Information Pro- cessing Systems 17 [Neural Information Processing Systems, NIPS 2004, December 13-18, 2004, Van- couver, British Columbia, Canada], pages 1185– 1192. Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie- Yan Liu. 2019. MASS: masked sequence to se- quence pre-training for language generation. In Pro- ceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, volume 97 of Pro- ceedings of Machine Learning Research, pages 5926–5936. PMLR. Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014. Sequence to sequence learning with neural networks. In Advances in Neural Information Processing Sys- tems 27: Annual Conference on Neural Informa- tion Processing Systems 2014, December 8-13 2014, Montreal, Quebec, Canada, pages 3104–3112. Duyu Tang, Bing Qin, Xiaocheng Feng, and Ting Liu. 2016a. Effective LSTMs for target-dependent sen- In Proceedings of COLING timent classiﬁcation. 2016, the 26th International Conference on Compu- tational Linguistics: Technical Papers, pages 3298– 3307, Osaka, Japan. The COLING 2016 Organizing Committee. Duyu Tang, Bing Qin, and Ting Liu. 2016b. Aspect level sentiment classiﬁcation with deep memory net- In Proceedings of the 2016 Conference on work. Empirical Methods in Natural Language Processing, pages 214–224, Austin, Texas. Association for Com- putational Linguistics. Yi Tay, Luu Anh Tuan, and Siu Cheung Hui. 2018. Learning to attend via word-aspect associative fu- In Pro- sion for aspect-based sentiment analysis. ceedings of the Thirty-Second AAAI Conference on Artiﬁcial Intelligence, (AAAI-18), the 30th innova- tive Applications of Artiﬁcial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Ad- vances in Artiﬁcial Intelligence (EAAI-18), New Or- leans, Louisiana, USA, February 2-7, 2018, pages 5956–5963. AAAI Press. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Pro- cessing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4- 9, 2017, Long Beach, CA, USA, pages 5998–6008. Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. In Advances in Neural 2015. Pointer networks. Information Processing Systems 28: Annual Con- ference on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada, pages 2692–2700. Wenya Wang and Sinno Jialin Pan. 2018. Recursive neural structural correspondence network for cross- In Pro- domain aspect and opinion co-extraction. ceedings of the 56th Annual Meeting of the Associa- tion for Computational Linguistics (Volume 1: Long Papers), pages 2171–2181, Melbourne, Australia. Association for Computational Linguistics. Wenya Wang, Sinno Jialin Pan, Daniel Dahlmeier, and Xiaokui Xiao. 2016a. Recursive neural conditional random ﬁelds for aspect-based sentiment analysis. In Proceedings of the 2016 Conference on Empiri- cal Methods in Natural Language Processing, pages 616–626, Austin, Texas. Association for Computa- tional Linguistics. Wenya Wang, Sinno Jialin Pan, Daniel Dahlmeier, and Xiaokui Xiao. 2017. Coupled multi-layer attentions Meeting of the Association for Computational Lin- guistics, pages 3239–3248, Online. Association for Computational Linguistics. for co-extraction of aspect and opinion terms. In Proceedings of the Thirty-First AAAI Conference on Artiﬁcial Intelligence, February 4-9, 2017, San Fran- cisco, California, USA, pages 3316–3322. AAAI Press. Yequan Wang, Minlie Huang, Xiaoyan Zhu, and Li Zhao. 2016b. Attention-based LSTM for aspect- In Proceedings of level sentiment classiﬁcation. the 2016 Conference on Empirical Methods in Nat- ural Language Processing, pages 606–615, Austin, Texas. Association for Computational Linguistics. Zhen Wu, Fei Zhao, Xin-Yu Dai, Shujian Huang, and Jiajun Chen. 2020. Latent opinions transfer network for target-oriented opinion words extraction. In The Thirty-Fourth AAAI Conference on Artiﬁcial Intelli- gence, AAAI 2020, The Thirty-Second Innovative Ap- plications of Artiﬁcial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artiﬁcial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020, pages 9298– 9305. AAAI Press. Hu Xu, Bing Liu, Lei Shu, and Philip S. Yu. 2018. Dou- ble embeddings and CNN-based sequence labeling for aspect extraction. In Proceedings of the 56th An- nual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 592– 598, Melbourne, Australia. Association for Compu- tational Linguistics. Lu Xu, Hao Li, Wei Lu, and Lidong Bing. 2020. Position-aware tagging for aspect sentiment triplet extraction. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Process- ing (EMNLP), pages 2339–2349, Online. Associa- tion for Computational Linguistics. Wei Xue and Tao Li. 2018. Aspect based sentiment analysis with gated convolutional networks. In Pro- ceedings of the 56th Annual Meeting of the Associa- tion for Computational Linguistics (Volume 1: Long Papers), pages 2514–2523, Melbourne, Australia. Association for Computational Linguistics. Meishan Zhang, Yue Zhang, and Duy-Tin Vo. 2015. Neural networks for open domain targeted sentiment. In Proceedings of the 2015 Conference on Empiri- cal Methods in Natural Language Processing, pages 612–621, Lisbon, Portugal. Association for Compu- tational Linguistics. Meishan Zhang, Yue Zhang, and Duy-Tin Vo. 2016. Gated neural networks for targeted sentiment anal- In Proceedings of the Thirtieth AAAI Con- ysis. ference on Artiﬁcial Intelligence, February 12-17, 2016, Phoenix, Arizona, USA, pages 3087–3093. AAAI Press. He Zhao, Longtao Huang, Rong Zhang, Quan Lu, and Hui Xue. 2020. SpanMlt: A span-based multi-task learning framework for pair-wise aspect and opinion terms extraction. In Proceedings of the 58th Annual A Supplemental Material A.1 Experimental Environment We use the triangular learning rate warmup. All experiments are conducted in the Nvidia Ge-Force RTX-3090 Graphical Card with 24G graphical memory. The averages running time for experiments on each dataset is less than 15 minutes. The number of parameters is as follows: • BART-Base model: 12 layers, 768 hidden di- mensions and 16 heads with the total number of parameters, 139M; • BERT-Base model: 12 layers, 768 hidden di- mensions and 12 heads with the total number of parameters, 110M. A.2 Decoding Algorithm for Different Datasets In this part, we introduce the decoding algorithm we used to convert the predicted target sequence Y into the target span set L. These algorithm can be found in Algorithm 2, 3, 4. Algorithm 2 Decoding Algorithm for the AOE sub- task Input: Number of tokens in the input sentence n, target sequence Y = [y1, ..., ym] and yi ∈ [1, n + |C|], LT is a given length for different tasks. 1, oe 1, ..., os i , oe i )} Output: Target span set L = {(os 1: L = {}, e = [], i = 3 2: while i <= m do yi = Y [i] 3: e.append(yi) i+ = 1 5: 6: end while 7: L.add(e) 8: return L 4: Algorithm 3 Decoding Algorithm for the AESC Subtask Input: Number of tokens in the input sentence n, target sequence Y = [y1, ..., ym] and yi ∈ [1, n + |C|] Output: Target = L set i , si)} i , ae {(as 1, ae span 1, s1), ..., (as 1: L = {}, e = [], i = 1 2: while i <= m do yi = Y [i] 3: if yi > n then 4: 5: 6: 7: 8: L.add((e, Cyi−n)) e = [] else e.append(yi) 9: end if i+ = 1 10: 11: end while 12: return L Algorithm 4 Decoding Algorithm for AE/OE/Pair subtasks Input: Number of tokens in the input sentence n, target sequence Y = [y1, ..., ym] and yi ∈ [1, n + |C|], LT is a given length for different tasks. the Output: Target span set L = {x1, ..., xi}(xi i ) for i ) and (as is (as i ), (os AE/OE/Pair, respectively) i , ae i , ae i , os i , oe i , oe 1: L = {}, e = [], i = 1 2: while i <= m do yi = Y [i] 3: if len(e) == LT then L.add((e, Cyi−n)) e = [] 4: 5: 6: 7: 8: end if e.append(yi) i+ = 1 9: 10: end while 11: return L A.3 Detailed Experimental Setup Experiments on each dataset As the different subtasks are conducted on differ- ent datasets, speciﬁcally, we conduct the following experiments on each dataset: • On the D17 dataset, we conduct the AESC and the OE in multi-task learning method. To that end, we feed the pre-deﬁned task tags “<AESC>” and “<OE>” to the decoder ﬁrst. For example, for the input “The drinks are always (cid:58)(cid:58)(cid:58)(cid:58)well (cid:58)(cid:58)(cid:58)(cid:58)(cid:58)made and wine selection is (cid:58)(cid:58)(cid:58)(cid:58)(cid:58) priced” from D17 dataset, we fairly (cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58) deﬁne the AESC sequence and the OE target se- quence as “<AESC>, 1, 1, POS, 7, 8, POS, </s>” and “<OE>, 4, 5, 10, 11, </s>”. • On the D19 dataset, we conduct the AOE. As the AOE subtask requires to detect the opinion terms given aspect terms in advance, the aspect terms need to be fed to our decoder ﬁrst. For the aforementioned example sentence from D19 dataset, we deﬁne the AOE target sequence as “ 1, 1, 4, 5, </s>” and the “ 7, 8, 10, 11, </s>”. • On the D20a and D20b datasets, we conduct the Triplet Extraction. For the aforementioned example sentence from D20a and D20b dataset, we deﬁne the Triplet target sequence as “1, 1, 4, 5, POS, 7, 8, 10, 11, POS, </s>”. Speciﬁc Subtask Metrics • On the D17 dataset, we get the AESC and OE results directly. Following previous work, we only calculate the metrics for AESC and ALSC from those true positive AE predictions. Speciﬁcally, the F1 • On the D19 dataset, we get the AOE results di- rectly. The metrics for AOE are standard Precision, Recall and the F1 score. • On the D20a and D20b datasets, we get the Triplet results directly. We preserve the <AT,OT> for Pair metric and <AT, SP> for AESC metric. The metrics for them are standard Precision, Recall and the F1 score. 